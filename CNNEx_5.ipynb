{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7cb7f33-5fe3-4fc7-98fd-2c818d634c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-29 16:56:53.874297: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-29 16:56:53.947983: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-11-29 16:56:53.966550: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-29 16:56:54.287579: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.7/lib64:\n",
      "2022-11-29 16:56:54.287623: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.7/lib64:\n",
      "2022-11-29 16:56:54.287627: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import dlt\n",
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Conv2D, MaxPooling2D, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPool2D\n",
    "from keras.layers.core import Dense,Activation,Dropout,Flatten\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import np_utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cf1a0ee-23e8-4873-b701-ec4709aa7521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-29 16:57:17.447679: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-29 16:57:17.465890: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-29 16:57:17.465987: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-29 16:57:17.466320: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-29 16:57:17.467048: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-29 16:57:17.467145: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-29 16:57:17.467235: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-29 16:57:17.746275: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-29 16:57:17.746396: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-29 16:57:17.746475: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-29 16:57:17.746538: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14236 MB memory:  -> device: 0, name: NVIDIA RTX A4000, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2022-11-29 16:57:18.795855: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8600\n",
      "2022-11-29 16:57:19.255732: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 3s 16ms/step - loss: 1.9676 - accuracy: 0.2619 - val_loss: 1.6985 - val_accuracy: 0.3850\n",
      "Epoch 2/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 1.5304 - accuracy: 0.4352 - val_loss: 1.5189 - val_accuracy: 0.4700\n",
      "Epoch 3/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 1.3115 - accuracy: 0.5264 - val_loss: 1.4283 - val_accuracy: 0.5130\n",
      "Epoch 4/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 1.0928 - accuracy: 0.6192 - val_loss: 1.2675 - val_accuracy: 0.5600\n",
      "Epoch 5/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.8687 - accuracy: 0.6966 - val_loss: 1.1873 - val_accuracy: 0.6050\n",
      "Epoch 6/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.6972 - accuracy: 0.7628 - val_loss: 1.1800 - val_accuracy: 0.6220\n",
      "Epoch 7/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.5164 - accuracy: 0.8319 - val_loss: 1.2010 - val_accuracy: 0.6280\n",
      "Epoch 8/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.3704 - accuracy: 0.8729 - val_loss: 1.4139 - val_accuracy: 0.6110\n",
      "Epoch 9/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.2601 - accuracy: 0.9133 - val_loss: 1.4554 - val_accuracy: 0.6310\n",
      "Epoch 10/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.1786 - accuracy: 0.9359 - val_loss: 1.4556 - val_accuracy: 0.6430\n",
      "Epoch 11/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.1424 - accuracy: 0.9541 - val_loss: 1.7037 - val_accuracy: 0.6120\n",
      "Epoch 12/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.1225 - accuracy: 0.9592 - val_loss: 1.6742 - val_accuracy: 0.6440\n",
      "Epoch 13/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.0843 - accuracy: 0.9734 - val_loss: 1.7550 - val_accuracy: 0.6440\n",
      "Epoch 14/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.0709 - accuracy: 0.9777 - val_loss: 1.7949 - val_accuracy: 0.6360\n",
      "Epoch 15/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.0510 - accuracy: 0.9838 - val_loss: 1.9072 - val_accuracy: 0.6370\n",
      "Epoch 16/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.0463 - accuracy: 0.9857 - val_loss: 1.9398 - val_accuracy: 0.6460\n",
      "Epoch 17/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.0432 - accuracy: 0.9874 - val_loss: 2.0044 - val_accuracy: 0.6470\n",
      "Epoch 18/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.0301 - accuracy: 0.9908 - val_loss: 2.1544 - val_accuracy: 0.6330\n",
      "Epoch 19/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.0283 - accuracy: 0.9913 - val_loss: 2.1601 - val_accuracy: 0.6430\n",
      "Epoch 20/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.0282 - accuracy: 0.9900 - val_loss: 2.1126 - val_accuracy: 0.6270\n",
      "Test loss: 2.690460681915283\n",
      "Test accuracy: 0.5759999752044678\n",
      "Epoch 1/20\n",
      "71/71 [==============================] - 1s 12ms/step - loss: 1.9095 - accuracy: 0.2881 - val_loss: 1.6990 - val_accuracy: 0.3880\n",
      "Epoch 2/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 1.4592 - accuracy: 0.4633 - val_loss: 1.4872 - val_accuracy: 0.4990\n",
      "Epoch 3/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 1.2571 - accuracy: 0.5490 - val_loss: 1.2715 - val_accuracy: 0.5500\n",
      "Epoch 4/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 1.0575 - accuracy: 0.6309 - val_loss: 1.2861 - val_accuracy: 0.5520\n",
      "Epoch 5/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.8549 - accuracy: 0.7054 - val_loss: 1.2100 - val_accuracy: 0.5790\n",
      "Epoch 6/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.6931 - accuracy: 0.7659 - val_loss: 1.1629 - val_accuracy: 0.6090\n",
      "Epoch 7/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.5437 - accuracy: 0.8188 - val_loss: 1.2431 - val_accuracy: 0.6050\n",
      "Epoch 8/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.3839 - accuracy: 0.8704 - val_loss: 1.3198 - val_accuracy: 0.6120\n",
      "Epoch 9/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.2500 - accuracy: 0.9176 - val_loss: 1.5747 - val_accuracy: 0.6320\n",
      "Epoch 10/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.1879 - accuracy: 0.9376 - val_loss: 1.5236 - val_accuracy: 0.6510\n",
      "Epoch 11/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.1236 - accuracy: 0.9601 - val_loss: 1.7022 - val_accuracy: 0.6490\n",
      "Epoch 12/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.0875 - accuracy: 0.9701 - val_loss: 1.7203 - val_accuracy: 0.6460\n",
      "Epoch 13/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.0757 - accuracy: 0.9752 - val_loss: 1.8579 - val_accuracy: 0.6510\n",
      "Epoch 14/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.0810 - accuracy: 0.9723 - val_loss: 1.7199 - val_accuracy: 0.6470\n",
      "Epoch 15/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.0869 - accuracy: 0.9704 - val_loss: 1.8728 - val_accuracy: 0.6430\n",
      "Epoch 16/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.0676 - accuracy: 0.9788 - val_loss: 1.8466 - val_accuracy: 0.6660\n",
      "Epoch 17/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.0484 - accuracy: 0.9843 - val_loss: 1.9758 - val_accuracy: 0.6490\n",
      "Epoch 18/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.0355 - accuracy: 0.9884 - val_loss: 2.2333 - val_accuracy: 0.6380\n",
      "Epoch 19/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.0383 - accuracy: 0.9870 - val_loss: 2.3857 - val_accuracy: 0.6420\n",
      "Epoch 20/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.0509 - accuracy: 0.9827 - val_loss: 2.0560 - val_accuracy: 0.6250\n",
      "Test loss: 2.664138078689575\n",
      "Test accuracy: 0.5759999752044678\n",
      "Epoch 1/20\n",
      "71/71 [==============================] - 1s 12ms/step - loss: 1.9596 - accuracy: 0.2704 - val_loss: 1.7874 - val_accuracy: 0.4010\n",
      "Epoch 2/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 1.5388 - accuracy: 0.4358 - val_loss: 1.4990 - val_accuracy: 0.4550\n",
      "Epoch 3/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 1.3293 - accuracy: 0.5227 - val_loss: 1.4441 - val_accuracy: 0.5040\n",
      "Epoch 4/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 1.1219 - accuracy: 0.6021 - val_loss: 1.2959 - val_accuracy: 0.5590\n",
      "Epoch 5/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.9295 - accuracy: 0.6756 - val_loss: 1.2085 - val_accuracy: 0.5820\n",
      "Epoch 6/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.7245 - accuracy: 0.7513 - val_loss: 1.1871 - val_accuracy: 0.6280\n",
      "Epoch 7/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.5625 - accuracy: 0.8107 - val_loss: 1.2162 - val_accuracy: 0.6400\n",
      "Epoch 8/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.4270 - accuracy: 0.8576 - val_loss: 1.2665 - val_accuracy: 0.6240\n",
      "Epoch 9/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.2966 - accuracy: 0.8996 - val_loss: 1.3061 - val_accuracy: 0.6560\n",
      "Epoch 10/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.2286 - accuracy: 0.9218 - val_loss: 1.4238 - val_accuracy: 0.6430\n",
      "Epoch 11/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.1759 - accuracy: 0.9402 - val_loss: 1.4633 - val_accuracy: 0.6580\n",
      "Epoch 12/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.1148 - accuracy: 0.9622 - val_loss: 1.6731 - val_accuracy: 0.6500\n",
      "Epoch 13/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.1145 - accuracy: 0.9631 - val_loss: 1.7239 - val_accuracy: 0.6570\n",
      "Epoch 14/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.0740 - accuracy: 0.9737 - val_loss: 1.7757 - val_accuracy: 0.6600\n",
      "Epoch 15/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.0701 - accuracy: 0.9757 - val_loss: 1.8658 - val_accuracy: 0.6540\n",
      "Epoch 16/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.0618 - accuracy: 0.9787 - val_loss: 1.9205 - val_accuracy: 0.6600\n",
      "Epoch 17/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.0622 - accuracy: 0.9783 - val_loss: 2.0704 - val_accuracy: 0.6400\n",
      "Epoch 18/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.0585 - accuracy: 0.9793 - val_loss: 1.9969 - val_accuracy: 0.6490\n",
      "Epoch 19/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.0421 - accuracy: 0.9862 - val_loss: 2.0228 - val_accuracy: 0.6510\n",
      "Epoch 20/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.0461 - accuracy: 0.9847 - val_loss: 2.0279 - val_accuracy: 0.6680\n",
      "Test loss: 2.746957540512085\n",
      "Test accuracy: 0.5619999766349792\n",
      "Epoch 1/20\n",
      "71/71 [==============================] - 1s 12ms/step - loss: 1.8842 - accuracy: 0.2961 - val_loss: 1.5980 - val_accuracy: 0.4240\n",
      "Epoch 2/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 1.4961 - accuracy: 0.4599 - val_loss: 1.6246 - val_accuracy: 0.4590\n",
      "Epoch 3/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 1.2759 - accuracy: 0.5364 - val_loss: 1.3571 - val_accuracy: 0.5090\n",
      "Epoch 4/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 1.0442 - accuracy: 0.6330 - val_loss: 1.3105 - val_accuracy: 0.5500\n",
      "Epoch 5/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.8280 - accuracy: 0.7171 - val_loss: 1.2070 - val_accuracy: 0.5830\n",
      "Epoch 6/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.6117 - accuracy: 0.7921 - val_loss: 1.2724 - val_accuracy: 0.5970\n",
      "Epoch 7/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.4415 - accuracy: 0.8527 - val_loss: 1.3185 - val_accuracy: 0.6060\n",
      "Epoch 8/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.3069 - accuracy: 0.8993 - val_loss: 1.3549 - val_accuracy: 0.6240\n",
      "Epoch 9/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.2178 - accuracy: 0.9296 - val_loss: 1.5666 - val_accuracy: 0.6270\n",
      "Epoch 10/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.1464 - accuracy: 0.9520 - val_loss: 1.6173 - val_accuracy: 0.6200\n",
      "Epoch 11/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.1169 - accuracy: 0.9604 - val_loss: 1.7662 - val_accuracy: 0.6130\n",
      "Epoch 12/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.1026 - accuracy: 0.9653 - val_loss: 1.8714 - val_accuracy: 0.6200\n",
      "Epoch 13/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.0596 - accuracy: 0.9800 - val_loss: 1.9998 - val_accuracy: 0.6120\n",
      "Epoch 14/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.0615 - accuracy: 0.9796 - val_loss: 1.9462 - val_accuracy: 0.6320\n",
      "Epoch 15/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.0520 - accuracy: 0.9840 - val_loss: 2.1771 - val_accuracy: 0.6110\n",
      "Epoch 16/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.0451 - accuracy: 0.9846 - val_loss: 2.1963 - val_accuracy: 0.6190\n",
      "Epoch 17/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.0552 - accuracy: 0.9814 - val_loss: 2.2976 - val_accuracy: 0.6220\n",
      "Epoch 18/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.0571 - accuracy: 0.9806 - val_loss: 2.0604 - val_accuracy: 0.6160\n",
      "Epoch 19/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.0412 - accuracy: 0.9858 - val_loss: 2.3351 - val_accuracy: 0.6380\n",
      "Epoch 20/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.0407 - accuracy: 0.9872 - val_loss: 2.2582 - val_accuracy: 0.6050\n",
      "Test loss: 2.855844736099243\n",
      "Test accuracy: 0.550000011920929\n",
      "Epoch 1/20\n",
      "71/71 [==============================] - 1s 12ms/step - loss: 1.9925 - accuracy: 0.2578 - val_loss: 1.6507 - val_accuracy: 0.4030\n",
      "Epoch 2/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 1.5518 - accuracy: 0.4298 - val_loss: 1.5238 - val_accuracy: 0.4590\n",
      "Epoch 3/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 1.3208 - accuracy: 0.5157 - val_loss: 1.4056 - val_accuracy: 0.4920\n",
      "Epoch 4/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 1.1150 - accuracy: 0.6001 - val_loss: 1.3271 - val_accuracy: 0.5600\n",
      "Epoch 5/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.8912 - accuracy: 0.6871 - val_loss: 1.1769 - val_accuracy: 0.5960\n",
      "Epoch 6/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.6968 - accuracy: 0.7614 - val_loss: 1.1449 - val_accuracy: 0.6260\n",
      "Epoch 7/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.4886 - accuracy: 0.8372 - val_loss: 1.1353 - val_accuracy: 0.6530\n",
      "Epoch 8/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.3702 - accuracy: 0.8761 - val_loss: 1.2158 - val_accuracy: 0.6470\n",
      "Epoch 9/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.2734 - accuracy: 0.9069 - val_loss: 1.2890 - val_accuracy: 0.6500\n",
      "Epoch 10/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.1783 - accuracy: 0.9398 - val_loss: 1.4817 - val_accuracy: 0.6400\n",
      "Epoch 11/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.1204 - accuracy: 0.9596 - val_loss: 1.5384 - val_accuracy: 0.6640\n",
      "Epoch 12/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.1065 - accuracy: 0.9651 - val_loss: 1.6239 - val_accuracy: 0.6630\n",
      "Epoch 13/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.0960 - accuracy: 0.9688 - val_loss: 1.6525 - val_accuracy: 0.6680\n",
      "Epoch 14/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.0695 - accuracy: 0.9783 - val_loss: 1.9569 - val_accuracy: 0.6600\n",
      "Epoch 15/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.0716 - accuracy: 0.9756 - val_loss: 1.7778 - val_accuracy: 0.6460\n",
      "Epoch 16/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.0631 - accuracy: 0.9793 - val_loss: 1.7809 - val_accuracy: 0.6480\n",
      "Epoch 17/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.0407 - accuracy: 0.9870 - val_loss: 1.9869 - val_accuracy: 0.6480\n",
      "Epoch 18/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.0373 - accuracy: 0.9884 - val_loss: 2.1400 - val_accuracy: 0.6420\n",
      "Epoch 19/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.0304 - accuracy: 0.9903 - val_loss: 2.0023 - val_accuracy: 0.6650\n",
      "Epoch 20/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.0458 - accuracy: 0.9840 - val_loss: 2.0473 - val_accuracy: 0.6400\n",
      "Test loss: 3.060108184814453\n",
      "Test accuracy: 0.5490000247955322\n",
      "Epoch 1/20\n",
      "71/71 [==============================] - 1s 12ms/step - loss: 1.9028 - accuracy: 0.2909 - val_loss: 1.6175 - val_accuracy: 0.4200\n",
      "Epoch 2/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 1.4976 - accuracy: 0.4469 - val_loss: 1.5497 - val_accuracy: 0.4420\n",
      "Epoch 3/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 1.3113 - accuracy: 0.5322 - val_loss: 1.3567 - val_accuracy: 0.5290\n",
      "Epoch 4/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 1.0564 - accuracy: 0.6228 - val_loss: 1.2941 - val_accuracy: 0.5510\n",
      "Epoch 5/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.8395 - accuracy: 0.7090 - val_loss: 1.1819 - val_accuracy: 0.5980\n",
      "Epoch 6/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.6213 - accuracy: 0.7847 - val_loss: 1.1858 - val_accuracy: 0.6210\n",
      "Epoch 7/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.4586 - accuracy: 0.8456 - val_loss: 1.2660 - val_accuracy: 0.6250\n",
      "Epoch 8/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.3170 - accuracy: 0.8941 - val_loss: 1.2626 - val_accuracy: 0.6190\n",
      "Epoch 9/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.2058 - accuracy: 0.9283 - val_loss: 1.3958 - val_accuracy: 0.6400\n",
      "Epoch 10/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.1261 - accuracy: 0.9589 - val_loss: 1.7246 - val_accuracy: 0.6100\n",
      "Epoch 11/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.1307 - accuracy: 0.9572 - val_loss: 1.7266 - val_accuracy: 0.6420\n",
      "Epoch 12/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.0872 - accuracy: 0.9707 - val_loss: 1.7840 - val_accuracy: 0.6440\n",
      "Epoch 13/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.0749 - accuracy: 0.9753 - val_loss: 1.9282 - val_accuracy: 0.6440\n",
      "Epoch 14/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.0736 - accuracy: 0.9780 - val_loss: 1.8288 - val_accuracy: 0.6380\n",
      "Epoch 15/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.0433 - accuracy: 0.9856 - val_loss: 1.9018 - val_accuracy: 0.6630\n",
      "Epoch 16/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.0491 - accuracy: 0.9828 - val_loss: 1.9306 - val_accuracy: 0.6440\n",
      "Epoch 17/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.0398 - accuracy: 0.9874 - val_loss: 1.9899 - val_accuracy: 0.6310\n",
      "Epoch 18/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.0410 - accuracy: 0.9859 - val_loss: 1.9375 - val_accuracy: 0.6570\n",
      "Epoch 19/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.0328 - accuracy: 0.9890 - val_loss: 2.1622 - val_accuracy: 0.6390\n",
      "Epoch 20/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.0267 - accuracy: 0.9913 - val_loss: 2.4663 - val_accuracy: 0.6400\n",
      "Test loss: 3.526251792907715\n",
      "Test accuracy: 0.5630000233650208\n",
      "Epoch 1/20\n",
      "71/71 [==============================] - 1s 12ms/step - loss: 1.9630 - accuracy: 0.2690 - val_loss: 1.7652 - val_accuracy: 0.3880\n",
      "Epoch 2/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 1.5470 - accuracy: 0.4207 - val_loss: 1.5178 - val_accuracy: 0.4480\n",
      "Epoch 3/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 1.3182 - accuracy: 0.5290 - val_loss: 1.3492 - val_accuracy: 0.5180\n",
      "Epoch 4/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 1.1317 - accuracy: 0.5990 - val_loss: 1.2951 - val_accuracy: 0.5460\n",
      "Epoch 5/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.8765 - accuracy: 0.6950 - val_loss: 1.2284 - val_accuracy: 0.5900\n",
      "Epoch 6/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.6851 - accuracy: 0.7668 - val_loss: 1.4114 - val_accuracy: 0.5590\n",
      "Epoch 7/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.5147 - accuracy: 0.8234 - val_loss: 1.2664 - val_accuracy: 0.6040\n",
      "Epoch 8/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.3909 - accuracy: 0.8674 - val_loss: 1.2468 - val_accuracy: 0.6240\n",
      "Epoch 9/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.2607 - accuracy: 0.9126 - val_loss: 1.3939 - val_accuracy: 0.6000\n",
      "Epoch 10/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.2021 - accuracy: 0.9334 - val_loss: 1.5453 - val_accuracy: 0.6210\n",
      "Epoch 11/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.1447 - accuracy: 0.9548 - val_loss: 1.5016 - val_accuracy: 0.6220\n",
      "Epoch 12/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.1147 - accuracy: 0.9638 - val_loss: 1.5936 - val_accuracy: 0.6290\n",
      "Epoch 13/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.0856 - accuracy: 0.9719 - val_loss: 1.7144 - val_accuracy: 0.6180\n",
      "Epoch 14/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.0740 - accuracy: 0.9752 - val_loss: 1.7979 - val_accuracy: 0.6400\n",
      "Epoch 15/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.0702 - accuracy: 0.9767 - val_loss: 1.8720 - val_accuracy: 0.6260\n",
      "Epoch 16/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.0645 - accuracy: 0.9796 - val_loss: 1.9078 - val_accuracy: 0.6280\n",
      "Epoch 17/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.0537 - accuracy: 0.9849 - val_loss: 1.8875 - val_accuracy: 0.6290\n",
      "Epoch 18/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.0428 - accuracy: 0.9864 - val_loss: 2.0770 - val_accuracy: 0.6410\n",
      "Epoch 19/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.0390 - accuracy: 0.9878 - val_loss: 2.1413 - val_accuracy: 0.6200\n",
      "Epoch 20/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.0522 - accuracy: 0.9829 - val_loss: 1.9848 - val_accuracy: 0.6470\n",
      "Test loss: 2.892014980316162\n",
      "Test accuracy: 0.5649999976158142\n",
      "Epoch 1/20\n",
      "71/71 [==============================] - 1s 12ms/step - loss: 1.9140 - accuracy: 0.2844 - val_loss: 1.8613 - val_accuracy: 0.3700\n",
      "Epoch 2/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 1.5439 - accuracy: 0.4290 - val_loss: 1.4262 - val_accuracy: 0.4870\n",
      "Epoch 3/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 1.2936 - accuracy: 0.5383 - val_loss: 1.3977 - val_accuracy: 0.4970\n",
      "Epoch 4/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 1.1021 - accuracy: 0.6107 - val_loss: 1.2554 - val_accuracy: 0.5500\n",
      "Epoch 5/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.8704 - accuracy: 0.6968 - val_loss: 1.1817 - val_accuracy: 0.5880\n",
      "Epoch 6/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.6775 - accuracy: 0.7712 - val_loss: 1.2320 - val_accuracy: 0.6160\n",
      "Epoch 7/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.5044 - accuracy: 0.8311 - val_loss: 1.2904 - val_accuracy: 0.5930\n",
      "Epoch 8/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.3387 - accuracy: 0.8848 - val_loss: 1.2968 - val_accuracy: 0.6250\n",
      "Epoch 9/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.2314 - accuracy: 0.9223 - val_loss: 1.5374 - val_accuracy: 0.6270\n",
      "Epoch 10/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.1642 - accuracy: 0.9430 - val_loss: 1.6379 - val_accuracy: 0.6360\n",
      "Epoch 11/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.1467 - accuracy: 0.9507 - val_loss: 1.4974 - val_accuracy: 0.6430\n",
      "Epoch 12/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.1015 - accuracy: 0.9676 - val_loss: 1.8618 - val_accuracy: 0.6330\n",
      "Epoch 13/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.0739 - accuracy: 0.9757 - val_loss: 1.9864 - val_accuracy: 0.6440\n",
      "Epoch 14/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.0667 - accuracy: 0.9770 - val_loss: 1.8619 - val_accuracy: 0.6240\n",
      "Epoch 15/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.0608 - accuracy: 0.9810 - val_loss: 2.0346 - val_accuracy: 0.6260\n",
      "Epoch 16/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.0614 - accuracy: 0.9787 - val_loss: 1.9044 - val_accuracy: 0.6380\n",
      "Epoch 17/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.0461 - accuracy: 0.9847 - val_loss: 2.1120 - val_accuracy: 0.6500\n",
      "Epoch 18/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.0387 - accuracy: 0.9877 - val_loss: 2.1788 - val_accuracy: 0.6390\n",
      "Epoch 19/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.0385 - accuracy: 0.9866 - val_loss: 2.3474 - val_accuracy: 0.6360\n",
      "Epoch 20/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.0506 - accuracy: 0.9828 - val_loss: 2.3473 - val_accuracy: 0.6190\n",
      "Test loss: 3.101940631866455\n",
      "Test accuracy: 0.5450000166893005\n",
      "Epoch 1/20\n",
      "71/71 [==============================] - 1s 12ms/step - loss: 1.9626 - accuracy: 0.2641 - val_loss: 1.6877 - val_accuracy: 0.4120\n",
      "Epoch 2/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 1.5712 - accuracy: 0.4198 - val_loss: 1.5285 - val_accuracy: 0.4720\n",
      "Epoch 3/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 1.3549 - accuracy: 0.5081 - val_loss: 1.3436 - val_accuracy: 0.5280\n",
      "Epoch 4/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 1.1381 - accuracy: 0.5959 - val_loss: 1.2508 - val_accuracy: 0.5680\n",
      "Epoch 5/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.9149 - accuracy: 0.6829 - val_loss: 1.2483 - val_accuracy: 0.5700\n",
      "Epoch 6/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.7387 - accuracy: 0.7487 - val_loss: 1.1649 - val_accuracy: 0.6060\n",
      "Epoch 7/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.5422 - accuracy: 0.8137 - val_loss: 1.3488 - val_accuracy: 0.6090\n",
      "Epoch 8/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.4002 - accuracy: 0.8634 - val_loss: 1.2461 - val_accuracy: 0.6340\n",
      "Epoch 9/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.3106 - accuracy: 0.8980 - val_loss: 1.2842 - val_accuracy: 0.6440\n",
      "Epoch 10/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.2052 - accuracy: 0.9314 - val_loss: 1.4638 - val_accuracy: 0.6460\n",
      "Epoch 11/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.1573 - accuracy: 0.9497 - val_loss: 1.5283 - val_accuracy: 0.6580\n",
      "Epoch 12/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.1249 - accuracy: 0.9580 - val_loss: 1.7257 - val_accuracy: 0.6450\n",
      "Epoch 13/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.0929 - accuracy: 0.9697 - val_loss: 1.7574 - val_accuracy: 0.6560\n",
      "Epoch 14/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.0773 - accuracy: 0.9736 - val_loss: 1.8435 - val_accuracy: 0.6530\n",
      "Epoch 15/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.0683 - accuracy: 0.9789 - val_loss: 1.8405 - val_accuracy: 0.6600\n",
      "Epoch 16/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.0603 - accuracy: 0.9799 - val_loss: 1.8641 - val_accuracy: 0.6500\n",
      "Epoch 17/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.0491 - accuracy: 0.9834 - val_loss: 1.8578 - val_accuracy: 0.6500\n",
      "Epoch 18/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.0530 - accuracy: 0.9820 - val_loss: 1.9239 - val_accuracy: 0.6560\n",
      "Epoch 19/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.0461 - accuracy: 0.9851 - val_loss: 2.1716 - val_accuracy: 0.6270\n",
      "Epoch 20/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.0590 - accuracy: 0.9813 - val_loss: 2.0693 - val_accuracy: 0.6490\n",
      "Test loss: 2.5960559844970703\n",
      "Test accuracy: 0.574999988079071\n",
      "Epoch 1/20\n",
      "71/71 [==============================] - 1s 12ms/step - loss: 1.8962 - accuracy: 0.2828 - val_loss: 1.6870 - val_accuracy: 0.3960\n",
      "Epoch 2/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 1.4882 - accuracy: 0.4531 - val_loss: 1.4630 - val_accuracy: 0.4870\n",
      "Epoch 3/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 1.2340 - accuracy: 0.5537 - val_loss: 1.3294 - val_accuracy: 0.5310\n",
      "Epoch 4/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 1.0086 - accuracy: 0.6511 - val_loss: 1.2441 - val_accuracy: 0.5660\n",
      "Epoch 5/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.7851 - accuracy: 0.7323 - val_loss: 1.2060 - val_accuracy: 0.6010\n",
      "Epoch 6/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.5761 - accuracy: 0.8093 - val_loss: 1.2588 - val_accuracy: 0.6170\n",
      "Epoch 7/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.4059 - accuracy: 0.8601 - val_loss: 1.3631 - val_accuracy: 0.6210\n",
      "Epoch 8/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.2781 - accuracy: 0.9042 - val_loss: 1.3911 - val_accuracy: 0.6390\n",
      "Epoch 9/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.1820 - accuracy: 0.9380 - val_loss: 1.5788 - val_accuracy: 0.6190\n",
      "Epoch 10/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.1312 - accuracy: 0.9590 - val_loss: 1.6851 - val_accuracy: 0.6160\n",
      "Epoch 11/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.0992 - accuracy: 0.9642 - val_loss: 1.7405 - val_accuracy: 0.6310\n",
      "Epoch 12/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.0828 - accuracy: 0.9729 - val_loss: 1.9949 - val_accuracy: 0.6340\n",
      "Epoch 13/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.0755 - accuracy: 0.9740 - val_loss: 1.9585 - val_accuracy: 0.6140\n",
      "Epoch 14/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.0520 - accuracy: 0.9832 - val_loss: 1.9560 - val_accuracy: 0.6440\n",
      "Epoch 15/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.0523 - accuracy: 0.9859 - val_loss: 1.9365 - val_accuracy: 0.6420\n",
      "Epoch 16/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.0448 - accuracy: 0.9860 - val_loss: 1.9704 - val_accuracy: 0.6560\n",
      "Epoch 17/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.0525 - accuracy: 0.9836 - val_loss: 2.1309 - val_accuracy: 0.6370\n",
      "Epoch 18/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.0462 - accuracy: 0.9860 - val_loss: 2.1993 - val_accuracy: 0.6330\n",
      "Epoch 19/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.0310 - accuracy: 0.9897 - val_loss: 2.2011 - val_accuracy: 0.6370\n",
      "Epoch 20/20\n",
      "71/71 [==============================] - 1s 11ms/step - loss: 0.0410 - accuracy: 0.9844 - val_loss: 2.2709 - val_accuracy: 0.6240\n",
      "Test loss: 3.114283561706543\n",
      "Test accuracy: 0.5529999732971191\n"
     ]
    }
   ],
   "source": [
    "#データセットを読み込んでテンソルに変換\n",
    "\n",
    "#画像名リスト作成\n",
    "#ここで指定したディレクトリをまとめてnp配列に変換できる。\n",
    "\n",
    "#dcgan_filename = os.listdir('./10000all')\n",
    "dcgan_filename = os.listdir('./20000dcpic')\n",
    "\n",
    "true_filename = os.listdir('./Ex_5')\n",
    "\n",
    "test_filename = os.listdir('./500test')\n",
    "\n",
    "#クラスリスト作成\n",
    "#ex:\"frog\"が入ってたら6\n",
    "def makeclass(filename):\n",
    "    list1 = []\n",
    "    \n",
    "    for name in filename:\n",
    "        if \"airplane\" in name:\n",
    "            list1.append([0])\n",
    "        elif \"automobile\" in name:\n",
    "            list1.append([1])\n",
    "        elif \"bird\" in name:\n",
    "            list1.append([2])\n",
    "        elif \"cat\" in name:\n",
    "            list1.append([3])\n",
    "        elif \"deer\" in name:\n",
    "            list1.append([4])\n",
    "        elif \"dog\" in name:\n",
    "            list1.append([5])\n",
    "        elif \"frog\" in name:\n",
    "            list1.append([6])\n",
    "        elif \"horse\" in name:\n",
    "            list1.append([7])\n",
    "        elif \"ship\" in name:\n",
    "            list1.append([8])\n",
    "        elif \"truck\" in name:\n",
    "            list1.append([9])\n",
    "        else:\n",
    "            list1.append([10])\n",
    "\n",
    "            \n",
    "    #list型をnp.arrayに変換\n",
    "    classlist = np.array(list1)\n",
    "    return classlist\n",
    "\n",
    "if \".ipynb_checkpoints\" in dcgan_filename:\n",
    "    dcgan_filename.remove(\".ipynb_checkpoints\")     #いらないものを消す。\n",
    "\n",
    "if \".ipynb_checkpoints\" in true_filename:\n",
    "    true_filename.remove(\".ipynb_checkpoints\")\n",
    "\n",
    "if \".ipynb_checkpoints\" in test_filename:\n",
    "    test_filename.remove(\".ipynb_checkpoints\")\n",
    "#print(filename)\n",
    "\n",
    "\n",
    "#統計用リスト\n",
    "lskekka = []\n",
    "ackekka = []\n",
    "\n",
    "for run in range(10):\n",
    "\n",
    "    dcgan_label = makeclass(dcgan_filename)\n",
    "    true_label = makeclass(true_filename)\n",
    "    test_label = makeclass(test_filename)\n",
    "\n",
    "\n",
    "    #画像ファイルの相対パスを取得\n",
    "    dcgan_filepass = []\n",
    "    for name in dcgan_filename:\n",
    "        #dcgan_filepass.append(\"./10000all/\"+name)\n",
    "        dcgan_filepass.append(\"./20000dcpic/\"+name)\n",
    "\n",
    "\n",
    "    #print(filepass)\n",
    "\n",
    "    true_filepass = []\n",
    "    for name in true_filename:\n",
    "        true_filepass.append(\"./Ex_5/\"+name)\n",
    "\n",
    "\n",
    "    test_filepass = []\n",
    "    for name in test_filename:\n",
    "        test_filepass.append(\"./500test/\"+name)\n",
    "\n",
    "\n",
    "    #dcgan画像\n",
    "    #png画像をndarrayに変換。→一旦listに直して、imlistに追加\n",
    "    dcgan_imlist = []\n",
    "    for im in dcgan_filepass:\n",
    "        pic = np.array(Image.open(im))\n",
    "        piclist = pic.tolist()\n",
    "        dcgan_imlist.append(piclist)\n",
    "\n",
    "    #imlist（list型）をimarray（ndarray型）に変換\n",
    "    dcgan_imarray = np.array(dcgan_imlist)\n",
    "\n",
    "\n",
    "    #true画像\n",
    "    #png画像をndarrayに変換。→一旦listに直して、imlistに追加\n",
    "    true_imlist = []\n",
    "    for im in true_filepass:\n",
    "        pic = np.array(Image.open(im))\n",
    "        piclist = pic.tolist()\n",
    "        true_imlist.append(piclist)\n",
    "\n",
    "    #imlist（list型）をimarray（ndarray型）に変換\n",
    "    true_imarray = np.array(true_imlist)\n",
    "\n",
    "    #print(np.concatenate([dcgan_imarray, true_imarray]))\n",
    "\n",
    "    #test画像\n",
    "    test_imlist = []\n",
    "\n",
    "    for im in test_filepass:\n",
    "        pic = np.array(Image.open(im))\n",
    "        piclist = pic.tolist()\n",
    "        test_imlist.append(piclist)\n",
    "\n",
    "    #imlist（list型）をimarray（ndarray型）に変換\n",
    "    test_imarray = np.array(test_imlist)\n",
    "\n",
    "    #使用画像選択!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "    #Ex_2:CIFAR−１０画像+TP画像2500枚+FP画像2500枚のパターン。\n",
    "    #\n",
    "    \n",
    "    \n",
    "    xttr = true_imarray\n",
    "    yttr = true_label\n",
    "\n",
    "    xtcon = np.concatenate([true_imarray[0:5000],dcgan_imarray[0:5000]])\n",
    "    ytcon = np.concatenate([true_label[0:5000], dcgan_label[0:5000]])\n",
    "\n",
    "    (x_train, y_train) = (xttr, yttr)\n",
    "    (x_test, y_test) = (test_imarray, test_label)\n",
    "\n",
    "\n",
    "    #画像を0-1の範囲で正規化\n",
    "    x_train=x_train.astype('float32')/255.0\n",
    "    x_test=x_test.astype('float32')/255.0\n",
    "\n",
    "    #正解ラベルをOne-Hot表現に変換\n",
    "    y_train=np_utils.to_categorical(y_train,10)\n",
    "    y_test=np_utils.to_categorical(y_test,10)\n",
    "\n",
    "    #モデルを構築\n",
    "    model=Sequential()\n",
    "\n",
    "    model.add(Conv2D(64,(3,3),padding='same',input_shape=(32,32,3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64,(3,3),padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    #model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(128,(3,3),padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(128,(3,3),padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    #model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(10,activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "    history=model.fit(x_train,y_train,batch_size=128,epochs=20,verbose=1,validation_split=0.1)\n",
    "\n",
    "    #モデルと重みを保存\n",
    "    json_string=model.to_json()\n",
    "    open('cifar10_cnn.json',\"w\").write(json_string)\n",
    "    model.save_weights('cifar10_cnn.h5')\n",
    "\n",
    "    #モデルの表示\n",
    "    #model.summary()\n",
    "\n",
    "    #評価\n",
    "    score=model.evaluate(x_test,y_test,verbose=0)\n",
    "    print('Test loss:',score[0])\n",
    "    print('Test accuracy:',score[1])\n",
    "    \n",
    "    lskekka.append(score[0])\n",
    "    ackekka.append(score[1])\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6b6e72c-72a5-4151-9fd6-da5f9d92da3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.690460681915283, 2.664138078689575, 2.746957540512085, 2.855844736099243, 3.060108184814453, 3.526251792907715, 2.892014980316162, 3.101940631866455, 2.5960559844970703, 3.114283561706543]\n",
      "[0.5759999752044678, 0.5759999752044678, 0.5619999766349792, 0.550000011920929, 0.5490000247955322, 0.5630000233650208, 0.5649999976158142, 0.5450000166893005, 0.574999988079071, 0.5529999732971191]\n",
      "0.5613999962806702\n"
     ]
    }
   ],
   "source": [
    "print(lskekka)\n",
    "print(ackekka)\n",
    "\n",
    "print(np.average(ackekka))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51c48d1b-0c14-45bb-8f39-42bc85327394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    489\n",
      "1    484\n",
      "2    500\n",
      "3    474\n",
      "4    505\n",
      "5    488\n",
      "6    494\n",
      "7    521\n",
      "8    537\n",
      "9    508\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def counter(x):\n",
    "    count = [0,0,0,0,0,0,0,0,0,0]\n",
    "    for i in range(len(x)):\n",
    "        if x[i] == 0:\n",
    "            count[0] += 1\n",
    "        elif x[i] == 1:\n",
    "            count[1] += 1\n",
    "        elif x[i] == 2:\n",
    "            count[2] += 1\n",
    "        elif x[i] == 3:\n",
    "            count[3] += 1\n",
    "        elif x[i] == 4:\n",
    "            count[4] += 1\n",
    "        elif x[i] == 5:\n",
    "            count[5] += 1\n",
    "        elif x[i] == 6:\n",
    "            count[6] += 1\n",
    "        elif x[i] == 7:\n",
    "            count[7] += 1\n",
    "        elif x[i] == 8:\n",
    "            count[8] += 1\n",
    "        else:\n",
    "            count[9] += 1\n",
    "    s1 = pd.Series(count)\n",
    "    return s1\n",
    "    \n",
    "a = np_utils.to_categorical(dcgan_label[0:5000],10)\n",
    "print(counter(np.argmax(a,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719bca41-2ea6-4aab-adbc-a377cc0c5334",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
