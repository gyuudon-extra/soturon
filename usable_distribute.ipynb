{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9aa4e0e-94e0-4492-8c23-42050ff889da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-29 16:02:10.556261: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-29 16:02:10.623619: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-11-29 16:02:10.642174: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-29 16:02:10.961536: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.7/lib64:\n",
      "2022-11-29 16:02:10.961576: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.7/lib64:\n",
      "2022-11-29 16:02:10.961579: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2022-11-29 16:02:17.483817: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-29 16:02:17.501919: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-29 16:02:17.502013: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-29 16:02:17.502354: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-29 16:02:17.503106: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-29 16:02:17.503287: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-29 16:02:17.503386: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-29 16:02:17.774031: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-29 16:02:17.774157: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-29 16:02:17.774236: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-29 16:02:17.774298: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14236 MB memory:  -> device: 0, name: NVIDIA RTX A4000, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-29 16:02:18.777785: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8600\n",
      "2022-11-29 16:02:19.224176: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 2s 19ms/step - loss: 0.3544 - accuracy: 0.8904 - val_loss: 0.2928 - val_accuracy: 0.9120\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2631 - accuracy: 0.8987 - val_loss: 0.2861 - val_accuracy: 0.9120\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2590 - accuracy: 0.9004 - val_loss: 0.2147 - val_accuracy: 0.9200\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2405 - accuracy: 0.9042 - val_loss: 0.2203 - val_accuracy: 0.9260\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2360 - accuracy: 0.9060 - val_loss: 0.2397 - val_accuracy: 0.9260\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2350 - accuracy: 0.9062 - val_loss: 0.2001 - val_accuracy: 0.9360\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2132 - accuracy: 0.9082 - val_loss: 0.2086 - val_accuracy: 0.9360\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2037 - accuracy: 0.9149 - val_loss: 0.1782 - val_accuracy: 0.9320\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1895 - accuracy: 0.9202 - val_loss: 0.1774 - val_accuracy: 0.9380\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1696 - accuracy: 0.9320 - val_loss: 0.2265 - val_accuracy: 0.9180\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1567 - accuracy: 0.9331 - val_loss: 0.2509 - val_accuracy: 0.8900\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1512 - accuracy: 0.9422 - val_loss: 0.1640 - val_accuracy: 0.9320\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1185 - accuracy: 0.9527 - val_loss: 0.1637 - val_accuracy: 0.9420\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1209 - accuracy: 0.9520 - val_loss: 0.1634 - val_accuracy: 0.9380\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0998 - accuracy: 0.9596 - val_loss: 0.1535 - val_accuracy: 0.9420\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0693 - accuracy: 0.9733 - val_loss: 0.1982 - val_accuracy: 0.9460\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0513 - accuracy: 0.9809 - val_loss: 0.1584 - val_accuracy: 0.9540\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0337 - accuracy: 0.9893 - val_loss: 0.2124 - val_accuracy: 0.9540\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0477 - accuracy: 0.9807 - val_loss: 0.2022 - val_accuracy: 0.9520\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0261 - accuracy: 0.9900 - val_loss: 0.1883 - val_accuracy: 0.9300\n",
      "Test loss: 0.3418448269367218\n",
      "Test accuracy: 0.9110000133514404\n",
      "63/63 [==============================] - 0s 2ms/step\n",
      "0.8195\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 13ms/step - loss: 0.3555 - accuracy: 0.8853 - val_loss: 0.2828 - val_accuracy: 0.9120\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2626 - accuracy: 0.8987 - val_loss: 0.2547 - val_accuracy: 0.9120\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2468 - accuracy: 0.9009 - val_loss: 0.2455 - val_accuracy: 0.9280\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2353 - accuracy: 0.9047 - val_loss: 0.2204 - val_accuracy: 0.9180\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2288 - accuracy: 0.9084 - val_loss: 0.2565 - val_accuracy: 0.9140\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2175 - accuracy: 0.9100 - val_loss: 0.1946 - val_accuracy: 0.9380\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1981 - accuracy: 0.9191 - val_loss: 0.1863 - val_accuracy: 0.9380\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1868 - accuracy: 0.9249 - val_loss: 0.1943 - val_accuracy: 0.9220\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1678 - accuracy: 0.9276 - val_loss: 0.1783 - val_accuracy: 0.9440\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1529 - accuracy: 0.9342 - val_loss: 0.1753 - val_accuracy: 0.9360\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1501 - accuracy: 0.9391 - val_loss: 0.2065 - val_accuracy: 0.9220\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1389 - accuracy: 0.9429 - val_loss: 0.1698 - val_accuracy: 0.9360\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1067 - accuracy: 0.9569 - val_loss: 0.2219 - val_accuracy: 0.9200\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0994 - accuracy: 0.9598 - val_loss: 0.1665 - val_accuracy: 0.9460\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0840 - accuracy: 0.9640 - val_loss: 0.1646 - val_accuracy: 0.9460\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0658 - accuracy: 0.9731 - val_loss: 0.2278 - val_accuracy: 0.9360\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0510 - accuracy: 0.9802 - val_loss: 0.1871 - val_accuracy: 0.9540\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0369 - accuracy: 0.9862 - val_loss: 0.2236 - val_accuracy: 0.9380\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0203 - accuracy: 0.9920 - val_loss: 0.2952 - val_accuracy: 0.9440\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0292 - accuracy: 0.9896 - val_loss: 0.2821 - val_accuracy: 0.9440\n",
      "Test loss: 0.601668655872345\n",
      "Test accuracy: 0.921999990940094\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.551\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 13ms/step - loss: 0.3462 - accuracy: 0.8913 - val_loss: 0.2960 - val_accuracy: 0.9120\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2649 - accuracy: 0.8987 - val_loss: 0.2561 - val_accuracy: 0.9120\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2478 - accuracy: 0.9022 - val_loss: 0.2237 - val_accuracy: 0.9220\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2296 - accuracy: 0.9069 - val_loss: 0.2382 - val_accuracy: 0.9300\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2350 - accuracy: 0.9102 - val_loss: 0.2348 - val_accuracy: 0.9020\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2174 - accuracy: 0.9138 - val_loss: 0.1963 - val_accuracy: 0.9360\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2041 - accuracy: 0.9158 - val_loss: 0.1868 - val_accuracy: 0.9340\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1930 - accuracy: 0.9191 - val_loss: 0.2124 - val_accuracy: 0.9280\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1956 - accuracy: 0.9167 - val_loss: 0.1898 - val_accuracy: 0.9380\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1732 - accuracy: 0.9249 - val_loss: 0.1895 - val_accuracy: 0.9320\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1578 - accuracy: 0.9318 - val_loss: 0.2190 - val_accuracy: 0.9380\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1511 - accuracy: 0.9333 - val_loss: 0.1993 - val_accuracy: 0.9220\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1378 - accuracy: 0.9440 - val_loss: 0.2057 - val_accuracy: 0.9460\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1223 - accuracy: 0.9502 - val_loss: 0.2197 - val_accuracy: 0.9280\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1011 - accuracy: 0.9616 - val_loss: 0.1742 - val_accuracy: 0.9400\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0883 - accuracy: 0.9667 - val_loss: 0.2010 - val_accuracy: 0.9320\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0748 - accuracy: 0.9724 - val_loss: 0.2641 - val_accuracy: 0.9440\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0623 - accuracy: 0.9764 - val_loss: 0.2754 - val_accuracy: 0.9280\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0519 - accuracy: 0.9809 - val_loss: 0.2000 - val_accuracy: 0.9420\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0304 - accuracy: 0.9900 - val_loss: 0.2540 - val_accuracy: 0.9280\n",
      "Test loss: 0.4346124231815338\n",
      "Test accuracy: 0.8989999890327454\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.817\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 13ms/step - loss: 0.3788 - accuracy: 0.8916 - val_loss: 0.2935 - val_accuracy: 0.9120\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.3039 - accuracy: 0.8987 - val_loss: 0.3000 - val_accuracy: 0.9120\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2672 - accuracy: 0.8993 - val_loss: 0.2549 - val_accuracy: 0.9160\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2482 - accuracy: 0.9047 - val_loss: 0.2390 - val_accuracy: 0.9220\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2363 - accuracy: 0.9107 - val_loss: 0.2442 - val_accuracy: 0.9200\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2275 - accuracy: 0.9129 - val_loss: 0.2162 - val_accuracy: 0.9180\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2074 - accuracy: 0.9151 - val_loss: 0.2122 - val_accuracy: 0.9300\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2064 - accuracy: 0.9171 - val_loss: 0.1994 - val_accuracy: 0.9320\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1872 - accuracy: 0.9204 - val_loss: 0.1933 - val_accuracy: 0.9400\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1697 - accuracy: 0.9269 - val_loss: 0.1876 - val_accuracy: 0.9280\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1586 - accuracy: 0.9331 - val_loss: 0.1781 - val_accuracy: 0.9340\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1481 - accuracy: 0.9387 - val_loss: 0.1802 - val_accuracy: 0.9360\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1210 - accuracy: 0.9524 - val_loss: 0.1782 - val_accuracy: 0.9320\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1186 - accuracy: 0.9549 - val_loss: 0.1889 - val_accuracy: 0.9420\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0978 - accuracy: 0.9607 - val_loss: 0.1838 - val_accuracy: 0.9500\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0741 - accuracy: 0.9707 - val_loss: 0.2504 - val_accuracy: 0.9380\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0588 - accuracy: 0.9738 - val_loss: 0.2456 - val_accuracy: 0.9480\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0496 - accuracy: 0.9798 - val_loss: 0.2632 - val_accuracy: 0.9460\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0335 - accuracy: 0.9864 - val_loss: 0.2705 - val_accuracy: 0.9340\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0255 - accuracy: 0.9898 - val_loss: 0.3663 - val_accuracy: 0.9300\n",
      "Test loss: 0.4479944705963135\n",
      "Test accuracy: 0.9179999828338623\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.8865\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 13ms/step - loss: 0.3513 - accuracy: 0.8798 - val_loss: 0.3127 - val_accuracy: 0.9120\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2876 - accuracy: 0.8987 - val_loss: 0.2590 - val_accuracy: 0.9120\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2714 - accuracy: 0.8987 - val_loss: 0.2424 - val_accuracy: 0.9120\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2592 - accuracy: 0.9011 - val_loss: 0.2310 - val_accuracy: 0.9180\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2317 - accuracy: 0.9080 - val_loss: 0.2139 - val_accuracy: 0.9200\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2198 - accuracy: 0.9138 - val_loss: 0.2018 - val_accuracy: 0.9240\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2162 - accuracy: 0.9140 - val_loss: 0.2093 - val_accuracy: 0.9380\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2061 - accuracy: 0.9162 - val_loss: 0.1959 - val_accuracy: 0.9300\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1851 - accuracy: 0.9198 - val_loss: 0.1774 - val_accuracy: 0.9400\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1661 - accuracy: 0.9309 - val_loss: 0.2160 - val_accuracy: 0.9300\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1607 - accuracy: 0.9351 - val_loss: 0.1885 - val_accuracy: 0.9420\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1443 - accuracy: 0.9364 - val_loss: 0.1760 - val_accuracy: 0.9320\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1260 - accuracy: 0.9456 - val_loss: 0.1939 - val_accuracy: 0.9260\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1119 - accuracy: 0.9540 - val_loss: 0.1981 - val_accuracy: 0.9220\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0862 - accuracy: 0.9642 - val_loss: 0.1894 - val_accuracy: 0.9380\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0830 - accuracy: 0.9667 - val_loss: 0.1940 - val_accuracy: 0.9480\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0553 - accuracy: 0.9813 - val_loss: 0.1956 - val_accuracy: 0.9520\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0501 - accuracy: 0.9787 - val_loss: 0.2162 - val_accuracy: 0.9480\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0269 - accuracy: 0.9907 - val_loss: 0.2883 - val_accuracy: 0.9480\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0235 - accuracy: 0.9920 - val_loss: 0.2351 - val_accuracy: 0.9240\n",
      "Test loss: 0.38812580704689026\n",
      "Test accuracy: 0.9169999957084656\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.8635\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 13ms/step - loss: 0.3555 - accuracy: 0.8920 - val_loss: 0.2898 - val_accuracy: 0.9120\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2823 - accuracy: 0.8987 - val_loss: 0.3062 - val_accuracy: 0.9120\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2628 - accuracy: 0.8989 - val_loss: 0.2499 - val_accuracy: 0.9240\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2492 - accuracy: 0.9022 - val_loss: 0.2327 - val_accuracy: 0.9300\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2342 - accuracy: 0.9118 - val_loss: 0.2115 - val_accuracy: 0.9240\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2183 - accuracy: 0.9171 - val_loss: 0.2014 - val_accuracy: 0.9260\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2152 - accuracy: 0.9156 - val_loss: 0.2171 - val_accuracy: 0.9320\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1963 - accuracy: 0.9204 - val_loss: 0.1993 - val_accuracy: 0.9160\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1904 - accuracy: 0.9258 - val_loss: 0.1578 - val_accuracy: 0.9380\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1652 - accuracy: 0.9336 - val_loss: 0.1704 - val_accuracy: 0.9320\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1483 - accuracy: 0.9409 - val_loss: 0.1588 - val_accuracy: 0.9480\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1317 - accuracy: 0.9478 - val_loss: 0.1646 - val_accuracy: 0.9440\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1133 - accuracy: 0.9524 - val_loss: 0.1687 - val_accuracy: 0.9380\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0956 - accuracy: 0.9607 - val_loss: 0.1859 - val_accuracy: 0.9480\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0753 - accuracy: 0.9680 - val_loss: 0.1676 - val_accuracy: 0.9500\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0622 - accuracy: 0.9744 - val_loss: 0.1720 - val_accuracy: 0.9540\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0395 - accuracy: 0.9836 - val_loss: 0.1975 - val_accuracy: 0.9400\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0553 - accuracy: 0.9813 - val_loss: 0.2020 - val_accuracy: 0.9420\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0362 - accuracy: 0.9876 - val_loss: 0.2522 - val_accuracy: 0.9540\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0242 - accuracy: 0.9920 - val_loss: 0.2930 - val_accuracy: 0.9460\n",
      "Test loss: 0.5558624267578125\n",
      "Test accuracy: 0.9210000038146973\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.7885\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3178 - accuracy: 0.8880 - val_loss: 0.2873 - val_accuracy: 0.9120\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2688 - accuracy: 0.8984 - val_loss: 0.2951 - val_accuracy: 0.9120\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2576 - accuracy: 0.9009 - val_loss: 0.2154 - val_accuracy: 0.9180\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2341 - accuracy: 0.9060 - val_loss: 0.2326 - val_accuracy: 0.9240\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2294 - accuracy: 0.9087 - val_loss: 0.2420 - val_accuracy: 0.9220\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2112 - accuracy: 0.9149 - val_loss: 0.1817 - val_accuracy: 0.9440\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1890 - accuracy: 0.9222 - val_loss: 0.1726 - val_accuracy: 0.9380\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1758 - accuracy: 0.9253 - val_loss: 0.1689 - val_accuracy: 0.9420\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1538 - accuracy: 0.9331 - val_loss: 0.1923 - val_accuracy: 0.9540\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1388 - accuracy: 0.9418 - val_loss: 0.1393 - val_accuracy: 0.9520\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1199 - accuracy: 0.9498 - val_loss: 0.1278 - val_accuracy: 0.9580\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0936 - accuracy: 0.9636 - val_loss: 0.1836 - val_accuracy: 0.9160\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0812 - accuracy: 0.9684 - val_loss: 0.1409 - val_accuracy: 0.9520\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0729 - accuracy: 0.9718 - val_loss: 0.1668 - val_accuracy: 0.9160\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0760 - accuracy: 0.9698 - val_loss: 0.1466 - val_accuracy: 0.9540\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0629 - accuracy: 0.9767 - val_loss: 0.1459 - val_accuracy: 0.9540\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0356 - accuracy: 0.9871 - val_loss: 0.1665 - val_accuracy: 0.9540\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0834 - accuracy: 0.9722 - val_loss: 0.1391 - val_accuracy: 0.9440\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0377 - accuracy: 0.9898 - val_loss: 0.1458 - val_accuracy: 0.9600\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0132 - accuracy: 0.9960 - val_loss: 0.1767 - val_accuracy: 0.9560\n",
      "Test loss: 0.4574209451675415\n",
      "Test accuracy: 0.9300000071525574\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.705\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3637 - accuracy: 0.8964 - val_loss: 0.3193 - val_accuracy: 0.9120\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2866 - accuracy: 0.8987 - val_loss: 0.2579 - val_accuracy: 0.9120\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2543 - accuracy: 0.9038 - val_loss: 0.2431 - val_accuracy: 0.9200\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2464 - accuracy: 0.9018 - val_loss: 0.2184 - val_accuracy: 0.9300\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2338 - accuracy: 0.9104 - val_loss: 0.2393 - val_accuracy: 0.9260\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2188 - accuracy: 0.9116 - val_loss: 0.2386 - val_accuracy: 0.9060\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2271 - accuracy: 0.9098 - val_loss: 0.1853 - val_accuracy: 0.9260\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2033 - accuracy: 0.9164 - val_loss: 0.2135 - val_accuracy: 0.9240\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1894 - accuracy: 0.9220 - val_loss: 0.1740 - val_accuracy: 0.9360\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1657 - accuracy: 0.9293 - val_loss: 0.1634 - val_accuracy: 0.9380\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1592 - accuracy: 0.9351 - val_loss: 0.2097 - val_accuracy: 0.9120\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1677 - accuracy: 0.9338 - val_loss: 0.1423 - val_accuracy: 0.9460\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1234 - accuracy: 0.9453 - val_loss: 0.1671 - val_accuracy: 0.9440\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1071 - accuracy: 0.9544 - val_loss: 0.1368 - val_accuracy: 0.9520\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0956 - accuracy: 0.9607 - val_loss: 0.1365 - val_accuracy: 0.9540\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0826 - accuracy: 0.9669 - val_loss: 0.1823 - val_accuracy: 0.9200\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0941 - accuracy: 0.9611 - val_loss: 0.1688 - val_accuracy: 0.9380\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0516 - accuracy: 0.9798 - val_loss: 0.1871 - val_accuracy: 0.9320\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0530 - accuracy: 0.9800 - val_loss: 0.2039 - val_accuracy: 0.9420\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0386 - accuracy: 0.9856 - val_loss: 0.1939 - val_accuracy: 0.9420\n",
      "Test loss: 0.3813258111476898\n",
      "Test accuracy: 0.921999990940094\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.57\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3322 - accuracy: 0.8791 - val_loss: 0.2898 - val_accuracy: 0.9120\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2619 - accuracy: 0.8987 - val_loss: 0.2447 - val_accuracy: 0.9120\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2412 - accuracy: 0.9042 - val_loss: 0.2392 - val_accuracy: 0.9260\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2323 - accuracy: 0.9091 - val_loss: 0.2112 - val_accuracy: 0.9240\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2191 - accuracy: 0.9093 - val_loss: 0.2015 - val_accuracy: 0.9260\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2047 - accuracy: 0.9169 - val_loss: 0.1910 - val_accuracy: 0.9340\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1914 - accuracy: 0.9191 - val_loss: 0.1971 - val_accuracy: 0.9220\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1734 - accuracy: 0.9258 - val_loss: 0.1906 - val_accuracy: 0.9260\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1700 - accuracy: 0.9302 - val_loss: 0.2300 - val_accuracy: 0.8880\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1486 - accuracy: 0.9347 - val_loss: 0.2398 - val_accuracy: 0.9340\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1376 - accuracy: 0.9402 - val_loss: 0.1909 - val_accuracy: 0.9220\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1105 - accuracy: 0.9540 - val_loss: 0.1610 - val_accuracy: 0.9520\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0803 - accuracy: 0.9680 - val_loss: 0.1910 - val_accuracy: 0.9380\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0655 - accuracy: 0.9733 - val_loss: 0.1883 - val_accuracy: 0.9500\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0637 - accuracy: 0.9744 - val_loss: 0.2424 - val_accuracy: 0.9400\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0407 - accuracy: 0.9856 - val_loss: 0.1960 - val_accuracy: 0.9480\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0358 - accuracy: 0.9849 - val_loss: 0.2694 - val_accuracy: 0.9540\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0293 - accuracy: 0.9876 - val_loss: 0.2254 - val_accuracy: 0.9320\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0282 - accuracy: 0.9913 - val_loss: 0.2455 - val_accuracy: 0.9440\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0516 - accuracy: 0.9789 - val_loss: 0.1955 - val_accuracy: 0.9500\n",
      "Test loss: 0.39376431703567505\n",
      "Test accuracy: 0.9169999957084656\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.6665\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3209 - accuracy: 0.8871 - val_loss: 0.2811 - val_accuracy: 0.9120\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2592 - accuracy: 0.8987 - val_loss: 0.2411 - val_accuracy: 0.9180\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2379 - accuracy: 0.9033 - val_loss: 0.2980 - val_accuracy: 0.8660\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2428 - accuracy: 0.8989 - val_loss: 0.1940 - val_accuracy: 0.9280\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2125 - accuracy: 0.9118 - val_loss: 0.2011 - val_accuracy: 0.9380\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2088 - accuracy: 0.9129 - val_loss: 0.1868 - val_accuracy: 0.9400\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1990 - accuracy: 0.9178 - val_loss: 0.1845 - val_accuracy: 0.9340\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1831 - accuracy: 0.9218 - val_loss: 0.1841 - val_accuracy: 0.9380\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1719 - accuracy: 0.9267 - val_loss: 0.1729 - val_accuracy: 0.9340\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1495 - accuracy: 0.9324 - val_loss: 0.1799 - val_accuracy: 0.9420\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1267 - accuracy: 0.9458 - val_loss: 0.1649 - val_accuracy: 0.9540\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1055 - accuracy: 0.9562 - val_loss: 0.1807 - val_accuracy: 0.9520\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1232 - accuracy: 0.9469 - val_loss: 0.1665 - val_accuracy: 0.9460\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0739 - accuracy: 0.9707 - val_loss: 0.2451 - val_accuracy: 0.9420\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0745 - accuracy: 0.9722 - val_loss: 0.2013 - val_accuracy: 0.9500\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0552 - accuracy: 0.9791 - val_loss: 0.2174 - val_accuracy: 0.9400\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0342 - accuracy: 0.9871 - val_loss: 0.3020 - val_accuracy: 0.9480\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0531 - accuracy: 0.9789 - val_loss: 0.2752 - val_accuracy: 0.9400\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0301 - accuracy: 0.9907 - val_loss: 0.3104 - val_accuracy: 0.9440\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0336 - accuracy: 0.9864 - val_loss: 0.2398 - val_accuracy: 0.9380\n",
      "Test loss: 0.3886253535747528\n",
      "Test accuracy: 0.9020000100135803\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.743\n",
      "      通し番号  カウント\n",
      "0        0     6\n",
      "1        1    10\n",
      "2        2     4\n",
      "3        3    10\n",
      "4        4    10\n",
      "...    ...   ...\n",
      "1995  1995    10\n",
      "1996  1996     4\n",
      "1997  1997     7\n",
      "1998  1998     9\n",
      "1999  1999     2\n",
      "\n",
      "[2000 rows x 2 columns]\n",
      "[0.8195, 0.551, 0.817, 0.8865, 0.8635, 0.7885, 0.705, 0.57, 0.6665, 0.743]\n",
      "11\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[318, 1443, 1497, 1499, 277, 1502, 256, 892, 1554, 250, 240, 233, 1441, 203, 1629, 169, 114, 1664, 1669, 63, 20, 1804, 378, 506, 1378, 1283, 820, 814, 922, 1935, 776, 1004, 1009, 1019, 735, 707, 680, 665, 1946, 661, 1049, 634, 631, 1050, 595, 1102, 530, 1156, 1203, 511, 508, 1896, 441, 1928, 1955, 1938, 395, 835, 360, 564, 49, 573, 501, 423, 89, 387, 99, 525, 638, 623, 126, 290, 142, 468, 1839, 1000, 1560, 1475, 1135, 1145, 1644, 1659, 1047, 1086, 894, 1223, 1663, 983, 1748, 1773, 908, 1922, 1265, 906, 1079, 1926, 1866, 1913, 1874, 1916, 1855, 1999, 1849, 1085, 1386, 1374, 418, 856, 1278, 1232, 1226, 1220, 514, 1175, 1103, 588, 615, 1432, 1056, 1054, 728, 741, 768, 784, 935, 786, 912, 795, 819, 897, 1429, 1279, 1439, 254, 1832, 11, 27, 1724, 1707, 1679, 104, 1645, 193, 1597, 225, 1610, 261, 327, 1466, 1472, 311, 87, 1894, 276, 1465, 262, 123, 1324, 121, 80, 1487, 22, 1300, 24, 78, 1401, 215, 1393, 199, 1286, 1471, 1385, 45, 1888, 166, 771, 1120, 1205, 919, 1202, 1962, 986, 984, 524, 975, 534, 539, 1568, 1688, 552, 939, 565, 613, 466, 904, 626, 1949, 1598, 865, 662, 1422, 854, 1870, 721, 743, 793, 1619, 490, 1875, 1026, 1547, 1200, 1185, 1860, 1178, 326, 1168, 1765, 1508, 1511, 365, 370, 1902, 1139, 374, 1750, 1735, 1967, 1719, 1055, 1537, 1096, 1109, 386, 1854, 409, 1128, 401, 1134, 482, 164, 133, 147, 1905, 1818, 1549, 150, 1091, 432, 1075, 1814, 450, 1015, 1519, 1123, 1742, 1215, 1228, 264, 1976, 1777, 1195, 308, 1234, 1241, 317, 330, 236, 1167, 1256, 1261, 1755, 1136, 1752, 384, 1287, 1291, 183, 1710, 397, 1292, 483, 1219, 127, 864, 1671, 53, 915, 1352, 493, 1592, 43, 1657, 1656, 639, 866, 663, 1996, 692, 569, 694, 710, 841, 1446, 836, 829, 1611, 813, 1412, 744, 1614, 2, 779, 1344, 618, 928, 122, 105, 970, 1676, 513, 1562, 77, 505, 969, 958, 528, 550, 1341, 1704, 554, 1681, 952, 340, 668, 414, 68, 1717, 643, 716, 641, 425, 1733, 1660, 110, 1944, 1842, 50, 406, 627, 42, 1741, 731, 739, 404, 1631, 1763, 14, 358, 371, 377, 759, 115, 137, 120, 1703, 1691, 527, 201, 510, 303, 438, 288, 1715, 287, 251, 1706, 492, 1720, 281, 373, 1687, 545, 309, 433, 1802, 184, 559, 176, 172, 1677, 162, 1729, 430, 600, 145, 1772, 372, 1430, 1264, 1101, 1327, 1119, 1154, 873, 1267, 1541, 1137, 884, 901, 1889, 968, 1162, 1923, 1111, 1133, 1131, 1880, 1294, 1342, 1461, 942, 1576, 1410, 775, 1314, 1199, 1878, 816, 1021, 1249, 796, 1413, 1037, 791, 1318, 849, 1305, 1900, 1040, 1914, 1044, 1807, 1857, 1754, 1464, 1852, 1746, 1877, 1701, 1881, 1564, 1853, 1591, 1460, 1790, 1831, 1605, 1692, 1871, 1740, 1781, 1477, 1640, 1684, 1527, 1523, 1555, 1793, 1603, 1646, 1512, 1863, 1705, 1480, 1858, 1601, 0, 667, 1140, 1028, 465, 1022, 473, 500, 1013, 1007, 995, 502, 992, 509, 991, 521, 542, 962, 452, 448, 1046, 1106, 390, 392, 403, 1129, 1121, 408, 426, 444, 762, 1088, 437, 1063, 1057, 442, 549, 954, 556, 1940, 1927, 718, 840, 723, 1929, 726, 808, 652, 803, 745, 748, 752, 756, 789, 861, 651, 947, 913, 945, 560, 567, 584, 597, 914, 608, 874, 621, 898, 896, 633, 635, 883, 1971, 428, 195, 1984, 148, 154, 188, 1275, 1269, 222, 1253, 280, 228, 1242, 237, 1981, 266, 269, 1306, 101, 76, 73, 72, 1347, 52, 51, 1384, 1399, 37, 1405, 1409, 35, 13, 6, 1417, 1977, 777, 301, 354, 324, 1179, 1171, 339, 1159, 289, 1187, 1469, 1433, 1473, 26, 1343, 446, 1965, 1434, 1847, 1244, 421, 1435, 1391, 1731, 1997, 40, 1451, 46, 1268, 1833, 1415, 440, 1365, 29, 1845, 9, 1368, 1258, 7, 56, 1311, 1483, 1448, 1288, 1373, 1428, 1309, 417, 1419, 574, 1486, 855, 242, 834, 243, 244, 831, 1958, 248, 822, 812, 1979, 1978, 1789, 797, 1620, 781, 778, 271, 1785, 761, 844, 1983, 980, 867, 978, 977, 972, 1567, 1803, 189, 1236, 206, 516, 214, 218, 1925, 890, 888, 880, 876, 1695, 1969, 394, 754, 1628, 286, 742, 343, 562, 625, 1753, 619, 1972, 361, 602, 599, 1674, 1761, 590, 368, 1954, 369, 571, 579, 1756, 572, 644, 1767, 561, 702, 1779, 1635, 733, 306, 551, 1775, 705, 703, 1975, 333, 698, 315, 682, 1678, 332, 656, 655, 653, 979, 1800, 180, 1078, 1155, 488, 1146, 1142, 1989, 1130, 1124, 1525, 131, 1819, 134, 1817, 402, 1099, 1097, 1533, 1092, 1534, 1089, 1510, 1738, 1164, 1495, 470, 1224, 1897, 1222, 1216, 1214, 475, 1207, 102, 1166, 103, 1190, 1188, 1501, 1503, 1712, 1711, 1507, 1816, 139, 1557, 1912, 1016, 167, 1002, 1027, 1548, 1035, 1038, 1544, 1543, 1542, 998, 994, 1010, 1052, 1744, 1536, 1074, 149, 153, 1053, 158, 157, 985, 990, 143, 1520, 1280, 1602, 800, 1585, 32, 853, 1077, 128, 1835, 1277, 235, 802, 640, 70, 342, 1948, 1276, 1138, 1813, 1298, 1515, 1882, 344, 345, 62, 1647, 1362, 1648, 335, 141, 491, 664, 1973, 1293, 144, 1358, 329, 660, 1095, 66, 1768, 1098, 331, 1285, 1083, 334, 1104, 1296, 135, 1411, 1081, 1513, 1836, 1709, 1445, 1113, 69, 1115, 794, 1529, 769, 1418, 477, 1980, 1370, 1212, 1883, 1210, 591, 1968, 436, 366, 1670, 362, 1828, 81, 1255, 1991, 1485, 1217, 93, 1233, 1240, 1792, 1238, 1237, 821, 1436, 1230, 1898, 1229, 570, 249, 472, 815, 92, 1827, 1456, 1377, 601, 1665, 842, 116, 1479, 1270, 536, 31, 419, 845, 351, 1273, 379, 1150, 629, 1599, 259, 241, 838, 1762, 1257, 1500, 1184, 1183, 359, 1367, 1608, 616, 356, 355, 1675, 1826, 1667, 1375, 1600, 1994, 152, 1780, 1383, 1859, 185, 1570, 186, 966, 213, 964, 1452, 1571, 1392, 1721, 190, 1572, 191, 1805, 1699, 1566, 893, 1326, 719, 1639, 722, 38, 724, 424, 1941, 1621, 1617, 39, 293, 1862, 1622, 192, 1573, 1351, 1861, 278, 760, 929, 1459, 1581, 1454, 911, 541, 1920, 275, 921, 205, 1582, 767, 207, 1985, 1784, 909, 197, 1782, 773, 746, 1587, 1388, 196, 1970, 274, 273, 211, 940, 282, 938, 1697, 19, 1030, 173, 1643, 1404, 1550, 312, 1313, 1791, 678, 1964, 871, 1032, 268, 1058, 783, 1407, 878, 553, 1682, 555, 1406, 1041, 1910, 319, 1722, 1043, 1974, 1911, 538, 422, 1596, 1403, 382, 1808, 1014, 885, 713, 455, 1003, 1558, 504, 712, 785, 1008, 1690, 1966, 220, 1357, 701, 221, 33, 673, 704, 1316, 1402, 1553, 381, 1017, 1538, 948, 963, 943, 47, 1335, 1700, 1841, 44, 187, 1579, 949, 451, 1745, 1462, 194, 941, 951, 950, 953, 1329, 1332, 982, 456, 1020, 1018, 1837, 1012, 1011, 1319, 575, 1006, 1001, 1321, 454, 1325, 174, 175, 1806, 1561, 1563, 1463, 989, 988, 177, 1328, 1960, 1331, 937, 1580, 515, 223, 447, 226, 869, 229, 863, 1694, 231, 1693, 858, 1359, 1360, 529, 1794, 238, 239, 1982, 843, 30, 839, 1607, 245, 1609, 827, 247, 824, 523, 522, 202, 1594, 931, 204, 1024, 926, 925, 924, 923, 1919, 917, 1583, 208, 1829, 517, 905, 903, 212, 900, 398, 519, 1348, 1349, 891, 889, 886, 1593, 165, 936, 1025, 1163, 1260, 1177, 480, 1504, 481, 112, 1505, 79, 1263, 1506, 75, 1165, 1158, 1517, 1739, 1901, 1272, 487, 1823, 1822, 1148, 1147, 1274, 1821, 124, 125, 1876, 411, 412, 1182, 469, 1235, 1489, 1490, 1245, 1491, 1895, 1714, 1492, 1737, 1250, 95, 474, 1209, 98, 1204, 1899, 1484, 100, 1198, 1192, 1191, 1189, 1186, 463, 1514, 1903, 55, 60, 1301, 1811, 1066, 495, 156, 1302, 1061, 1060, 1059, 1303, 1909, 1540, 1051, 1518, 459, 496, 1308, 1045, 1042, 1545, 497, 1736, 498, 499, 531, 1029, 151, 1812, 1072, 1815, 1132, 1820, 1522, 1125, 71, 130, 1122, 1526, 1118, 1117, 1116, 1112, 1108, 1284, 1105, 1476, 1289, 67, 140, 1093, 65, 1090, 1535, 64, 494, 1033, 1921, 817, 693, 1778, 1396, 1776, 304, 305, 17, 16, 696, 695, 690, 1685, 689, 439, 316, 686, 320, 321, 677, 675, 558, 717, 1638, 380, 1390, 763, 21, 1627, 1783, 1887, 388, 750, 285, 1389, 738, 299, 291, 292, 734, 1394, 1686, 296, 385, 1751, 1637, 1770, 670, 1939, 1425, 1666, 617, 1952, 353, 566, 607, 606, 8, 1865, 364, 620, 1431, 1885, 586, 585, 1672, 1673, 1757, 435, 576, 1421, 622, 429, 645, 666, 1945, 328, 1447, 654, 12, 336, 337, 1998, 10, 1420, 1766, 341, 1654, 1868, 346, 348, 349, 1867, 624, 765, 1488, 782, 799, 1624, 267, 1747, 1616, 1848, 1723, 1623, 1932, 391, 801, 780, 1381, 270, 1376, 1933, 537, 792, 265, 927, 749, 730, 1636, 732, 736, 737, 740, 1634, 1633, 1632, 1630, 747, 751, 1727, 753, 755, 757, 758, 1626, 1625, 764, 766, 770, 772, 774, 729, 1942, 727, 725, 676, 679, 681, 683, 684, 685, 687, 688, 691, 1869, 697, 699, 700, 706, 1943, 708, 709, 1642, 711, 714, 715, 1641, 1440, 1937, 1936, 1934, 837, 846, 847, 848, 1604, 850, 851, 852, 857, 859, 860, 862, 1873, 868, 870, 872, 1595, 875, 877, 879, 881, 882, 887, 895, 1606, 833, 787, 832, 788, 790, 1618, 798, 1615, 804, 805, 806, 807, 1613, 809, 810, 811, 1612, 1872, 818, 1931, 1930, 823, 825, 826, 828, 830, 674, 672, 671, 1702, 1963, 507, 1698, 1961, 512, 518, 520, 1696, 1959, 526, 532, 533, 535, 540, 1689, 543, 544, 546, 547, 548, 1683, 1680, 557, 503, 1708, 563, 489, 1726, 1725, 443, 445, 449, 1718, 453, 457, 458, 460, 461, 462, 464, 1716, 467, 471, 1713, 476, 478, 479, 484, 485, 486, 1864, 1957, 669, 1662, 630, 1950, 632, 1661, 1658, 636, 637, 1655, 642, 1653, 646, 647, 648, 649, 650, 1652, 1651, 657, 658, 659, 1947, 1650, 1649, 628, 1951, 568, 614, 1956, 577, 578, 580, 581, 582, 583, 587, 589, 592, 593, 594, 1953, 596, 598, 603, 604, 605, 1668, 609, 610, 611, 612, 1590, 1924, 1589, 1259, 1262, 1481, 1893, 1266, 1271, 1478, 1892, 1891, 1281, 1282, 1890, 1290, 1879, 1474, 1295, 1297, 1299, 1470, 1304, 1468, 1307, 1310, 1312, 1482, 1254, 1315, 1252, 1194, 1196, 1197, 1498, 1496, 1201, 1494, 1206, 1208, 1211, 1213, 1493, 1218, 1221, 1225, 1227, 1231, 1239, 1243, 1246, 1247, 1248, 1251, 1467, 1317, 1181, 1372, 1379, 1380, 1382, 1453, 1387, 1395, 1397, 1398, 1400, 1450, 1449, 1408, 1444, 1414, 1416, 1442, 1423, 1424, 1426, 1427, 1886, 1437, 1438, 1455, 1371, 1320, 1369, 1322, 1323, 1330, 1333, 1334, 1336, 1337, 1338, 1339, 1340, 1345, 1346, 1458, 1350, 1457, 1353, 1354, 1355, 1356, 1361, 1363, 1364, 1366, 1193, 1180, 899, 961, 967, 1569, 971, 973, 974, 976, 981, 1917, 1565, 987, 993, 1559, 996, 997, 999, 1, 1005, 1915, 1556, 1552, 1551, 1023, 1031, 965, 960, 1036, 959, 1588, 902, 1586, 907, 910, 1584, 916, 918, 920, 930, 932, 933, 934, 1918, 1578, 944, 1577, 946, 1575, 1574, 955, 956, 957, 1034, 1546, 1176, 1107, 1528, 1114, 1524, 1126, 1127, 1521, 1516, 1141, 1143, 1144, 1149, 1151, 1152, 1153, 1157, 1160, 1161, 1509, 1169, 1170, 1172, 1173, 1174, 1110, 1530, 1039, 1904, 1048, 1539, 1062, 1064, 1065, 1067, 1068, 1069, 1070, 1071, 1073, 1076, 1908, 1080, 1082, 1084, 1907, 1906, 1087, 1094, 1100, 1532, 1531, 434, 720, 1728, 234, 224, 1796, 227, 1795, 230, 232, 246, 219, 252, 253, 255, 257, 258, 260, 1797, 217, 376, 1801, 171, 178, 179, 181, 182, 1986, 198, 216, 431, 200, 1799, 209, 210, 1798, 263, 1788, 1787, 352, 323, 325, 1769, 338, 347, 350, 1764, 272, 357, 363, 367, 1760, 1759, 1758, 322, 1771, 314, 313, 310, 1774, 307, 302, 300, 298, 297, 295, 294, 284, 283, 279, 1786, 170, 1987, 168, 58, 48, 1995, 1840, 1838, 54, 57, 59, 85, 61, 1834, 74, 1830, 82, 83, 1843, 1844, 41, 36, 1846, 34, 28, 25, 23, 1856, 18, 15, 1850, 1851, 5, 4, 3, 84, 86, 1809, 1988, 119, 1824, 129, 132, 136, 138, 146, 88, 155, 159, 160, 161, 1810, 163, 118, 117, 1825, 1990, 113, 111, 109, 108, 107, 106, 1992, 97, 96, 94, 91, 90, 1993, 375, 1884, 393, 420, 1749, 1732, 410, 1730, 396, 400, 399, 1743, 413, 416, 427, 389, 407, 405, 1734, 415, 383]\n",
      "500\n",
      "500\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3575 - accuracy: 0.8902 - val_loss: 0.3711 - val_accuracy: 0.9260\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2796 - accuracy: 0.8989 - val_loss: 0.2159 - val_accuracy: 0.9260\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2241 - accuracy: 0.9107 - val_loss: 0.2004 - val_accuracy: 0.9300\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1934 - accuracy: 0.9218 - val_loss: 0.1690 - val_accuracy: 0.9320\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1892 - accuracy: 0.9222 - val_loss: 0.1656 - val_accuracy: 0.9260\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1832 - accuracy: 0.9284 - val_loss: 0.1527 - val_accuracy: 0.9360\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1628 - accuracy: 0.9344 - val_loss: 0.1531 - val_accuracy: 0.9360\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1449 - accuracy: 0.9444 - val_loss: 0.1341 - val_accuracy: 0.9300\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1246 - accuracy: 0.9544 - val_loss: 0.1442 - val_accuracy: 0.9360\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1146 - accuracy: 0.9533 - val_loss: 0.1310 - val_accuracy: 0.9460\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0978 - accuracy: 0.9624 - val_loss: 0.1481 - val_accuracy: 0.9480\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0790 - accuracy: 0.9696 - val_loss: 0.1758 - val_accuracy: 0.9420\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0673 - accuracy: 0.9767 - val_loss: 0.1420 - val_accuracy: 0.9520\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0544 - accuracy: 0.9802 - val_loss: 0.1596 - val_accuracy: 0.9520\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0441 - accuracy: 0.9824 - val_loss: 0.1476 - val_accuracy: 0.9480\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0238 - accuracy: 0.9922 - val_loss: 0.1688 - val_accuracy: 0.9500\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0204 - accuracy: 0.9933 - val_loss: 0.2256 - val_accuracy: 0.9500\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0135 - accuracy: 0.9960 - val_loss: 0.2326 - val_accuracy: 0.9520\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0077 - accuracy: 0.9976 - val_loss: 0.2253 - val_accuracy: 0.9460\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0047 - accuracy: 0.9989 - val_loss: 0.2198 - val_accuracy: 0.9540\n",
      "Test loss: 0.24227742850780487\n",
      "Test accuracy: 0.9390000104904175\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.7105\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3445 - accuracy: 0.8947 - val_loss: 0.2443 - val_accuracy: 0.9200\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2695 - accuracy: 0.8958 - val_loss: 0.2317 - val_accuracy: 0.9280\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2197 - accuracy: 0.9118 - val_loss: 0.1721 - val_accuracy: 0.9300\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1835 - accuracy: 0.9236 - val_loss: 0.1904 - val_accuracy: 0.9280\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1656 - accuracy: 0.9353 - val_loss: 0.1355 - val_accuracy: 0.9400\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1439 - accuracy: 0.9400 - val_loss: 0.1395 - val_accuracy: 0.9420\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1334 - accuracy: 0.9480 - val_loss: 0.1413 - val_accuracy: 0.9460\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1268 - accuracy: 0.9491 - val_loss: 0.1261 - val_accuracy: 0.9520\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1012 - accuracy: 0.9591 - val_loss: 0.1206 - val_accuracy: 0.9500\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0933 - accuracy: 0.9644 - val_loss: 0.1277 - val_accuracy: 0.9600\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0818 - accuracy: 0.9693 - val_loss: 0.1948 - val_accuracy: 0.9400\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0884 - accuracy: 0.9671 - val_loss: 0.1283 - val_accuracy: 0.9560\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0532 - accuracy: 0.9791 - val_loss: 0.1469 - val_accuracy: 0.9480\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0619 - accuracy: 0.9767 - val_loss: 0.1442 - val_accuracy: 0.9480\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0423 - accuracy: 0.9860 - val_loss: 0.1441 - val_accuracy: 0.9520\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0418 - accuracy: 0.9842 - val_loss: 0.1783 - val_accuracy: 0.9600\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0234 - accuracy: 0.9916 - val_loss: 0.1636 - val_accuracy: 0.9540\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0134 - accuracy: 0.9951 - val_loss: 0.1625 - val_accuracy: 0.9620\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0070 - accuracy: 0.9980 - val_loss: 0.1931 - val_accuracy: 0.9520\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0123 - accuracy: 0.9947 - val_loss: 0.1962 - val_accuracy: 0.9540\n",
      "Test loss: 0.2541373372077942\n",
      "Test accuracy: 0.9359999895095825\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.673\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3504 - accuracy: 0.8776 - val_loss: 0.2420 - val_accuracy: 0.9260\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2701 - accuracy: 0.9031 - val_loss: 0.2300 - val_accuracy: 0.9000\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2210 - accuracy: 0.9138 - val_loss: 0.1871 - val_accuracy: 0.9240\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2088 - accuracy: 0.9180 - val_loss: 0.1822 - val_accuracy: 0.9280\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1878 - accuracy: 0.9251 - val_loss: 0.1664 - val_accuracy: 0.9260\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1561 - accuracy: 0.9356 - val_loss: 0.1503 - val_accuracy: 0.9440\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1546 - accuracy: 0.9404 - val_loss: 0.1271 - val_accuracy: 0.9500\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1306 - accuracy: 0.9496 - val_loss: 0.1327 - val_accuracy: 0.9440\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1141 - accuracy: 0.9576 - val_loss: 0.1481 - val_accuracy: 0.9420\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1044 - accuracy: 0.9602 - val_loss: 0.1380 - val_accuracy: 0.9540\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0917 - accuracy: 0.9667 - val_loss: 0.1422 - val_accuracy: 0.9560\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0722 - accuracy: 0.9738 - val_loss: 0.1148 - val_accuracy: 0.9620\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0668 - accuracy: 0.9778 - val_loss: 0.1215 - val_accuracy: 0.9620\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0527 - accuracy: 0.9802 - val_loss: 0.1373 - val_accuracy: 0.9560\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0389 - accuracy: 0.9856 - val_loss: 0.1559 - val_accuracy: 0.9440\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0249 - accuracy: 0.9916 - val_loss: 0.1686 - val_accuracy: 0.9540\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0112 - accuracy: 0.9973 - val_loss: 0.1888 - val_accuracy: 0.9540\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0061 - accuracy: 0.9982 - val_loss: 0.2209 - val_accuracy: 0.9640\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0060 - accuracy: 0.9980 - val_loss: 0.1782 - val_accuracy: 0.9520\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0295 - accuracy: 0.9898 - val_loss: 0.1728 - val_accuracy: 0.9540\n",
      "Test loss: 0.20573630928993225\n",
      "Test accuracy: 0.9409999847412109\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.6405\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3766 - accuracy: 0.8869 - val_loss: 0.2790 - val_accuracy: 0.9240\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2754 - accuracy: 0.8989 - val_loss: 0.2192 - val_accuracy: 0.9200\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2411 - accuracy: 0.9016 - val_loss: 0.2117 - val_accuracy: 0.9200\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2044 - accuracy: 0.9147 - val_loss: 0.1487 - val_accuracy: 0.9400\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1850 - accuracy: 0.9267 - val_loss: 0.1638 - val_accuracy: 0.9280\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1640 - accuracy: 0.9280 - val_loss: 0.1327 - val_accuracy: 0.9520\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1537 - accuracy: 0.9396 - val_loss: 0.1539 - val_accuracy: 0.9380\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1349 - accuracy: 0.9444 - val_loss: 0.1087 - val_accuracy: 0.9580\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1115 - accuracy: 0.9567 - val_loss: 0.1000 - val_accuracy: 0.9600\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0949 - accuracy: 0.9660 - val_loss: 0.2098 - val_accuracy: 0.9520\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0962 - accuracy: 0.9636 - val_loss: 0.1178 - val_accuracy: 0.9460\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0650 - accuracy: 0.9769 - val_loss: 0.1168 - val_accuracy: 0.9620\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0601 - accuracy: 0.9767 - val_loss: 0.0973 - val_accuracy: 0.9620\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0408 - accuracy: 0.9858 - val_loss: 0.1306 - val_accuracy: 0.9520\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0286 - accuracy: 0.9911 - val_loss: 0.1545 - val_accuracy: 0.9560\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0289 - accuracy: 0.9878 - val_loss: 0.1439 - val_accuracy: 0.9520\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0175 - accuracy: 0.9947 - val_loss: 0.1496 - val_accuracy: 0.9600\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0076 - accuracy: 0.9976 - val_loss: 0.1457 - val_accuracy: 0.9480\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0357 - accuracy: 0.9873 - val_loss: 0.1298 - val_accuracy: 0.9480\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0187 - accuracy: 0.9933 - val_loss: 0.1505 - val_accuracy: 0.9560\n",
      "Test loss: 0.18634679913520813\n",
      "Test accuracy: 0.9539999961853027\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.787\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3383 - accuracy: 0.8789 - val_loss: 0.2305 - val_accuracy: 0.9240\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2470 - accuracy: 0.9024 - val_loss: 0.1972 - val_accuracy: 0.9280\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2079 - accuracy: 0.9140 - val_loss: 0.1726 - val_accuracy: 0.9300\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1811 - accuracy: 0.9267 - val_loss: 0.1561 - val_accuracy: 0.9380\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1729 - accuracy: 0.9291 - val_loss: 0.1307 - val_accuracy: 0.9460\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1531 - accuracy: 0.9380 - val_loss: 0.1300 - val_accuracy: 0.9460\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1402 - accuracy: 0.9427 - val_loss: 0.1225 - val_accuracy: 0.9480\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1171 - accuracy: 0.9571 - val_loss: 0.1202 - val_accuracy: 0.9520\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1081 - accuracy: 0.9560 - val_loss: 0.1250 - val_accuracy: 0.9520\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0906 - accuracy: 0.9658 - val_loss: 0.1716 - val_accuracy: 0.9200\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0924 - accuracy: 0.9642 - val_loss: 0.1362 - val_accuracy: 0.9380\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0772 - accuracy: 0.9716 - val_loss: 0.1266 - val_accuracy: 0.9380\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0533 - accuracy: 0.9818 - val_loss: 0.1350 - val_accuracy: 0.9480\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0340 - accuracy: 0.9873 - val_loss: 0.1327 - val_accuracy: 0.9580\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0244 - accuracy: 0.9924 - val_loss: 0.1437 - val_accuracy: 0.9620\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0258 - accuracy: 0.9902 - val_loss: 0.1665 - val_accuracy: 0.9500\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0151 - accuracy: 0.9944 - val_loss: 0.1735 - val_accuracy: 0.9600\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0083 - accuracy: 0.9978 - val_loss: 0.1741 - val_accuracy: 0.9580\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0062 - accuracy: 0.9976 - val_loss: 0.1620 - val_accuracy: 0.9500\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0071 - accuracy: 0.9978 - val_loss: 0.2294 - val_accuracy: 0.9680\n",
      "Test loss: 0.26859766244888306\n",
      "Test accuracy: 0.953000009059906\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.599\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3564 - accuracy: 0.8893 - val_loss: 0.2447 - val_accuracy: 0.9240\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2744 - accuracy: 0.8978 - val_loss: 0.2245 - val_accuracy: 0.9240\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2178 - accuracy: 0.9144 - val_loss: 0.1733 - val_accuracy: 0.9400\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2054 - accuracy: 0.9189 - val_loss: 0.1630 - val_accuracy: 0.9340\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1773 - accuracy: 0.9273 - val_loss: 0.1576 - val_accuracy: 0.9400\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1608 - accuracy: 0.9367 - val_loss: 0.1472 - val_accuracy: 0.9500\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1498 - accuracy: 0.9404 - val_loss: 0.1485 - val_accuracy: 0.9460\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1343 - accuracy: 0.9473 - val_loss: 0.1681 - val_accuracy: 0.9260\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1208 - accuracy: 0.9504 - val_loss: 0.1320 - val_accuracy: 0.9460\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0967 - accuracy: 0.9644 - val_loss: 0.1270 - val_accuracy: 0.9480\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0781 - accuracy: 0.9724 - val_loss: 0.1504 - val_accuracy: 0.9520\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0821 - accuracy: 0.9727 - val_loss: 0.1355 - val_accuracy: 0.9560\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0514 - accuracy: 0.9802 - val_loss: 0.1445 - val_accuracy: 0.9540\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0446 - accuracy: 0.9849 - val_loss: 0.1228 - val_accuracy: 0.9660\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0242 - accuracy: 0.9909 - val_loss: 0.2431 - val_accuracy: 0.9480\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0204 - accuracy: 0.9933 - val_loss: 0.1636 - val_accuracy: 0.9560\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0601 - accuracy: 0.9762 - val_loss: 0.1705 - val_accuracy: 0.9580\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0434 - accuracy: 0.9838 - val_loss: 0.1790 - val_accuracy: 0.9560\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0174 - accuracy: 0.9936 - val_loss: 0.1890 - val_accuracy: 0.9560\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0117 - accuracy: 0.9962 - val_loss: 0.1455 - val_accuracy: 0.9540\n",
      "Test loss: 0.17306414246559143\n",
      "Test accuracy: 0.9470000267028809\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.831\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3492 - accuracy: 0.8727 - val_loss: 0.3084 - val_accuracy: 0.9260\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2658 - accuracy: 0.9051 - val_loss: 0.2087 - val_accuracy: 0.9280\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2225 - accuracy: 0.9113 - val_loss: 0.1773 - val_accuracy: 0.9320\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1909 - accuracy: 0.9189 - val_loss: 0.1598 - val_accuracy: 0.9420\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1739 - accuracy: 0.9282 - val_loss: 0.1343 - val_accuracy: 0.9460\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1613 - accuracy: 0.9362 - val_loss: 0.1400 - val_accuracy: 0.9480\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1443 - accuracy: 0.9471 - val_loss: 0.1214 - val_accuracy: 0.9480\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1204 - accuracy: 0.9529 - val_loss: 0.1107 - val_accuracy: 0.9540\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0999 - accuracy: 0.9604 - val_loss: 0.1243 - val_accuracy: 0.9500\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0835 - accuracy: 0.9680 - val_loss: 0.1211 - val_accuracy: 0.9520\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0711 - accuracy: 0.9724 - val_loss: 0.1154 - val_accuracy: 0.9540\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0572 - accuracy: 0.9798 - val_loss: 0.1289 - val_accuracy: 0.9560\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0464 - accuracy: 0.9822 - val_loss: 0.1729 - val_accuracy: 0.9580\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0368 - accuracy: 0.9856 - val_loss: 0.2147 - val_accuracy: 0.9580\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0288 - accuracy: 0.9900 - val_loss: 0.1604 - val_accuracy: 0.9640\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0117 - accuracy: 0.9971 - val_loss: 0.2257 - val_accuracy: 0.9580\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0169 - accuracy: 0.9947 - val_loss: 0.1963 - val_accuracy: 0.9600\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0345 - accuracy: 0.9880 - val_loss: 0.1763 - val_accuracy: 0.9560\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0149 - accuracy: 0.9962 - val_loss: 0.1692 - val_accuracy: 0.9520\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0143 - accuracy: 0.9942 - val_loss: 0.1779 - val_accuracy: 0.9580\n",
      "Test loss: 0.17566075921058655\n",
      "Test accuracy: 0.9570000171661377\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.643\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.4004 - accuracy: 0.8964 - val_loss: 0.2651 - val_accuracy: 0.9240\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.3020 - accuracy: 0.8969 - val_loss: 0.2378 - val_accuracy: 0.9280\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2606 - accuracy: 0.8998 - val_loss: 0.2082 - val_accuracy: 0.9300\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2523 - accuracy: 0.9038 - val_loss: 0.2092 - val_accuracy: 0.9320\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2112 - accuracy: 0.9160 - val_loss: 0.1657 - val_accuracy: 0.9380\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1850 - accuracy: 0.9307 - val_loss: 0.1533 - val_accuracy: 0.9340\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1693 - accuracy: 0.9336 - val_loss: 0.1551 - val_accuracy: 0.9380\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1448 - accuracy: 0.9471 - val_loss: 0.1522 - val_accuracy: 0.9440\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1545 - accuracy: 0.9391 - val_loss: 0.1434 - val_accuracy: 0.9440\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1132 - accuracy: 0.9573 - val_loss: 0.1139 - val_accuracy: 0.9560\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1021 - accuracy: 0.9611 - val_loss: 0.1181 - val_accuracy: 0.9440\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0853 - accuracy: 0.9671 - val_loss: 0.1294 - val_accuracy: 0.9480\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0703 - accuracy: 0.9753 - val_loss: 0.1124 - val_accuracy: 0.9520\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0717 - accuracy: 0.9740 - val_loss: 0.1200 - val_accuracy: 0.9520\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0477 - accuracy: 0.9838 - val_loss: 0.1278 - val_accuracy: 0.9420\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0394 - accuracy: 0.9864 - val_loss: 0.1394 - val_accuracy: 0.9440\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0216 - accuracy: 0.9922 - val_loss: 0.1652 - val_accuracy: 0.9440\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0253 - accuracy: 0.9909 - val_loss: 0.1526 - val_accuracy: 0.9400\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0200 - accuracy: 0.9916 - val_loss: 0.1798 - val_accuracy: 0.9540\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0239 - accuracy: 0.9916 - val_loss: 0.1531 - val_accuracy: 0.9520\n",
      "Test loss: 0.19625233113765717\n",
      "Test accuracy: 0.9430000185966492\n",
      "63/63 [==============================] - 0s 2ms/step\n",
      "0.589\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3765 - accuracy: 0.8953 - val_loss: 0.2657 - val_accuracy: 0.9240\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2661 - accuracy: 0.8989 - val_loss: 0.2100 - val_accuracy: 0.9240\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2303 - accuracy: 0.9062 - val_loss: 0.2080 - val_accuracy: 0.9260\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2112 - accuracy: 0.9162 - val_loss: 0.1792 - val_accuracy: 0.9380\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1935 - accuracy: 0.9238 - val_loss: 0.1631 - val_accuracy: 0.9340\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1747 - accuracy: 0.9313 - val_loss: 0.1346 - val_accuracy: 0.9500\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1567 - accuracy: 0.9369 - val_loss: 0.1340 - val_accuracy: 0.9440\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1361 - accuracy: 0.9447 - val_loss: 0.1289 - val_accuracy: 0.9400\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1163 - accuracy: 0.9549 - val_loss: 0.1573 - val_accuracy: 0.9460\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1191 - accuracy: 0.9544 - val_loss: 0.1290 - val_accuracy: 0.9480\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0923 - accuracy: 0.9636 - val_loss: 0.1225 - val_accuracy: 0.9620\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0726 - accuracy: 0.9729 - val_loss: 0.1175 - val_accuracy: 0.9600\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0674 - accuracy: 0.9744 - val_loss: 0.1549 - val_accuracy: 0.9400\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0467 - accuracy: 0.9816 - val_loss: 0.1776 - val_accuracy: 0.9480\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0521 - accuracy: 0.9807 - val_loss: 0.1333 - val_accuracy: 0.9480\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0289 - accuracy: 0.9900 - val_loss: 0.1269 - val_accuracy: 0.9580\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0360 - accuracy: 0.9860 - val_loss: 0.1405 - val_accuracy: 0.9500\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0404 - accuracy: 0.9849 - val_loss: 0.1722 - val_accuracy: 0.9380\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0271 - accuracy: 0.9896 - val_loss: 0.1574 - val_accuracy: 0.9580\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0182 - accuracy: 0.9947 - val_loss: 0.1878 - val_accuracy: 0.9480\n",
      "Test loss: 0.21609705686569214\n",
      "Test accuracy: 0.9470000267028809\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.617\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3484 - accuracy: 0.8802 - val_loss: 0.2396 - val_accuracy: 0.9240\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2776 - accuracy: 0.8976 - val_loss: 0.2183 - val_accuracy: 0.9280\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2302 - accuracy: 0.9082 - val_loss: 0.1872 - val_accuracy: 0.9280\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2072 - accuracy: 0.9198 - val_loss: 0.1766 - val_accuracy: 0.9340\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1898 - accuracy: 0.9278 - val_loss: 0.1501 - val_accuracy: 0.9400\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1639 - accuracy: 0.9382 - val_loss: 0.1332 - val_accuracy: 0.9500\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1418 - accuracy: 0.9422 - val_loss: 0.1333 - val_accuracy: 0.9500\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1281 - accuracy: 0.9504 - val_loss: 0.1597 - val_accuracy: 0.9500\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1273 - accuracy: 0.9533 - val_loss: 0.1495 - val_accuracy: 0.9440\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0960 - accuracy: 0.9638 - val_loss: 0.1695 - val_accuracy: 0.9480\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0929 - accuracy: 0.9620 - val_loss: 0.1524 - val_accuracy: 0.9500\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0766 - accuracy: 0.9713 - val_loss: 0.1412 - val_accuracy: 0.9380\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0714 - accuracy: 0.9747 - val_loss: 0.1148 - val_accuracy: 0.9520\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0550 - accuracy: 0.9800 - val_loss: 0.1485 - val_accuracy: 0.9360\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0587 - accuracy: 0.9771 - val_loss: 0.1427 - val_accuracy: 0.9460\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0281 - accuracy: 0.9904 - val_loss: 0.1312 - val_accuracy: 0.9540\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0196 - accuracy: 0.9929 - val_loss: 0.1656 - val_accuracy: 0.9500\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0154 - accuracy: 0.9949 - val_loss: 0.2175 - val_accuracy: 0.9440\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0205 - accuracy: 0.9931 - val_loss: 0.1380 - val_accuracy: 0.9540\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0128 - accuracy: 0.9971 - val_loss: 0.2959 - val_accuracy: 0.9480\n",
      "Test loss: 0.2456424981355667\n",
      "Test accuracy: 0.949999988079071\n",
      "63/63 [==============================] - 0s 2ms/step\n",
      "0.5445\n",
      "      通し番号  カウント\n",
      "0        0     9\n",
      "1        1    10\n",
      "2        2     5\n",
      "3        3     7\n",
      "4        4     9\n",
      "...    ...   ...\n",
      "1995  1995     6\n",
      "1996  1996     4\n",
      "1997  1997     5\n",
      "1998  1998    10\n",
      "1999  1999     9\n",
      "\n",
      "[2000 rows x 2 columns]\n",
      "[0.7105, 0.673, 0.6405, 0.787, 0.599, 0.831, 0.643, 0.589, 0.617, 0.5445]\n",
      "11\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[811, 813, 1991, 775, 1898, 65, 833, 1962, 836, 867, 42, 724, 34, 1934, 732, 1913, 1947, 880, 915, 14, 1964, 53, 1966, 1968, 1969, 848, 845, 1975, 66, 1168, 68, 1665, 1396, 1395, 1386, 220, 1650, 1654, 1657, 1351, 1350, 433, 1348, 204, 79, 447, 1674, 1328, 200, 1322, 197, 193, 189, 188, 1697, 1291, 1399, 1401, 388, 1610, 1542, 1531, 1527, 288, 1554, 1519, 1560, 1518, 306, 1495, 258, 1579, 250, 1470, 1468, 1455, 1591, 1452, 1449, 1444, 1441, 1601, 1435, 1715, 1282, 479, 1803, 1808, 1815, 1101, 1817, 1099, 1822, 1079, 1835, 1837, 1840, 97, 1065, 1850, 1055, 1048, 1859, 1034, 1865, 82, 1873, 659, 995, 80, 1113, 1799, 1271, 1798, 1722, 1261, 160, 159, 1253, 1239, 530, 536, 1757, 560, 134, 133, 1773, 569, 1780, 584, 1783, 1143, 1788, 1789, 1136, 1792, 591, 794, 980, 1820, 716, 1920, 698, 985, 599, 593, 61, 1067, 1052, 1033, 1104, 1135, 919, 1137, 957, 976, 1785, 711, 640, 587, 678, 1879, 610, 973, 1854, 1903, 1056, 651, 1108, 1810, 116, 1018, 1014, 712, 118, 91, 962, 1091, 1100, 1092, 94, 928, 1847, 936, 1097, 1874, 1946, 41, 1299, 251, 1359, 1656, 1965, 1358, 1354, 254, 1574, 857, 434, 318, 1678, 1954, 28, 459, 883, 1311, 1365, 824, 1643, 1404, 362, 1605, 1606, 368, 1617, 391, 233, 247, 416, 1631, 1632, 1633, 770, 851, 405, 1586, 1598, 1699, 1704, 1232, 522, 524, 534, 1200, 550, 1189, 1188, 551, 1176, 293, 38, 568, 786, 911, 571, 801, 913, 1705, 517, 1233, 1891, 1706, 176, 468, 1293, 470, 295, 1717, 1945, 736, 902, 154, 512, 737, 1777, 509, 1546, 191, 1082, 1131, 615, 1321, 706, 511, 1692, 1936, 535, 907, 39, 874, 516, 1075, 1806, 752, 449, 722, 540, 602, 1255, 1944, 1281, 1915, 484, 603, 169, 493, 893, 898, 899, 1224, 1086, 1297, 1090, 1300, 504, 1301, 1336, 1734, 1735, 1935, 609, 467, 284, 942, 649, 1450, 1025, 1866, 691, 1030, 1608, 1431, 1428, 827, 756, 1425, 238, 1424, 1420, 379, 392, 1592, 1985, 693, 674, 1540, 804, 787, 1552, 1556, 679, 677, 313, 963, 1573, 256, 329, 331, 1583, 967, 996, 394, 1427, 1626, 1054, 697, 417, 422, 1363, 1967, 426, 1360, 212, 1845, 624, 1353, 759, 1074, 1667, 1669, 408, 585, 631, 15, 1630, 397, 1800, 123, 1881, 1553, 1561, 1818, 1795, 85, 1862, 1895, 1870, 148, 1896, 1901, 1613, 1972, 236, 232, 1634, 1595, 1593, 1590, 199, 1685, 1948, 1943, 10, 1695, 184, 180, 1710, 1939, 1721, 45, 1761, 139, 1567, 136, 1775, 1938, 1000, 703, 412, 1089, 1295, 1093, 1292, 935, 471, 474, 844, 1268, 492, 372, 1247, 838, 1437, 837, 1023, 1236, 1447, 1111, 739, 415, 1220, 1304, 443, 436, 453, 1323, 620, 760, 621, 1076, 1068, 949, 454, 460, 462, 1083, 889, 420, 418, 627, 463, 832, 505, 355, 814, 326, 989, 1183, 1179, 316, 1175, 312, 817, 308, 1500, 307, 305, 1191, 1170, 910, 1521, 290, 1161, 808, 1149, 1529, 583, 918, 975, 822, 869, 828, 1472, 715, 1115, 543, 1535, 1541, 1547, 1532, 793, 1508, 1555, 815, 352, 1457, 346, 332, 255, 820, 1981, 263, 802, 1492, 784, 1496, 1446, 1510, 1513, 1996, 1028, 1169, 1429, 1265, 1214, 1747, 520, 1612, 149, 1744, 1726, 1880, 1819, 475, 731, 905, 473, 650, 735, 990, 1752, 1753, 1754, 1203, 1784, 124, 1157, 1158, 132, 566, 1125, 563, 950, 555, 554, 702, 974, 705, 707, 1942, 32, 1098, 1390, 1648, 864, 757, 856, 1384, 228, 409, 1963, 1652, 1635, 1040, 1629, 1035, 1623, 841, 1863, 1852, 1366, 1060, 1677, 670, 992, 1309, 611, 892, 211, 1085, 1324, 1828, 1676, 437, 753, 965, 1379, 358, 1340, 1453, 357, 1433, 1976, 831, 387, 234, 1625, 1600, 383, 750, 395, 865, 356, 428, 1416, 875, 25, 1970, 377, 767, 1228, 882, 131, 940, 99, 1563, 1769, 696, 60, 1834, 1333, 1078, 299, 1156, 1779, 298, 582, 1832, 2, 586, 1134, 589, 271, 1128, 688, 999, 687, 1997, 69, 1888, 104, 986, 112, 92, 1213, 629, 163, 1329, 1949, 84, 466, 1302, 181, 249, 341, 1986, 33, 1538, 89, 1578, 1277, 725, 83, 931, 713, 147, 1222, 1223, 1102, 1742, 921, 1244, 499, 494, 1043, 1267, 384, 1426, 101, 730, 912, 451, 1017, 1332, 1533, 1087, 1264, 1877, 1276, 1825, 86, 669, 993, 1335, 746, 849, 1337, 745, 1461, 768, 1548, 1858, 1306, 345, 439, 742, 1053, 30, 456, 1730, 1662, 1009, 1977, 1660, 340, 1007, 96, 665, 1003, 1838, 744, 616, 1280, 1308, 1599, 1732, 754, 860, 966, 311, 1760, 144, 52, 1758, 1640, 1993, 1439, 708, 1569, 225, 155, 531, 934, 1186, 126, 806, 359, 692, 580, 758, 300, 1151, 1772, 407, 854, 564, 1768, 269, 1765, 699, 1995, 47, 137, 419, 800, 1105, 46, 780, 527, 321, 1522, 1814, 682, 44, 1923, 1621, 1238, 287, 523, 1749, 1959, 276, 497, 525, 1796, 1597, 927, 1487, 862, 1231, 1912, 3, 866, 239, 1992, 1911, 1160, 20, 955, 58, 1380, 951, 302, 565, 1505, 1906, 878, 1994, 700, 810, 310, 1190, 925, 1910, 938, 222, 1206, 1908, 916, 1451, 1465, 472, 334, 734, 469, 1474, 173, 872, 1298, 1700, 208, 1693, 924, 438, 1686, 1462, 887, 1679, 1982, 1458, 749, 1951, 1671, 1477, 167, 1355, 1575, 21, 214, 507, 1925, 917, 1733, 503, 1362, 1256, 1257, 1727, 1385, 1927, 490, 1655, 1724, 1928, 1270, 7, 1930, 1456, 807, 748, 660, 1627, 1133, 243, 657, 1050, 240, 1618, 1130, 1129, 294, 95, 618, 381, 600, 1077, 968, 1403, 1887, 121, 847, 672, 1407, 105, 1103, 1409, 1961, 1550, 109, 1549, 1791, 286, 1637, 579, 1027, 1144, 63, 656, 842, 964, 1869, 1974, 797, 1020, 1537, 1515, 1139, 1787, 1152, 1142, 128, 1148, 1154, 576, 573, 1776, 1774, 1766, 559, 1763, 1793, 1397, 592, 597, 1036, 1039, 639, 637, 1046, 1857, 1855, 1853, 1057, 1059, 628, 1063, 1844, 1841, 1069, 1080, 614, 613, 1827, 106, 1823, 1095, 1096, 1106, 1109, 1802, 1801, 1118, 1797, 546, 1272, 544, 365, 370, 1611, 1614, 1616, 373, 374, 375, 1418, 235, 396, 796, 398, 1383, 226, 1372, 421, 423, 1603, 1460, 1666, 344, 1536, 1534, 1526, 1523, 279, 1514, 1509, 1502, 266, 264, 260, 1488, 1486, 1485, 253, 1469, 1588, 1661, 203, 1199, 506, 153, 152, 1740, 514, 515, 150, 518, 1227, 1748, 1218, 526, 1751, 532, 1207, 537, 538, 1755, 508, 1736, 1675, 491, 1325, 196, 1320, 457, 1314, 1702, 1711, 1712, 1288, 1286, 166, 1279, 1275, 476, 1032, 488, 1725, 1861, 1543, 926, 658, 1917, 873, 762, 664, 684, 761, 1006, 1005, 1876, 704, 903, 1002, 969, 852, 859, 997, 1937, 1001, 6, 909, 799, 1980, 1875, 763, 74, 12, 782, 695, 885, 961, 673, 652, 54, 743, 1021, 825, 998, 1019, 764, 1918, 894, 771, 26, 1015, 971, 948, 945, 929, 884, 933, 846, 972, 970, 855, 853, 958, 897, 941, 843, 937, 956, 821, 959, 947, 0, 1010, 1659, 1756, 1750, 1746, 1743, 1741, 1739, 1719, 1716, 1698, 1694, 1684, 1670, 1663, 1651, 1011, 1622, 1615, 1596, 1589, 1584, 1581, 1558, 1551, 1539, 1520, 1512, 1507, 1481, 1759, 1771, 1782, 1786, 1984, 1983, 1978, 1973, 1958, 1955, 1933, 1924, 1919, 1907, 1892, 1889, 1885, 1872, 1871, 1868, 1856, 1851, 1846, 1824, 1811, 1809, 1807, 1805, 1804, 1794, 1790, 1479, 1478, 1467, 1251, 1237, 1219, 1216, 1204, 1201, 1196, 1195, 1193, 1181, 1172, 1167, 1164, 1150, 1146, 1124, 1122, 1112, 1110, 1088, 1081, 1073, 1070, 1064, 1062, 1047, 1042, 1022, 1249, 1258, 1466, 1263, 1438, 1430, 1422, 1421, 1419, 1417, 1411, 1410, 1406, 1402, 1400, 1392, 1388, 1382, 1381, 1377, 1375, 1371, 1364, 1339, 1317, 1316, 1303, 1296, 1274, 1273, 1269, 798, 1999, 23, 217, 427, 545, 213, 425, 424, 671, 215, 171, 216, 110, 414, 386, 413, 605, 581, 411, 229, 403, 36, 108, 62, 151, 209, 430, 111, 207, 738, 464, 186, 190, 70, 458, 72, 195, 607, 676, 75, 452, 608, 448, 202, 29, 115, 444, 441, 205, 177, 19, 465, 776, 125, 777, 567, 4, 164, 90, 630, 314, 482, 265, 632, 267, 558, 552, 594, 273, 642, 789, 548, 644, 280, 647, 322, 323, 285, 324, 168, 666, 100, 98, 572, 765, 162, 242, 367, 766, 570, 626, 245, 248, 354, 64, 283, 9, 528, 662, 50, 145, 1398, 1349, 435, 1346, 1345, 1344, 1343, 440, 1342, 442, 1341, 710, 445, 446, 1338, 1334, 1331, 450, 1330, 1347, 432, 328, 431, 923, 1378, 714, 1376, 930, 1374, 1373, 932, 1370, 1369, 1368, 1367, 1361, 1357, 1356, 429, 1352, 1327, 1326, 1319, 455, 478, 944, 480, 481, 483, 1266, 485, 486, 487, 946, 489, 1262, 1260, 1259, 701, 1254, 495, 477, 943, 1278, 1307, 1318, 709, 1315, 1313, 461, 1312, 1310, 1305, 1283, 939, 1294, 1290, 1289, 1287, 1285, 1284, 1387, 410, 717, 1434, 350, 351, 1463, 353, 1459, 1454, 1448, 1445, 1443, 1442, 360, 361, 1440, 363, 364, 729, 366, 349, 348, 347, 337, 330, 904, 1476, 333, 994, 335, 336, 338, 1464, 339, 1473, 1471, 342, 343, 906, 908, 1436, 369, 1389, 1432, 1408, 721, 393, 1405, 720, 719, 795, 1394, 399, 400, 401, 402, 1393, 404, 718, 406, 1391, 390, 389, 922, 378, 371, 728, 1423, 727, 726, 376, 914, 920, 723, 380, 1415, 382, 1414, 1413, 385, 1412, 496, 1252, 498, 1061, 1107, 1094, 612, 680, 1084, 978, 979, 617, 1072, 619, 1071, 981, 622, 623, 1066, 625, 982, 681, 977, 1114, 683, 1132, 590, 1127, 1126, 1123, 595, 596, 598, 606, 1121, 1120, 601, 1119, 1117, 604, 1116, 675, 1058, 1138, 1051, 1026, 1024, 653, 654, 655, 987, 1016, 1013, 1012, 988, 661, 991, 663, 1008, 1004, 1, 667, 1029, 1031, 648, 638, 1049, 983, 633, 634, 635, 636, 1045, 1044, 1037, 984, 641, 1041, 643, 1038, 645, 646, 588, 1140, 500, 541, 1225, 1221, 953, 1217, 954, 1215, 1212, 529, 1211, 1210, 1209, 533, 1208, 1205, 1202, 694, 539, 521, 1226, 519, 1242, 501, 502, 1250, 1248, 1246, 1245, 1243, 510, 1229, 1241, 1240, 513, 952, 1235, 1234, 1230, 1198, 542, 1141, 1197, 689, 1171, 1166, 1165, 1163, 1162, 574, 575, 1159, 577, 578, 1155, 1153, 686, 1147, 685, 1145, 1173, 1174, 1177, 553, 1194, 547, 960, 549, 1192, 1187, 1185, 1184, 562, 1182, 556, 557, 690, 1180, 1178, 561, 733, 1475, 327, 1830, 1826, 107, 773, 1821, 1816, 1813, 1812, 113, 114, 772, 826, 117, 829, 119, 120, 769, 122, 1829, 103, 1714, 102, 819, 1867, 1864, 87, 88, 1860, 823, 1849, 93, 1848, 774, 1843, 1842, 1839, 1836, 1833, 1831, 830, 834, 835, 839, 861, 863, 1738, 1737, 1731, 156, 157, 158, 1729, 1728, 161, 1723, 1480, 1720, 755, 165, 1718, 858, 1745, 146, 135, 127, 840, 129, 130, 1781, 1778, 1770, 1767, 850, 1764, 138, 1762, 140, 141, 142, 143, 778, 779, 81, 40, 22, 1957, 24, 1956, 805, 27, 1953, 1952, 1950, 31, 1941, 1940, 809, 35, 1932, 37, 1931, 788, 1960, 1971, 792, 1998, 1990, 1989, 5, 1988, 1987, 8, 791, 18, 11, 1979, 13, 790, 803, 16, 17, 1929, 1926, 1878, 785, 1897, 1894, 1893, 816, 67, 1890, 781, 1886, 71, 818, 73, 1884, 1883, 76, 77, 78, 1882, 1899, 1900, 1902, 1914, 43, 1922, 1921, 812, 1916, 48, 49, 51, 59, 1909, 783, 1905, 55, 56, 57, 1904, 868, 668, 1713, 272, 1570, 1568, 1566, 1565, 268, 1564, 270, 1562, 1559, 262, 274, 275, 740, 277, 278, 1557, 891, 281, 1571, 261, 1607, 1585, 1604, 1602, 244, 886, 246, 1594, 888, 1587, 890, 1572, 252, 1582, 741, 1580, 1577, 257, 1576, 259, 282, 1545, 1544, 1490, 1499, 309, 1498, 1497, 1494, 1493, 1491, 315, 317, 895, 1489, 319, 320, 1484, 1483, 1482, 901, 325, 1501, 1503, 1504, 304, 1530, 1528, 1525, 289, 1524, 291, 292, 896, 1517, 1516, 296, 297, 1511, 900, 301, 1506, 303, 170, 241, 1609, 1682, 1689, 1688, 192, 1687, 194, 751, 1683, 198, 877, 1681, 1680, 201, 1673, 876, 1668, 206, 1690, 1691, 187, 871, 1709, 172, 1708, 174, 175, 1707, 1703, 178, 179, 1701, 870, 182, 183, 1696, 185, 1664, 1672, 879, 219, 231, 230, 1636, 1638, 227, 1639, 1641, 224, 223, 1642, 1624, 881, 221, 1628, 1644, 218, 747, 210, 1658, 237, 1645, 1653, 1619, 1649, 1647, 1620, 1646]\n",
      "500\n",
      "500\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3421 - accuracy: 0.8864 - val_loss: 0.2691 - val_accuracy: 0.9080\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2903 - accuracy: 0.8991 - val_loss: 0.3050 - val_accuracy: 0.9080\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2807 - accuracy: 0.8991 - val_loss: 0.2551 - val_accuracy: 0.9080\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2695 - accuracy: 0.8998 - val_loss: 0.2644 - val_accuracy: 0.9080\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2560 - accuracy: 0.9018 - val_loss: 0.2416 - val_accuracy: 0.9120\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2473 - accuracy: 0.9031 - val_loss: 0.2315 - val_accuracy: 0.9120\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2527 - accuracy: 0.9047 - val_loss: 0.2726 - val_accuracy: 0.9140\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2369 - accuracy: 0.9064 - val_loss: 0.2221 - val_accuracy: 0.9140\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2172 - accuracy: 0.9109 - val_loss: 0.2221 - val_accuracy: 0.9140\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2047 - accuracy: 0.9151 - val_loss: 0.2315 - val_accuracy: 0.9100\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1964 - accuracy: 0.9191 - val_loss: 0.2019 - val_accuracy: 0.9260\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1780 - accuracy: 0.9262 - val_loss: 0.2505 - val_accuracy: 0.9120\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1768 - accuracy: 0.9260 - val_loss: 0.2162 - val_accuracy: 0.9200\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1407 - accuracy: 0.9373 - val_loss: 0.2682 - val_accuracy: 0.9180\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1294 - accuracy: 0.9449 - val_loss: 0.2418 - val_accuracy: 0.9200\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1023 - accuracy: 0.9604 - val_loss: 0.2682 - val_accuracy: 0.8820\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0923 - accuracy: 0.9618 - val_loss: 0.2778 - val_accuracy: 0.8920\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0717 - accuracy: 0.9709 - val_loss: 0.2734 - val_accuracy: 0.9000\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0394 - accuracy: 0.9853 - val_loss: 0.3152 - val_accuracy: 0.8820\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0358 - accuracy: 0.9876 - val_loss: 0.4641 - val_accuracy: 0.8980\n",
      "Test loss: 0.5809020400047302\n",
      "Test accuracy: 0.8960000276565552\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.2895\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3290 - accuracy: 0.8867 - val_loss: 0.2593 - val_accuracy: 0.9080\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.3000 - accuracy: 0.8991 - val_loss: 0.2563 - val_accuracy: 0.9080\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2732 - accuracy: 0.8991 - val_loss: 0.2577 - val_accuracy: 0.9080\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2697 - accuracy: 0.9002 - val_loss: 0.2303 - val_accuracy: 0.9080\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2556 - accuracy: 0.9024 - val_loss: 0.2276 - val_accuracy: 0.9080\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2463 - accuracy: 0.9040 - val_loss: 0.2146 - val_accuracy: 0.9220\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2318 - accuracy: 0.9111 - val_loss: 0.2082 - val_accuracy: 0.9160\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2163 - accuracy: 0.9118 - val_loss: 0.2268 - val_accuracy: 0.9180\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2094 - accuracy: 0.9164 - val_loss: 0.2220 - val_accuracy: 0.9160\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1836 - accuracy: 0.9240 - val_loss: 0.2252 - val_accuracy: 0.9220\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1791 - accuracy: 0.9251 - val_loss: 0.2422 - val_accuracy: 0.9040\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1675 - accuracy: 0.9300 - val_loss: 0.2209 - val_accuracy: 0.9120\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1423 - accuracy: 0.9389 - val_loss: 0.2308 - val_accuracy: 0.9060\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1204 - accuracy: 0.9540 - val_loss: 0.2267 - val_accuracy: 0.9060\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0866 - accuracy: 0.9653 - val_loss: 0.3192 - val_accuracy: 0.8680\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0942 - accuracy: 0.9609 - val_loss: 0.2472 - val_accuracy: 0.9100\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0660 - accuracy: 0.9747 - val_loss: 0.3635 - val_accuracy: 0.9280\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0538 - accuracy: 0.9802 - val_loss: 0.3084 - val_accuracy: 0.9080\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0282 - accuracy: 0.9884 - val_loss: 0.4128 - val_accuracy: 0.9100\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0231 - accuracy: 0.9911 - val_loss: 0.4099 - val_accuracy: 0.9120\n",
      "Test loss: 0.589265763759613\n",
      "Test accuracy: 0.906000018119812\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.064\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3597 - accuracy: 0.8782 - val_loss: 0.3004 - val_accuracy: 0.9080\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.3246 - accuracy: 0.8991 - val_loss: 0.2876 - val_accuracy: 0.9080\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.3083 - accuracy: 0.8991 - val_loss: 0.2673 - val_accuracy: 0.9080\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2946 - accuracy: 0.8991 - val_loss: 0.2597 - val_accuracy: 0.9080\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2960 - accuracy: 0.8991 - val_loss: 0.2608 - val_accuracy: 0.9080\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2789 - accuracy: 0.8991 - val_loss: 0.2487 - val_accuracy: 0.9080\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2640 - accuracy: 0.8993 - val_loss: 0.2363 - val_accuracy: 0.9080\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2542 - accuracy: 0.8998 - val_loss: 0.2440 - val_accuracy: 0.9120\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2392 - accuracy: 0.9027 - val_loss: 0.2195 - val_accuracy: 0.9120\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2367 - accuracy: 0.9047 - val_loss: 0.2272 - val_accuracy: 0.9220\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2307 - accuracy: 0.9093 - val_loss: 0.2625 - val_accuracy: 0.9080\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2220 - accuracy: 0.9078 - val_loss: 0.2238 - val_accuracy: 0.9140\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2039 - accuracy: 0.9140 - val_loss: 0.2153 - val_accuracy: 0.9200\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1777 - accuracy: 0.9258 - val_loss: 0.2294 - val_accuracy: 0.8980\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1838 - accuracy: 0.9191 - val_loss: 0.2142 - val_accuracy: 0.9140\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1452 - accuracy: 0.9376 - val_loss: 0.2219 - val_accuracy: 0.9080\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1371 - accuracy: 0.9396 - val_loss: 0.2406 - val_accuracy: 0.8920\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1364 - accuracy: 0.9373 - val_loss: 0.2348 - val_accuracy: 0.9060\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1002 - accuracy: 0.9600 - val_loss: 0.2597 - val_accuracy: 0.9020\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0745 - accuracy: 0.9684 - val_loss: 0.3416 - val_accuracy: 0.8960\n",
      "Test loss: 0.41446757316589355\n",
      "Test accuracy: 0.8960000276565552\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.315\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3600 - accuracy: 0.8909 - val_loss: 0.2823 - val_accuracy: 0.9080\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.3111 - accuracy: 0.8991 - val_loss: 0.2697 - val_accuracy: 0.9080\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2872 - accuracy: 0.8991 - val_loss: 0.3256 - val_accuracy: 0.9080\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2899 - accuracy: 0.8991 - val_loss: 0.2575 - val_accuracy: 0.9080\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2734 - accuracy: 0.8996 - val_loss: 0.2367 - val_accuracy: 0.9080\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2574 - accuracy: 0.9009 - val_loss: 0.2481 - val_accuracy: 0.9080\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2500 - accuracy: 0.9020 - val_loss: 0.2247 - val_accuracy: 0.9100\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2355 - accuracy: 0.9022 - val_loss: 0.2328 - val_accuracy: 0.9180\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2327 - accuracy: 0.9042 - val_loss: 0.2329 - val_accuracy: 0.9160\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2222 - accuracy: 0.9069 - val_loss: 0.2274 - val_accuracy: 0.9080\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2063 - accuracy: 0.9127 - val_loss: 0.2242 - val_accuracy: 0.9140\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1882 - accuracy: 0.9224 - val_loss: 0.2162 - val_accuracy: 0.9160\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1772 - accuracy: 0.9251 - val_loss: 0.2173 - val_accuracy: 0.9260\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1618 - accuracy: 0.9347 - val_loss: 0.2312 - val_accuracy: 0.9000\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1402 - accuracy: 0.9396 - val_loss: 0.2337 - val_accuracy: 0.9240\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1291 - accuracy: 0.9493 - val_loss: 0.2223 - val_accuracy: 0.9160\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0951 - accuracy: 0.9611 - val_loss: 0.2564 - val_accuracy: 0.9080\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0956 - accuracy: 0.9638 - val_loss: 0.2480 - val_accuracy: 0.9180\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0613 - accuracy: 0.9753 - val_loss: 0.3341 - val_accuracy: 0.8960\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0644 - accuracy: 0.9773 - val_loss: 0.5368 - val_accuracy: 0.9200\n",
      "Test loss: 0.7014513611793518\n",
      "Test accuracy: 0.9049999713897705\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.075\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3349 - accuracy: 0.8809 - val_loss: 0.2671 - val_accuracy: 0.9080\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2937 - accuracy: 0.8991 - val_loss: 0.2896 - val_accuracy: 0.9080\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2803 - accuracy: 0.8991 - val_loss: 0.2464 - val_accuracy: 0.9080\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2599 - accuracy: 0.8996 - val_loss: 0.2381 - val_accuracy: 0.9080\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2510 - accuracy: 0.9020 - val_loss: 0.2266 - val_accuracy: 0.9080\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2428 - accuracy: 0.9036 - val_loss: 0.2589 - val_accuracy: 0.9120\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2316 - accuracy: 0.9091 - val_loss: 0.3058 - val_accuracy: 0.9120\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2273 - accuracy: 0.9060 - val_loss: 0.2099 - val_accuracy: 0.9180\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1994 - accuracy: 0.9202 - val_loss: 0.2059 - val_accuracy: 0.9160\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1889 - accuracy: 0.9227 - val_loss: 0.2074 - val_accuracy: 0.9140\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1695 - accuracy: 0.9300 - val_loss: 0.2109 - val_accuracy: 0.9180\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1538 - accuracy: 0.9349 - val_loss: 0.2236 - val_accuracy: 0.9020\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1238 - accuracy: 0.9502 - val_loss: 0.3142 - val_accuracy: 0.9240\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1019 - accuracy: 0.9609 - val_loss: 0.2670 - val_accuracy: 0.9160\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0815 - accuracy: 0.9664 - val_loss: 0.3008 - val_accuracy: 0.9140\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0669 - accuracy: 0.9749 - val_loss: 0.2686 - val_accuracy: 0.8860\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0486 - accuracy: 0.9800 - val_loss: 0.2755 - val_accuracy: 0.9180\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0289 - accuracy: 0.9904 - val_loss: 0.3919 - val_accuracy: 0.9080\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0325 - accuracy: 0.9878 - val_loss: 0.4009 - val_accuracy: 0.9040\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0364 - accuracy: 0.9862 - val_loss: 0.3314 - val_accuracy: 0.8800\n",
      "Test loss: 0.5201157331466675\n",
      "Test accuracy: 0.859000027179718\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.3285\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3458 - accuracy: 0.8809 - val_loss: 0.3459 - val_accuracy: 0.9080\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.3183 - accuracy: 0.8991 - val_loss: 0.2713 - val_accuracy: 0.9080\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.3025 - accuracy: 0.8991 - val_loss: 0.2943 - val_accuracy: 0.9080\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2919 - accuracy: 0.8991 - val_loss: 0.2538 - val_accuracy: 0.9080\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2689 - accuracy: 0.8993 - val_loss: 0.2488 - val_accuracy: 0.9080\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2569 - accuracy: 0.9011 - val_loss: 0.2556 - val_accuracy: 0.9080\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2497 - accuracy: 0.9031 - val_loss: 0.2237 - val_accuracy: 0.9100\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2495 - accuracy: 0.9031 - val_loss: 0.2546 - val_accuracy: 0.9100\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2501 - accuracy: 0.9040 - val_loss: 0.2401 - val_accuracy: 0.9140\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2197 - accuracy: 0.9089 - val_loss: 0.2222 - val_accuracy: 0.9140\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2083 - accuracy: 0.9122 - val_loss: 0.2093 - val_accuracy: 0.9160\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1906 - accuracy: 0.9213 - val_loss: 0.2211 - val_accuracy: 0.9220\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1689 - accuracy: 0.9291 - val_loss: 0.2148 - val_accuracy: 0.9220\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1356 - accuracy: 0.9411 - val_loss: 0.2356 - val_accuracy: 0.9080\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1145 - accuracy: 0.9518 - val_loss: 0.2717 - val_accuracy: 0.9280\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1001 - accuracy: 0.9593 - val_loss: 0.2968 - val_accuracy: 0.9220\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0803 - accuracy: 0.9673 - val_loss: 0.2785 - val_accuracy: 0.9260\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0509 - accuracy: 0.9804 - val_loss: 0.3483 - val_accuracy: 0.9200\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0393 - accuracy: 0.9851 - val_loss: 0.3362 - val_accuracy: 0.9160\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0421 - accuracy: 0.9871 - val_loss: 0.3890 - val_accuracy: 0.9160\n",
      "Test loss: 0.5019069910049438\n",
      "Test accuracy: 0.9089999794960022\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.2075\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3460 - accuracy: 0.8780 - val_loss: 0.3092 - val_accuracy: 0.9080\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.3163 - accuracy: 0.8991 - val_loss: 0.2617 - val_accuracy: 0.9080\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2919 - accuracy: 0.8991 - val_loss: 0.2593 - val_accuracy: 0.9080\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2867 - accuracy: 0.8991 - val_loss: 0.2453 - val_accuracy: 0.9080\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2640 - accuracy: 0.8991 - val_loss: 0.2596 - val_accuracy: 0.9080\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2570 - accuracy: 0.9027 - val_loss: 0.2744 - val_accuracy: 0.9100\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2496 - accuracy: 0.9007 - val_loss: 0.2325 - val_accuracy: 0.9100\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2337 - accuracy: 0.9069 - val_loss: 0.2395 - val_accuracy: 0.9180\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2186 - accuracy: 0.9144 - val_loss: 0.2233 - val_accuracy: 0.9180\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1971 - accuracy: 0.9176 - val_loss: 0.2301 - val_accuracy: 0.9060\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2013 - accuracy: 0.9162 - val_loss: 0.2287 - val_accuracy: 0.9140\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1867 - accuracy: 0.9229 - val_loss: 0.2944 - val_accuracy: 0.8620\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1817 - accuracy: 0.9236 - val_loss: 0.2198 - val_accuracy: 0.9140\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1411 - accuracy: 0.9422 - val_loss: 0.2267 - val_accuracy: 0.9180\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1321 - accuracy: 0.9476 - val_loss: 0.2175 - val_accuracy: 0.9100\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1012 - accuracy: 0.9607 - val_loss: 0.2376 - val_accuracy: 0.9160\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0762 - accuracy: 0.9698 - val_loss: 0.2368 - val_accuracy: 0.9180\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1005 - accuracy: 0.9602 - val_loss: 0.2773 - val_accuracy: 0.8920\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0489 - accuracy: 0.9804 - val_loss: 0.3733 - val_accuracy: 0.9260\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0334 - accuracy: 0.9889 - val_loss: 0.3372 - val_accuracy: 0.9000\n",
      "Test loss: 0.4506409466266632\n",
      "Test accuracy: 0.9100000262260437\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.2245\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3269 - accuracy: 0.8793 - val_loss: 0.2590 - val_accuracy: 0.9080\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2992 - accuracy: 0.8991 - val_loss: 0.2828 - val_accuracy: 0.9080\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2782 - accuracy: 0.8991 - val_loss: 0.2508 - val_accuracy: 0.9080\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2670 - accuracy: 0.8993 - val_loss: 0.2372 - val_accuracy: 0.9080\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2479 - accuracy: 0.9020 - val_loss: 0.2306 - val_accuracy: 0.9120\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2338 - accuracy: 0.9087 - val_loss: 0.2590 - val_accuracy: 0.9080\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2323 - accuracy: 0.9073 - val_loss: 0.2474 - val_accuracy: 0.9000\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2353 - accuracy: 0.9091 - val_loss: 0.2486 - val_accuracy: 0.9020\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2089 - accuracy: 0.9136 - val_loss: 0.2166 - val_accuracy: 0.9120\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1817 - accuracy: 0.9242 - val_loss: 0.2641 - val_accuracy: 0.9140\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1742 - accuracy: 0.9264 - val_loss: 0.2181 - val_accuracy: 0.9180\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1574 - accuracy: 0.9336 - val_loss: 0.2451 - val_accuracy: 0.9100\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1322 - accuracy: 0.9447 - val_loss: 0.2506 - val_accuracy: 0.8980\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1131 - accuracy: 0.9527 - val_loss: 0.2766 - val_accuracy: 0.8980\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0909 - accuracy: 0.9620 - val_loss: 0.2938 - val_accuracy: 0.9160\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0689 - accuracy: 0.9722 - val_loss: 0.3062 - val_accuracy: 0.9000\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0731 - accuracy: 0.9704 - val_loss: 0.3634 - val_accuracy: 0.9060\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0480 - accuracy: 0.9816 - val_loss: 0.3628 - val_accuracy: 0.9000\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0348 - accuracy: 0.9873 - val_loss: 0.4506 - val_accuracy: 0.8800\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0254 - accuracy: 0.9900 - val_loss: 0.5848 - val_accuracy: 0.9040\n",
      "Test loss: 0.6052525043487549\n",
      "Test accuracy: 0.8870000243186951\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.3265\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3565 - accuracy: 0.8951 - val_loss: 0.3142 - val_accuracy: 0.9080\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.3137 - accuracy: 0.8991 - val_loss: 0.2854 - val_accuracy: 0.9080\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2816 - accuracy: 0.8991 - val_loss: 0.2608 - val_accuracy: 0.9080\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2743 - accuracy: 0.8991 - val_loss: 0.2491 - val_accuracy: 0.9080\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2619 - accuracy: 0.9007 - val_loss: 0.2455 - val_accuracy: 0.9100\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2563 - accuracy: 0.9020 - val_loss: 0.2412 - val_accuracy: 0.9080\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2523 - accuracy: 0.9033 - val_loss: 0.2268 - val_accuracy: 0.9100\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2310 - accuracy: 0.9060 - val_loss: 0.2298 - val_accuracy: 0.9120\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2181 - accuracy: 0.9127 - val_loss: 0.2161 - val_accuracy: 0.9200\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2082 - accuracy: 0.9147 - val_loss: 0.2110 - val_accuracy: 0.9200\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1776 - accuracy: 0.9276 - val_loss: 0.2738 - val_accuracy: 0.9180\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1791 - accuracy: 0.9267 - val_loss: 0.2171 - val_accuracy: 0.9160\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1619 - accuracy: 0.9289 - val_loss: 0.2378 - val_accuracy: 0.9020\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1421 - accuracy: 0.9411 - val_loss: 0.2138 - val_accuracy: 0.9320\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1000 - accuracy: 0.9618 - val_loss: 0.2370 - val_accuracy: 0.9160\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0986 - accuracy: 0.9611 - val_loss: 0.3149 - val_accuracy: 0.9220\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0786 - accuracy: 0.9689 - val_loss: 0.2894 - val_accuracy: 0.9260\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0834 - accuracy: 0.9691 - val_loss: 0.2538 - val_accuracy: 0.9160\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0494 - accuracy: 0.9800 - val_loss: 0.3078 - val_accuracy: 0.9100\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0304 - accuracy: 0.9896 - val_loss: 0.3279 - val_accuracy: 0.9160\n",
      "Test loss: 0.6124502420425415\n",
      "Test accuracy: 0.8939999938011169\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.1505\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3657 - accuracy: 0.8980 - val_loss: 0.2867 - val_accuracy: 0.9080\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.3008 - accuracy: 0.8991 - val_loss: 0.3274 - val_accuracy: 0.9080\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2955 - accuracy: 0.8991 - val_loss: 0.2551 - val_accuracy: 0.9080\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2815 - accuracy: 0.8991 - val_loss: 0.2489 - val_accuracy: 0.9080\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2749 - accuracy: 0.8993 - val_loss: 0.2403 - val_accuracy: 0.9080\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2761 - accuracy: 0.9002 - val_loss: 0.2487 - val_accuracy: 0.9080\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2560 - accuracy: 0.9022 - val_loss: 0.2448 - val_accuracy: 0.9120\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2517 - accuracy: 0.9051 - val_loss: 0.2402 - val_accuracy: 0.9140\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2459 - accuracy: 0.9058 - val_loss: 0.2612 - val_accuracy: 0.9120\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2388 - accuracy: 0.9073 - val_loss: 0.2193 - val_accuracy: 0.9180\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2205 - accuracy: 0.9133 - val_loss: 0.2184 - val_accuracy: 0.9200\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2010 - accuracy: 0.9158 - val_loss: 0.2279 - val_accuracy: 0.9180\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1864 - accuracy: 0.9242 - val_loss: 0.2203 - val_accuracy: 0.9160\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1778 - accuracy: 0.9220 - val_loss: 0.2134 - val_accuracy: 0.9160\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1545 - accuracy: 0.9342 - val_loss: 0.2196 - val_accuracy: 0.9180\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1495 - accuracy: 0.9356 - val_loss: 0.2211 - val_accuracy: 0.9240\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1247 - accuracy: 0.9467 - val_loss: 0.2446 - val_accuracy: 0.9120\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1028 - accuracy: 0.9569 - val_loss: 0.3099 - val_accuracy: 0.9200\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0837 - accuracy: 0.9640 - val_loss: 0.2866 - val_accuracy: 0.8820\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0735 - accuracy: 0.9716 - val_loss: 0.4018 - val_accuracy: 0.9260\n",
      "Test loss: 0.5007302165031433\n",
      "Test accuracy: 0.9079999923706055\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.1475\n",
      "      通し番号  カウント\n",
      "0        0     0\n",
      "1        1     3\n",
      "2        2     5\n",
      "3        3     2\n",
      "4        4     5\n",
      "...    ...   ...\n",
      "1995  1995     1\n",
      "1996  1996     3\n",
      "1997  1997     2\n",
      "1998  1998     0\n",
      "1999  1999     1\n",
      "\n",
      "[2000 rows x 2 columns]\n",
      "[0.2895, 0.064, 0.315, 0.075, 0.3285, 0.2075, 0.2245, 0.3265, 0.1505, 0.1475]\n",
      "11\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[1951, 1670, 358, 357, 70, 355, 1722, 1675, 354, 1677, 1721, 1961, 319, 55, 1668, 360, 1681, 370, 1661, 312, 369, 45, 368, 366, 313, 314, 52, 1964, 317, 363, 1666, 361, 351, 1683, 1682, 1956, 1700, 1701, 324, 338, 325, 336, 59, 326, 343, 63, 1707, 332, 331, 1710, 64, 1952, 342, 1697, 1950, 1689, 1684, 1685, 1960, 1719, 320, 1687, 1688, 348, 1696, 347, 322, 1693, 1716, 323, 1695, 1958, 344, 385, 1659, 417, 1598, 1599, 1600, 1985, 433, 432, 28, 1605, 430, 424, 1608, 422, 420, 419, 1612, 1613, 1614, 1615, 418, 1597, 1596, 1987, 446, 1998, 7, 1580, 451, 8, 9, 1584, 447, 16, 1594, 445, 443, 1589, 17, 442, 18, 1592, 21, 1983, 1618, 371, 415, 392, 1640, 1641, 40, 1970, 1643, 389, 388, 1646, 1647, 1648, 387, 380, 376, 1653, 1654, 375, 43, 373, 39, 393, 1973, 1978, 414, 1621, 1622, 31, 1981, 32, 1624, 34, 407, 399, 405, 1977, 1629, 36, 1632, 402, 1974, 400, 311, 1896, 1948, 1844, 178, 1837, 177, 1839, 1915, 1840, 1841, 176, 174, 172, 306, 1914, 1847, 168, 1849, 165, 1913, 1853, 96, 1854, 1916, 181, 94, 184, 207, 203, 1817, 202, 1819, 201, 200, 196, 1823, 1921, 1920, 192, 1827, 1828, 1829, 91, 92, 190, 188, 1855, 158, 1857, 124, 122, 1879, 105, 1880, 120, 1882, 119, 1884, 117, 106, 1899, 112, 111, 1890, 1891, 109, 110, 1893, 1894, 1902, 1903, 1858, 133, 154, 153, 1910, 1862, 98, 148, 100, 147, 142, 1906, 140, 103, 139, 1869, 104, 1870, 138, 1872, 135, 1814, 1813, 1812, 286, 284, 283, 84, 282, 1939, 278, 277, 1938, 1757, 1758, 272, 269, 267, 1937, 1762, 1763, 266, 1936, 262, 285, 1747, 85, 1941, 1730, 1731, 1732, 73, 1895, 1735, 302, 300, 81, 82, 299, 296, 294, 1741, 1943, 293, 1743, 292, 83, 260, 258, 211, 231, 1928, 1794, 1795, 1927, 1797, 228, 1799, 87, 224, 222, 1802, 221, 1805, 218, 1924, 214, 213, 1923, 90, 1792, 233, 1770, 1929, 1934, 86, 252, 1932, 1775, 1776, 1777, 249, 246, 1780, 1781, 1931, 1783, 1930, 243, 242, 240, 1578, 237, 304, 1533, 1577, 1257, 1228, 857, 1231, 1232, 854, 1234, 852, 1238, 850, 849, 848, 847, 1243, 1245, 843, 1247, 841, 839, 838, 837, 835, 834, 830, 1226, 864, 865, 884, 1196, 899, 1200, 1201, 896, 1203, 894, 893, 1206, 886, 880, 1221, 879, 1212, 874, 872, 869, 868, 1217, 867, 1219, 1220, 826, 824, 905, 821, 779, 778, 1294, 773, 772, 771, 1299, 1300, 1301, 768, 1304, 1305, 765, 1307, 756, 1311, 1312, 755, 754, 1315, 1316, 753, 1318, 1291, 780, 1289, 802, 818, 817, 815, 814, 813, 811, 808, 1268, 1269, 1270, 800, 781, 797, 795, 787, 785, 1282, 1283, 783, 1285, 782, 1287, 1195, 1193, 456, 981, 1099, 1100, 1015, 1102, 1012, 1011, 1007, 1107, 1109, 1110, 997, 996, 1115, 995, 1117, 1119, 1120, 1121, 1122, 993, 992, 990, 989, 1017, 1020, 1021, 1080, 1069, 1063, 1071, 1062, 1073, 1053, 1052, 1046, 1078, 1079, 1040, 1025, 1083, 1034, 1033, 1030, 1088, 1029, 1028, 1091, 1027, 1093, 987, 1131, 1192, 1133, 1166, 940, 1169, 1170, 1171, 937, 1174, 1175, 1176, 928, 926, 924, 923, 919, 1183, 1184, 1185, 917, 1187, 916, 1189, 912, 910, 949, 951, 1161, 1144, 977, 1135, 975, 1137, 972, 970, 969, 1141, 968, 1143, 1145, 1160, 964, 963, 959, 958, 956, 1153, 1154, 1156, 1158, 1159, 1319, 751, 750, 536, 570, 567, 1482, 564, 1484, 1485, 562, 1488, 558, 555, 1492, 553, 552, 551, 1497, 546, 1499, 544, 1502, 542, 541, 540, 1507, 1479, 574, 1477, 1458, 607, 1448, 603, 1450, 601, 600, 1453, 599, 1456, 596, 1459, 577, 1461, 594, 592, 591, 588, 1469, 1470, 583, 581, 580, 1508, 1510, 749, 535, 1542, 1543, 1545, 496, 493, 1548, 1550, 1551, 490, 486, 1555, 1557, 484, 480, 479, 1562, 476, 1565, 471, 466, 465, 462, 459, 1541, 1540, 498, 1525, 533, 529, 1515, 528, 1517, 1520, 1521, 1522, 523, 522, 517, 1538, 512, 510, 504, 503, 502, 1065, 1534, 500, 499, 1537, 608, 611, 614, 616, 1353, 721, 1355, 1356, 720, 1358, 718, 1360, 713, 707, 705, 1365, 1366, 1367, 1368, 703, 697, 694, 693, 1374, 1375, 1376, 1377, 722, 726, 1349, 738, 1323, 748, 747, 1327, 1328, 744, 1330, 1331, 742, 741, 1335, 1348, 735, 733, 729, 1341, 727, 1343, 1344, 1345, 1346, 1347, 685, 684, 1383, 1430, 644, 642, 638, 637, 635, 634, 1426, 632, 1428, 631, 1431, 646, 628, 1434, 1435, 626, 624, 623, 622, 621, 620, 619, 1417, 647, 1384, 666, 681, 1387, 1388, 1389, 678, 674, 1393, 671, 1396, 668, 1399, 1414, 662, 1402, 660, 1404, 658, 1406, 1407, 1408, 656, 655, 0, 1397, 1113, 1405, 1295, 1863, 1398, 1868, 1116, 1874, 1556, 1861, 1123, 1433, 1429, 1818, 1427, 1826, 1421, 1415, 1411, 1410, 1845, 1876, 1850, 1292, 1859, 1860, 1296, 1386, 1877, 1352, 1963, 1310, 1313, 1966, 1967, 1314, 1972, 1979, 1982, 1320, 1953, 1351, 1986, 1990, 1322, 1992, 1350, 1325, 1995, 1338, 1962, 1362, 1878, 1908, 1392, 1889, 1897, 1900, 1901, 1098, 1097, 1905, 1439, 1911, 1308, 1912, 1379, 1919, 1925, 1933, 1940, 1373, 1946, 1371, 1815, 1778, 1441, 1503, 1610, 1617, 1526, 1627, 1524, 1254, 1519, 1639, 1509, 1649, 1530, 1650, 1198, 1500, 1656, 1337, 1259, 1669, 1671, 1673, 1208, 1209, 1139, 1573, 1560, 1236, 1235, 1563, 1244, 1568, 1227, 1571, 1572, 1574, 1210, 1248, 1546, 1583, 1586, 1591, 1536, 1213, 1595, 1604, 1678, 1679, 1680, 1274, 1750, 1267, 1756, 1759, 1476, 1764, 1475, 1164, 1162, 1468, 1686, 1773, 1559, 1466, 1785, 1465, 1149, 1791, 1798, 1142, 1739, 1173, 1177, 1737, 1495, 1691, 1261, 1698, 1699, 1182, 1494, 1704, 1708, 1493, 1714, 1491, 1179, 1723, 1264, 1724, 1726, 1729, 1736, 1068, 1999, 1066, 256, 220, 766, 762, 759, 229, 230, 235, 745, 244, 736, 250, 731, 255, 259, 901, 265, 724, 274, 281, 708, 287, 289, 692, 691, 688, 686, 682, 305, 215, 212, 777, 194, 115, 116, 877, 123, 131, 866, 862, 860, 856, 149, 152, 853, 851, 846, 161, 164, 170, 829, 820, 180, 182, 806, 805, 804, 794, 789, 193, 677, 307, 670, 543, 403, 404, 534, 408, 409, 526, 524, 411, 514, 431, 436, 497, 492, 439, 491, 440, 485, 441, 482, 478, 469, 467, 448, 449, 464, 452, 455, 401, 396, 664, 545, 654, 649, 648, 328, 643, 333, 640, 335, 340, 630, 346, 350, 352, 353, 597, 359, 595, 587, 586, 585, 584, 582, 374, 563, 557, 390, 550, 900, 239, 453, 57, 60, 97, 994, 935, 95, 89, 58, 939, 965, 961, 37, 1018, 22, 944, 998, 1005, 950, 953, 41, 1006, 42, 982, 955, 1009, 1036, 954, 108, 80, 11, 1061, 1041, 986, 19, 978, 13, 871, 890, 908, 1072, 902, 903, 907, 1211, 845, 888, 1230, 878, 1074, 1060, 1044, 883, 758, 895, 1309, 861, 1077, 891, 1045, 1216, 764, 775, 1246, 929, 931, 827, 1168, 941, 790, 1262, 1263, 1266, 979, 810, 1134, 807, 967, 966, 1157, 1271, 1272, 1147, 1273, 803, 798, 1281, 831, 842, 927, 1032, 1031, 1089, 840, 1250, 914, 1095, 836, 1019, 1013, 920, 774, 1010, 921, 1106, 1108, 922, 1288, 1286, 1002, 1001, 876, 1000, 739, 1667, 1690, 345, 1703, 1712, 1718, 316, 1733, 297, 290, 1746, 1751, 1753, 275, 1761, 263, 1769, 1771, 1772, 253, 1779, 1787, 227, 226, 1674, 1664, 487, 381, 1564, 475, 472, 461, 457, 454, 1579, 1588, 1593, 437, 434, 428, 425, 423, 410, 1628, 1634, 1635, 398, 1637, 1642, 1645, 384, 1801, 219, 1811, 210, 93, 1918, 1944, 78, 77, 76, 72, 65, 1955, 53, 50, 47, 1969, 1971, 30, 27, 24, 1991, 1994, 10, 1997, 5, 3, 99, 102, 1887, 1838, 209, 206, 205, 1821, 198, 186, 185, 183, 1834, 1835, 1843, 1885, 159, 155, 145, 143, 132, 130, 129, 127, 121, 118, 477, 362, 717, 719, 1531, 1473, 1474, 1359, 508, 511, 1489, 716, 657, 699, 549, 531, 532, 1380, 1480, 565, 561, 1501, 1486, 1487, 689, 1413, 1532, 1549, 1416, 734, 613, 728, 672, 489, 612, 1553, 1552, 604, 1460, 593, 673, 1498, 1547, 1390, 1425, 1423, 665, 1539, 162, 171, 1790, 173, 791, 1796, 1148, 1457, 1146, 1452, 223, 602, 1444, 199, 999, 1833, 1442, 793, 983, 1438, 985, 625, 175, 1128, 1114, 1401, 1, 1048, 68, 700, 67, 66, 61, 1959, 1364, 1082, 56, 760, 51, 1968, 1354, 1370, 723, 1051, 23, 1324, 1342, 1989, 15, 1996, 1329, 743, 1336, 1070, 698, 1947, 1871, 1395, 136, 784, 1284, 1873, 650, 134, 1293, 1004, 126, 590, 1008, 1103, 1394, 763, 1888, 1892, 1898, 769, 680, 1385, 88, 1087, 79, 75, 74, 1372, 1464, 740, 435, 463, 1706, 892, 330, 832, 1711, 925, 1725, 1518, 310, 943, 309, 1728, 889, 1738, 298, 938, 1256, 460, 470, 833, 1786, 1202, 1242, 495, 1249, 1652, 349, 377, 1199, 898, 1233, 1694, 341, 339, 507, 1229, 337, 1529, 474, 1222, 828, 822, 881, 426, 1215, 416, 427, 809, 1481, 568, 569, 1768, 268, 1163, 257, 1155, 444, 1152, 1603, 1214, 1471, 264, 1165, 1265, 946, 1496, 1755, 279, 1218, 554, 1754, 1260, 273, 458, 659, 1516, 1252, 627, 629, 801, 752, 525, 1506, 506, 746, 1403, 730, 1317, 799, 1253, 509, 1528, 663, 610, 609, 1587, 1590, 576, 1569, 757, 714, 1303, 1240, 1505, 538, 1258, 823, 1558, 488, 483, 548, 819, 519, 1418, 1561, 704, 473, 560, 1566, 1483, 683, 571, 1251, 573, 633, 786, 1570, 1279, 770, 1660, 191, 379, 904, 69, 367, 1003, 1713, 1875, 1740, 1127, 1820, 1766, 897, 974, 208, 971, 1765, 1742, 1172, 1709, 179, 909, 1848, 945, 1191, 1922, 1752, 913, 1022, 1881, 169, 1101, 280, 1809, 1644, 1808, 248, 930, 1607, 882, 1124, 150, 1057, 137, 216, 1151, 1782, 232, 236, 1602, 1064, 1774, 1800, 991, 295, 394, 1205, 54, 217, 1043, 952, 1976, 33, 35, 1126, 887, 1623, 413, 1241, 1926, 515, 1942, 1306, 1381, 1086, 1705, 1676, 356, 494, 107, 1544, 911, 1382, 501, 1692, 1024, 1302, 679, 1907, 101, 676, 1554, 1807, 690, 48, 1633, 1050, 29, 412, 26, 1620, 1054, 20, 1611, 885, 1609, 1059, 450, 4, 2, 873, 875, 46, 397, 1333, 49, 695, 372, 1084, 696, 702, 1037, 1014, 382, 383, 1237, 706, 858, 391, 1363, 709, 1965, 710, 1957, 1297, 559, 1842, 151, 1118, 547, 276, 636, 1490, 1852, 988, 948, 812, 566, 166, 1767, 167, 1437, 288, 1836, 247, 792, 618, 1129, 1275, 187, 195, 1463, 1455, 225, 1803, 1810, 1446, 1748, 1513, 1727, 1255, 652, 1178, 1514, 308, 1419, 1867, 144, 1511, 1409, 776, 537, 1744, 1104, 1715, 1451, 1804, 1784, 241, 1789, 1454, 962, 1793, 1472, 957, 1806, 1527, 251, 1225, 1657, 1655, 1239, 481, 1567, 859, 1636, 863, 578, 1625, 1575, 421, 1582, 1585, 870, 1606, 1662, 1663, 364, 1194, 254, 816, 825, 1749, 936, 934, 1717, 518, 516, 334, 505, 915, 1190, 1672, 906, 605, 438, 675, 1866, 725, 125, 1111, 1075, 1035, 1432, 1917, 651, 1412, 1420, 1851, 1440, 1424, 1038, 157, 156, 687, 1865, 71, 1864, 1280, 1422, 984, 1984, 669, 197, 1136, 976, 615, 1445, 1096, 1132, 732, 973, 1326, 1138, 1339, 1822, 1447, 1886, 14, 1443, 1298, 189, 667, 932, 141, 527, 1988, 1512, 1290, 1067, 653, 25, 645, 1224, 291, 1734, 539, 1504, 1745, 270, 245, 1332, 1478, 788, 572, 429, 6, 1140, 271, 639, 160, 1856, 1993, 1576, 1125, 1058, 1321, 1340, 1523, 1658, 1980, 1092, 1831, 395, 1462, 1042, 1023, 1188, 1830, 1081, 1535, 1904, 1090, 1039, 767, 1945, 1665, 365, 1277, 701, 468, 238, 1816, 113, 318, 1357, 1276, 1049, 321, 1130, 513, 1630, 1180, 1047, 327, 715, 1361, 712, 521, 1788, 844, 1760, 163, 1026, 1824, 1085, 947, 261, 575, 579, 1186, 1467, 661, 942, 1150, 1016, 1112, 933, 980, 303, 520, 1883, 1378, 315, 1400, 589, 1436, 598, 62, 1616, 711, 1207, 204, 1619, 1581, 1204, 1369, 855, 1651, 1626, 1601, 406, 1975, 1954, 378, 606, 1825, 1638, 1702, 761, 918, 1631, 1181, 114, 1909, 1720, 1167, 1846, 1449, 12, 1076, 796, 530, 556, 1223, 1056, 301, 641, 617, 386, 128, 44, 329, 1832, 1055, 960, 146, 1391, 1105, 1094, 38, 1197, 737, 1949, 1278, 1334, 234, 1935]\n",
      "500\n",
      "500\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3582 - accuracy: 0.8904 - val_loss: 0.3144 - val_accuracy: 0.9060\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.3283 - accuracy: 0.8993 - val_loss: 0.3241 - val_accuracy: 0.9060\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.3079 - accuracy: 0.8993 - val_loss: 0.2963 - val_accuracy: 0.9060\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2880 - accuracy: 0.8993 - val_loss: 0.3376 - val_accuracy: 0.9060\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2850 - accuracy: 0.8993 - val_loss: 0.2946 - val_accuracy: 0.9060\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2787 - accuracy: 0.8996 - val_loss: 0.2813 - val_accuracy: 0.9060\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2617 - accuracy: 0.8993 - val_loss: 0.2951 - val_accuracy: 0.9060\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2532 - accuracy: 0.8991 - val_loss: 0.2807 - val_accuracy: 0.9060\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2537 - accuracy: 0.9013 - val_loss: 0.2916 - val_accuracy: 0.9020\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2445 - accuracy: 0.9004 - val_loss: 0.3257 - val_accuracy: 0.9060\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2424 - accuracy: 0.9020 - val_loss: 0.3126 - val_accuracy: 0.9040\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2210 - accuracy: 0.9067 - val_loss: 0.3240 - val_accuracy: 0.8960\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2217 - accuracy: 0.9076 - val_loss: 0.3196 - val_accuracy: 0.9060\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2024 - accuracy: 0.9131 - val_loss: 0.3227 - val_accuracy: 0.8920\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1796 - accuracy: 0.9207 - val_loss: 0.3465 - val_accuracy: 0.8840\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1699 - accuracy: 0.9289 - val_loss: 0.3564 - val_accuracy: 0.8760\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1527 - accuracy: 0.9409 - val_loss: 0.3843 - val_accuracy: 0.8960\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1334 - accuracy: 0.9504 - val_loss: 0.4475 - val_accuracy: 0.8880\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1017 - accuracy: 0.9600 - val_loss: 0.4966 - val_accuracy: 0.8960\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0903 - accuracy: 0.9642 - val_loss: 0.4867 - val_accuracy: 0.8720\n",
      "Test loss: 0.3835422694683075\n",
      "Test accuracy: 0.8740000128746033\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.3285\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3457 - accuracy: 0.8791 - val_loss: 0.3016 - val_accuracy: 0.9060\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.3064 - accuracy: 0.8993 - val_loss: 0.2838 - val_accuracy: 0.9060\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2865 - accuracy: 0.8991 - val_loss: 0.2780 - val_accuracy: 0.9060\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2721 - accuracy: 0.8987 - val_loss: 0.2914 - val_accuracy: 0.9060\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2735 - accuracy: 0.8996 - val_loss: 0.2915 - val_accuracy: 0.9060\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2586 - accuracy: 0.8996 - val_loss: 0.2826 - val_accuracy: 0.9060\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2518 - accuracy: 0.8996 - val_loss: 0.2836 - val_accuracy: 0.9040\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2404 - accuracy: 0.9004 - val_loss: 0.2894 - val_accuracy: 0.9000\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2465 - accuracy: 0.9013 - val_loss: 0.2891 - val_accuracy: 0.9040\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2263 - accuracy: 0.9042 - val_loss: 0.3025 - val_accuracy: 0.8920\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2065 - accuracy: 0.9138 - val_loss: 0.3046 - val_accuracy: 0.8960\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2013 - accuracy: 0.9153 - val_loss: 0.3341 - val_accuracy: 0.9020\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1923 - accuracy: 0.9224 - val_loss: 0.3139 - val_accuracy: 0.8900\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1804 - accuracy: 0.9287 - val_loss: 0.3372 - val_accuracy: 0.8820\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1503 - accuracy: 0.9360 - val_loss: 0.3405 - val_accuracy: 0.9100\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1373 - accuracy: 0.9411 - val_loss: 0.4185 - val_accuracy: 0.8940\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1131 - accuracy: 0.9551 - val_loss: 0.4774 - val_accuracy: 0.8920\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0892 - accuracy: 0.9644 - val_loss: 0.4545 - val_accuracy: 0.8640\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0749 - accuracy: 0.9716 - val_loss: 0.6776 - val_accuracy: 0.8480\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0671 - accuracy: 0.9749 - val_loss: 0.5818 - val_accuracy: 0.8800\n",
      "Test loss: 0.49339792132377625\n",
      "Test accuracy: 0.8840000033378601\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.1585\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3574 - accuracy: 0.8882 - val_loss: 0.3086 - val_accuracy: 0.9060\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.3046 - accuracy: 0.8993 - val_loss: 0.2840 - val_accuracy: 0.9060\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2873 - accuracy: 0.8993 - val_loss: 0.2931 - val_accuracy: 0.9060\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2838 - accuracy: 0.8993 - val_loss: 0.2992 - val_accuracy: 0.9060\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2750 - accuracy: 0.8991 - val_loss: 0.2913 - val_accuracy: 0.9060\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2704 - accuracy: 0.8996 - val_loss: 0.2891 - val_accuracy: 0.9060\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2679 - accuracy: 0.8989 - val_loss: 0.2963 - val_accuracy: 0.9060\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2497 - accuracy: 0.9002 - val_loss: 0.3009 - val_accuracy: 0.9040\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2531 - accuracy: 0.9020 - val_loss: 0.2964 - val_accuracy: 0.9060\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2422 - accuracy: 0.9029 - val_loss: 0.3084 - val_accuracy: 0.9040\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2260 - accuracy: 0.9060 - val_loss: 0.3095 - val_accuracy: 0.8940\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2153 - accuracy: 0.9080 - val_loss: 0.3353 - val_accuracy: 0.8720\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2114 - accuracy: 0.9118 - val_loss: 0.3367 - val_accuracy: 0.9100\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1925 - accuracy: 0.9138 - val_loss: 0.3696 - val_accuracy: 0.9000\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1884 - accuracy: 0.9202 - val_loss: 0.3480 - val_accuracy: 0.8940\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1671 - accuracy: 0.9282 - val_loss: 0.3716 - val_accuracy: 0.8880\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1472 - accuracy: 0.9389 - val_loss: 0.3388 - val_accuracy: 0.8840\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1404 - accuracy: 0.9422 - val_loss: 0.4094 - val_accuracy: 0.9000\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1066 - accuracy: 0.9542 - val_loss: 0.4144 - val_accuracy: 0.8840\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0888 - accuracy: 0.9636 - val_loss: 0.5130 - val_accuracy: 0.8920\n",
      "Test loss: 0.4827166795730591\n",
      "Test accuracy: 0.890999972820282\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.234\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3491 - accuracy: 0.8831 - val_loss: 0.3189 - val_accuracy: 0.9060\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.3183 - accuracy: 0.8993 - val_loss: 0.2918 - val_accuracy: 0.9060\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2922 - accuracy: 0.8993 - val_loss: 0.3188 - val_accuracy: 0.9060\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2794 - accuracy: 0.8993 - val_loss: 0.2880 - val_accuracy: 0.9060\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2732 - accuracy: 0.8993 - val_loss: 0.2920 - val_accuracy: 0.9060\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2681 - accuracy: 0.8996 - val_loss: 0.2929 - val_accuracy: 0.9060\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2627 - accuracy: 0.8991 - val_loss: 0.3220 - val_accuracy: 0.9060\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2595 - accuracy: 0.8987 - val_loss: 0.2909 - val_accuracy: 0.9060\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2343 - accuracy: 0.9004 - val_loss: 0.2967 - val_accuracy: 0.9020\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2272 - accuracy: 0.9027 - val_loss: 0.3068 - val_accuracy: 0.9060\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2197 - accuracy: 0.9064 - val_loss: 0.2990 - val_accuracy: 0.9040\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2101 - accuracy: 0.9107 - val_loss: 0.3436 - val_accuracy: 0.8920\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2061 - accuracy: 0.9109 - val_loss: 0.3450 - val_accuracy: 0.9000\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1885 - accuracy: 0.9184 - val_loss: 0.3646 - val_accuracy: 0.8900\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1683 - accuracy: 0.9289 - val_loss: 0.4417 - val_accuracy: 0.8980\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1420 - accuracy: 0.9429 - val_loss: 0.4355 - val_accuracy: 0.8980\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1406 - accuracy: 0.9449 - val_loss: 0.4628 - val_accuracy: 0.8600\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1110 - accuracy: 0.9562 - val_loss: 0.5215 - val_accuracy: 0.8760\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0858 - accuracy: 0.9658 - val_loss: 0.4753 - val_accuracy: 0.8620\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0623 - accuracy: 0.9762 - val_loss: 0.5703 - val_accuracy: 0.8820\n",
      "Test loss: 0.4957055151462555\n",
      "Test accuracy: 0.8790000081062317\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.267\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3497 - accuracy: 0.8769 - val_loss: 0.2949 - val_accuracy: 0.9060\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2991 - accuracy: 0.8993 - val_loss: 0.3194 - val_accuracy: 0.9060\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2807 - accuracy: 0.8993 - val_loss: 0.3471 - val_accuracy: 0.9060\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2793 - accuracy: 0.8993 - val_loss: 0.2845 - val_accuracy: 0.9060\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2703 - accuracy: 0.8991 - val_loss: 0.2800 - val_accuracy: 0.9060\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2575 - accuracy: 0.8989 - val_loss: 0.2833 - val_accuracy: 0.9060\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2461 - accuracy: 0.8998 - val_loss: 0.3700 - val_accuracy: 0.9060\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2412 - accuracy: 0.9009 - val_loss: 0.2955 - val_accuracy: 0.9060\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2303 - accuracy: 0.9004 - val_loss: 0.2926 - val_accuracy: 0.9000\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2196 - accuracy: 0.9042 - val_loss: 0.3031 - val_accuracy: 0.8900\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2159 - accuracy: 0.9087 - val_loss: 0.3198 - val_accuracy: 0.9020\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1939 - accuracy: 0.9164 - val_loss: 0.3330 - val_accuracy: 0.8560\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1958 - accuracy: 0.9193 - val_loss: 0.3810 - val_accuracy: 0.9020\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1803 - accuracy: 0.9236 - val_loss: 0.3761 - val_accuracy: 0.8960\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1564 - accuracy: 0.9360 - val_loss: 0.4044 - val_accuracy: 0.8680\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1336 - accuracy: 0.9444 - val_loss: 0.5351 - val_accuracy: 0.8880\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1268 - accuracy: 0.9527 - val_loss: 0.4596 - val_accuracy: 0.8940\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1024 - accuracy: 0.9587 - val_loss: 0.5350 - val_accuracy: 0.8800\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0753 - accuracy: 0.9693 - val_loss: 0.6133 - val_accuracy: 0.8920\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0651 - accuracy: 0.9762 - val_loss: 0.7279 - val_accuracy: 0.8940\n",
      "Test loss: 0.57968670129776\n",
      "Test accuracy: 0.8859999775886536\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.2965\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 0.3611 - accuracy: 0.8949 - val_loss: 0.2993 - val_accuracy: 0.9060\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.3038 - accuracy: 0.8993 - val_loss: 0.3244 - val_accuracy: 0.9060\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2862 - accuracy: 0.8993 - val_loss: 0.2805 - val_accuracy: 0.9060\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2729 - accuracy: 0.8996 - val_loss: 0.2926 - val_accuracy: 0.9060\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2724 - accuracy: 0.8989 - val_loss: 0.2824 - val_accuracy: 0.9060\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2594 - accuracy: 0.9004 - val_loss: 0.2875 - val_accuracy: 0.9060\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2581 - accuracy: 0.9002 - val_loss: 0.3027 - val_accuracy: 0.9060\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2487 - accuracy: 0.9004 - val_loss: 0.3110 - val_accuracy: 0.9060\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2424 - accuracy: 0.9029 - val_loss: 0.3015 - val_accuracy: 0.8960\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2333 - accuracy: 0.9024 - val_loss: 0.3291 - val_accuracy: 0.9040\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2221 - accuracy: 0.9087 - val_loss: 0.3164 - val_accuracy: 0.9060\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2258 - accuracy: 0.9136 - val_loss: 0.3005 - val_accuracy: 0.9040\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2021 - accuracy: 0.9160 - val_loss: 0.3382 - val_accuracy: 0.8860\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1882 - accuracy: 0.9207 - val_loss: 0.3565 - val_accuracy: 0.8840\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1687 - accuracy: 0.9293 - val_loss: 0.3308 - val_accuracy: 0.8860\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1387 - accuracy: 0.9451 - val_loss: 0.4051 - val_accuracy: 0.8900\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1184 - accuracy: 0.9518 - val_loss: 0.4614 - val_accuracy: 0.8820\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0912 - accuracy: 0.9638 - val_loss: 0.4995 - val_accuracy: 0.8580\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1005 - accuracy: 0.9618 - val_loss: 0.5018 - val_accuracy: 0.8820\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0625 - accuracy: 0.9798 - val_loss: 0.7307 - val_accuracy: 0.8960\n",
      "Test loss: 0.7257777452468872\n",
      "Test accuracy: 0.8989999890327454\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.2745\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3366 - accuracy: 0.8871 - val_loss: 0.3007 - val_accuracy: 0.9060\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.3050 - accuracy: 0.8993 - val_loss: 0.2881 - val_accuracy: 0.9060\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2817 - accuracy: 0.8987 - val_loss: 0.2848 - val_accuracy: 0.9060\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2720 - accuracy: 0.9000 - val_loss: 0.3380 - val_accuracy: 0.9060\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2721 - accuracy: 0.8996 - val_loss: 0.2951 - val_accuracy: 0.9060\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2534 - accuracy: 0.9022 - val_loss: 0.3034 - val_accuracy: 0.9080\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2426 - accuracy: 0.9024 - val_loss: 0.3439 - val_accuracy: 0.9060\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2322 - accuracy: 0.9044 - val_loss: 0.3453 - val_accuracy: 0.8600\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2323 - accuracy: 0.9044 - val_loss: 0.3136 - val_accuracy: 0.8980\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2174 - accuracy: 0.9136 - val_loss: 0.3644 - val_accuracy: 0.8980\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1988 - accuracy: 0.9167 - val_loss: 0.3999 - val_accuracy: 0.8740\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1711 - accuracy: 0.9300 - val_loss: 0.4345 - val_accuracy: 0.8780\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1688 - accuracy: 0.9304 - val_loss: 0.4146 - val_accuracy: 0.8840\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1573 - accuracy: 0.9342 - val_loss: 0.4134 - val_accuracy: 0.8900\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1232 - accuracy: 0.9527 - val_loss: 0.4503 - val_accuracy: 0.8760\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1028 - accuracy: 0.9616 - val_loss: 0.5633 - val_accuracy: 0.8880\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0853 - accuracy: 0.9682 - val_loss: 0.5353 - val_accuracy: 0.8920\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0696 - accuracy: 0.9724 - val_loss: 0.6877 - val_accuracy: 0.8180\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0768 - accuracy: 0.9691 - val_loss: 0.6189 - val_accuracy: 0.8860\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0742 - accuracy: 0.9700 - val_loss: 0.7860 - val_accuracy: 0.9080\n",
      "Test loss: 0.712979793548584\n",
      "Test accuracy: 0.8989999890327454\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.12\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3369 - accuracy: 0.8820 - val_loss: 0.2996 - val_accuracy: 0.9060\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.3000 - accuracy: 0.8993 - val_loss: 0.2825 - val_accuracy: 0.9060\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.3095 - accuracy: 0.8993 - val_loss: 0.2905 - val_accuracy: 0.9060\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2913 - accuracy: 0.8993 - val_loss: 0.2869 - val_accuracy: 0.9060\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2742 - accuracy: 0.8998 - val_loss: 0.2834 - val_accuracy: 0.9060\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2646 - accuracy: 0.8993 - val_loss: 0.2892 - val_accuracy: 0.9060\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2586 - accuracy: 0.8991 - val_loss: 0.3008 - val_accuracy: 0.9060\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2494 - accuracy: 0.8996 - val_loss: 0.2949 - val_accuracy: 0.9060\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2481 - accuracy: 0.9009 - val_loss: 0.2851 - val_accuracy: 0.9060\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2335 - accuracy: 0.9007 - val_loss: 0.3111 - val_accuracy: 0.8980\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2252 - accuracy: 0.9049 - val_loss: 0.3109 - val_accuracy: 0.9040\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2187 - accuracy: 0.9098 - val_loss: 0.2968 - val_accuracy: 0.8960\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2007 - accuracy: 0.9136 - val_loss: 0.3015 - val_accuracy: 0.8820\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1869 - accuracy: 0.9227 - val_loss: 0.3281 - val_accuracy: 0.8940\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1692 - accuracy: 0.9284 - val_loss: 0.3613 - val_accuracy: 0.9020\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1573 - accuracy: 0.9327 - val_loss: 0.4162 - val_accuracy: 0.8940\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1340 - accuracy: 0.9460 - val_loss: 0.4097 - val_accuracy: 0.8900\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1146 - accuracy: 0.9524 - val_loss: 0.4556 - val_accuracy: 0.8980\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1000 - accuracy: 0.9600 - val_loss: 0.4599 - val_accuracy: 0.8920\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0779 - accuracy: 0.9724 - val_loss: 0.6119 - val_accuracy: 0.8720\n",
      "Test loss: 0.5206665396690369\n",
      "Test accuracy: 0.8809999823570251\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.3435\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3533 - accuracy: 0.8949 - val_loss: 0.3032 - val_accuracy: 0.9060\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.3090 - accuracy: 0.8993 - val_loss: 0.3076 - val_accuracy: 0.9060\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2996 - accuracy: 0.8993 - val_loss: 0.3030 - val_accuracy: 0.9060\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2923 - accuracy: 0.8998 - val_loss: 0.2914 - val_accuracy: 0.9060\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2702 - accuracy: 0.9000 - val_loss: 0.2850 - val_accuracy: 0.9060\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2589 - accuracy: 0.8989 - val_loss: 0.3110 - val_accuracy: 0.9060\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2517 - accuracy: 0.9004 - val_loss: 0.3035 - val_accuracy: 0.9040\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2440 - accuracy: 0.9007 - val_loss: 0.3056 - val_accuracy: 0.9060\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2312 - accuracy: 0.9029 - val_loss: 0.2928 - val_accuracy: 0.9020\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2195 - accuracy: 0.9080 - val_loss: 0.3099 - val_accuracy: 0.9040\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2017 - accuracy: 0.9144 - val_loss: 0.3439 - val_accuracy: 0.8980\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1878 - accuracy: 0.9200 - val_loss: 0.3210 - val_accuracy: 0.8900\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1783 - accuracy: 0.9273 - val_loss: 0.3543 - val_accuracy: 0.8940\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1802 - accuracy: 0.9293 - val_loss: 0.3456 - val_accuracy: 0.8820\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1543 - accuracy: 0.9362 - val_loss: 0.4242 - val_accuracy: 0.8680\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1228 - accuracy: 0.9478 - val_loss: 0.4122 - val_accuracy: 0.8700\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1047 - accuracy: 0.9600 - val_loss: 0.4305 - val_accuracy: 0.8880\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0835 - accuracy: 0.9702 - val_loss: 0.7490 - val_accuracy: 0.8920\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0713 - accuracy: 0.9704 - val_loss: 0.6211 - val_accuracy: 0.8860\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0458 - accuracy: 0.9829 - val_loss: 0.7870 - val_accuracy: 0.9020\n",
      "Test loss: 0.7647481560707092\n",
      "Test accuracy: 0.8999999761581421\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.149\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3489 - accuracy: 0.8802 - val_loss: 0.3105 - val_accuracy: 0.9060\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.3152 - accuracy: 0.8993 - val_loss: 0.3412 - val_accuracy: 0.9060\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.3107 - accuracy: 0.8996 - val_loss: 0.3202 - val_accuracy: 0.9060\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2892 - accuracy: 0.8991 - val_loss: 0.2929 - val_accuracy: 0.9060\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2685 - accuracy: 0.8991 - val_loss: 0.3082 - val_accuracy: 0.9060\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2579 - accuracy: 0.8998 - val_loss: 0.2911 - val_accuracy: 0.9060\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2487 - accuracy: 0.9018 - val_loss: 0.2900 - val_accuracy: 0.9060\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2312 - accuracy: 0.9022 - val_loss: 0.3005 - val_accuracy: 0.8980\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2256 - accuracy: 0.9078 - val_loss: 0.2874 - val_accuracy: 0.8960\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2116 - accuracy: 0.9104 - val_loss: 0.3076 - val_accuracy: 0.8940\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1939 - accuracy: 0.9220 - val_loss: 0.3375 - val_accuracy: 0.8560\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1938 - accuracy: 0.9196 - val_loss: 0.3942 - val_accuracy: 0.8980\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1607 - accuracy: 0.9353 - val_loss: 0.3766 - val_accuracy: 0.8840\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1482 - accuracy: 0.9382 - val_loss: 0.4294 - val_accuracy: 0.8760\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1077 - accuracy: 0.9536 - val_loss: 0.4364 - val_accuracy: 0.8660\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1071 - accuracy: 0.9582 - val_loss: 0.4777 - val_accuracy: 0.8920\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0809 - accuracy: 0.9651 - val_loss: 0.6496 - val_accuracy: 0.8840\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0514 - accuracy: 0.9824 - val_loss: 0.8121 - val_accuracy: 0.8880\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0493 - accuracy: 0.9820 - val_loss: 0.8084 - val_accuracy: 0.8920\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0401 - accuracy: 0.9844 - val_loss: 0.8733 - val_accuracy: 0.8960\n",
      "Test loss: 0.748715877532959\n",
      "Test accuracy: 0.8920000195503235\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.323\n",
      "      通し番号  カウント\n",
      "0        0     0\n",
      "1        1     1\n",
      "2        2     7\n",
      "3        3     6\n",
      "4        4     0\n",
      "...    ...   ...\n",
      "1995  1995     1\n",
      "1996  1996     7\n",
      "1997  1997     7\n",
      "1998  1998     0\n",
      "1999  1999     2\n",
      "\n",
      "[2000 rows x 2 columns]\n",
      "[0.3285, 0.1585, 0.234, 0.267, 0.2965, 0.2745, 0.12, 0.3435, 0.149, 0.323]\n",
      "11\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[1651, 1590, 1578, 350, 1602, 292, 324, 290, 1653, 1611, 1581, 1598, 1579, 325, 253, 1650, 1695, 352, 1608, 1673, 1660, 285, 258, 1592, 1625, 271, 1640, 311, 278, 1639, 1668, 273, 1677, 344, 1670, 1629, 341, 275, 1630, 1631, 305, 1674, 1664, 1663, 1593, 262, 1616, 1597, 284, 1619, 1659, 298, 261, 1644, 317, 280, 1584, 300, 282, 1623, 1594, 1641, 1624, 269, 335, 905, 251, 1893, 79, 72, 71, 1904, 1905, 1907, 1910, 1911, 65, 64, 63, 59, 1917, 1918, 1920, 58, 1923, 1924, 56, 1895, 1892, 1932, 1889, 1856, 1858, 1859, 111, 106, 1865, 105, 103, 102, 99, 1872, 97, 1876, 96, 95, 93, 92, 91, 89, 50, 1933, 250, 29, 26, 25, 1979, 23, 17, 16, 1983, 15, 1985, 1988, 8, 7, 1991, 1992, 1993, 1994, 6, 4, 1998, 1971, 1967, 45, 1962, 1936, 44, 1938, 1940, 1941, 41, 40, 1945, 1946, 38, 1948, 1949, 36, 1951, 1952, 35, 1958, 1959, 33, 1855, 1853, 1851, 1742, 221, 220, 218, 217, 213, 207, 206, 205, 203, 1761, 202, 1765, 195, 193, 1771, 192, 1774, 185, 183, 1743, 1740, 1850, 1739, 244, 1705, 1709, 239, 1714, 238, 1716, 1717, 1719, 1721, 232, 1727, 1729, 229, 1732, 1733, 227, 224, 1738, 1779, 176, 174, 172, 1821, 1822, 1823, 1824, 1827, 1828, 1829, 1832, 137, 136, 135, 1836, 133, 129, 127, 126, 1843, 1845, 1846, 1819, 1818, 148, 163, 169, 167, 166, 1792, 1794, 165, 1796, 1798, 158, 149, 1802, 1803, 155, 152, 1806, 1807, 151, 1811, 1793, 1453, 1575, 1105, 1109, 739, 737, 1114, 1115, 730, 1120, 729, 728, 726, 1126, 724, 721, 1133, 1134, 1137, 1138, 1139, 714, 1142, 1143, 1144, 1145, 740, 743, 1574, 747, 1061, 1063, 1064, 774, 773, 1070, 770, 767, 765, 1077, 1078, 762, 1086, 1090, 1091, 1092, 757, 1095, 755, 754, 752, 751, 749, 1146, 709, 1148, 1149, 656, 1212, 1215, 1216, 1217, 1220, 651, 645, 638, 1228, 634, 633, 1231, 632, 1233, 1234, 631, 629, 628, 627, 626, 1243, 624, 1209, 1208, 657, 1173, 1150, 706, 1153, 704, 700, 696, 695, 1167, 693, 691, 686, 661, 684, 1180, 1182, 1184, 678, 1190, 1192, 1196, 1197, 1201, 782, 1057, 1056, 840, 872, 867, 866, 951, 865, 863, 954, 862, 860, 859, 855, 962, 964, 966, 849, 968, 846, 842, 976, 977, 978, 980, 981, 945, 874, 877, 901, 908, 909, 910, 911, 912, 913, 903, 916, 917, 902, 900, 942, 924, 925, 927, 887, 884, 934, 935, 936, 938, 881, 982, 986, 784, 839, 807, 1023, 1024, 804, 1027, 1028, 802, 1031, 1032, 1034, 796, 794, 1038, 1039, 793, 1041, 792, 1043, 1046, 1048, 1049, 786, 1053, 808, 1017, 1014, 1001, 988, 838, 831, 827, 826, 825, 823, 997, 998, 999, 822, 813, 820, 819, 1005, 1006, 817, 1008, 1009, 816, 815, 814, 1245, 621, 617, 1501, 1466, 430, 1470, 425, 1476, 1477, 421, 420, 1480, 1481, 418, 417, 416, 415, 412, 1490, 410, 409, 1493, 407, 1495, 1497, 404, 1464, 433, 1461, 451, 1425, 1427, 468, 466, 463, 459, 1436, 457, 452, 1440, 1442, 435, 450, 449, 448, 1449, 1450, 443, 907, 439, 438, 436, 403, 1503, 473, 401, 380, 1540, 379, 378, 1543, 377, 375, 1546, 1547, 373, 371, 1556, 368, 366, 365, 1560, 364, 362, 360, 1566, 357, 355, 1573, 382, 1536, 1535, 1519, 399, 1506, 395, 394, 1511, 1512, 1513, 393, 1517, 391, 1520, 384, 1521, 1522, 1523, 390, 389, 1527, 1529, 1530, 1531, 388, 470, 1418, 1250, 548, 1293, 583, 579, 1297, 1299, 1302, 574, 572, 1305, 1306, 569, 1308, 1309, 1315, 560, 1318, 1320, 559, 1323, 557, 1327, 553, 1333, 584, 1291, 585, 598, 1251, 1252, 613, 612, 1257, 1258, 1259, 611, 603, 602, 597, 1289, 596, 595, 1275, 1276, 1279, 592, 1284, 1285, 588, 587, 1334, 1337, 1417, 546, 508, 507, 506, 1383, 504, 499, 1390, 497, 494, 493, 490, 489, 1400, 485, 479, 478, 1408, 1409, 1410, 1412, 1413, 475, 1415, 1379, 509, 1377, 1356, 1339, 543, 540, 1344, 538, 537, 530, 1350, 527, 526, 525, 1376, 1359, 523, 521, 520, 1363, 519, 515, 1368, 1369, 511, 0, 1977, 1238, 1667, 1242, 1444, 462, 1576, 1273, 1446, 623, 1665, 594, 1675, 445, 1277, 159, 1790, 1247, 608, 1788, 1263, 606, 1265, 178, 939, 1434, 187, 24, 1781, 1271, 1783, 616, 1974, 1973, 1669, 453, 1224, 441, 636, 1199, 1198, 1656, 666, 669, 144, 1191, 836, 673, 674, 677, 955, 679, 431, 1183, 956, 31, 1179, 683, 1553, 1817, 1816, 1457, 1226, 1769, 643, 871, 1455, 1219, 654, 1808, 1810, 660, 1214, 1213, 1210, 1554, 1207, 145, 1970, 28, 1978, 1463, 1430, 549, 483, 480, 1357, 918, 1723, 920, 1352, 1351, 255, 231, 531, 533, 1728, 361, 1730, 541, 1690, 12, 260, 237, 484, 254, 241, 1697, 500, 1387, 1384, 1995, 1704, 252, 1570, 1708, 915, 1397, 1710, 510, 240, 1373, 1372, 1712, 488, 1411, 225, 1281, 550, 211, 1753, 1754, 886, 1585, 1298, 1680, 577, 1757, 1424, 1426, 274, 1762, 469, 199, 198, 140, 937, 1282, 471, 931, 472, 1683, 13, 1330, 897, 1325, 1684, 1741, 558, 474, 1319, 1747, 1561, 1317, 1419, 561, 1313, 562, 930, 566, 1177, 1577, 1175, 1098, 1071, 1887, 1888, 975, 777, 1954, 85, 1891, 1062, 398, 1058, 80, 1055, 78, 787, 788, 1047, 1595, 789, 772, 974, 769, 94, 307, 1875, 758, 1878, 402, 759, 1088, 973, 1085, 88, 1083, 1652, 1081, 764, 1079, 1502, 1628, 308, 791, 338, 1903, 328, 54, 53, 1528, 1929, 48, 47, 327, 1934, 1, 1526, 1605, 1599, 1604, 43, 824, 332, 42, 1537, 1609, 1922, 318, 799, 1906, 1514, 69, 795, 67, 1515, 797, 1618, 1915, 810, 803, 984, 1613, 1022, 985, 1919, 1019, 1612, 1873, 763, 1486, 1155, 1121, 414, 114, 727, 294, 1471, 697, 1160, 1548, 1159, 1963, 426, 1128, 722, 1154, 1164, 851, 1550, 422, 716, 753, 715, 299, 120, 124, 712, 1475, 1961, 1698, 125, 1163, 293, 1634, 32, 844, 104, 112, 688, 1955, 301, 1638, 861, 1469, 1169, 427, 738, 741, 1956, 1635, 969, 34, 411, 101, 138, 1166, 1116, 732, 1118, 1107, 960, 1706, 1748, 1898, 1957, 1950, 1734, 1731, 1964, 1835, 1968, 1857, 1838, 1839, 1989, 1707, 1735, 1867, 1944, 1897, 1789, 970, 1899, 1780, 972, 1854, 1795, 932, 1772, 1800, 990, 1770, 1881, 943, 1767, 961, 1939, 1842, 1225, 1699, 1693, 1158, 1342, 1347, 1353, 1355, 1358, 1151, 1364, 1371, 1374, 1375, 1389, 1395, 1130, 1398, 1399, 1127, 1404, 1405, 1341, 1170, 1329, 1266, 1211, 1206, 1230, 1239, 1246, 1248, 1260, 1264, 1268, 1324, 1188, 1278, 1287, 1290, 1303, 1307, 1174, 1172, 1414, 1423, 1117, 1042, 1571, 1572, 1060, 1601, 1603, 1614, 1615, 1620, 1040, 1069, 1642, 1645, 1647, 1671, 1676, 1679, 1687, 1691, 1068, 1565, 1438, 1094, 1441, 1447, 1458, 1103, 1491, 1496, 1099, 1500, 1516, 1559, 1525, 1084, 1532, 1534, 1544, 1551, 1558, 1073, 1000, 1999, 131, 725, 718, 116, 118, 132, 708, 699, 694, 139, 143, 680, 287, 668, 286, 662, 659, 658, 147, 115, 109, 333, 736, 809, 805, 323, 321, 70, 315, 73, 75, 396, 780, 778, 775, 87, 761, 406, 303, 108, 440, 164, 630, 171, 552, 228, 545, 476, 529, 233, 235, 236, 517, 516, 513, 512, 243, 491, 246, 501, 247, 266, 554, 268, 590, 277, 615, 177, 276, 607, 184, 593, 196, 555, 589, 210, 576, 575, 214, 564, 222, 385, 498, 342, 345, 891, 369, 899, 873, 854, 841, 347, 359, 878, 370, 358, 30, 340, 353, 766, 821, 655, 710, 1003, 1187, 1176, 1012, 1122, 1119, 914, 1087, 996, 989, 837, 835, 892, 1082, 993, 1129, 1131, 720, 1132, 883, 1140, 979, 733, 1093, 1200, 1102, 870, 1051, 1050, 1189, 869, 1171, 670, 959, 957, 868, 953, 963, 928, 1112, 895, 852, 1072, 949, 879, 1021, 1075, 806, 847, 1052, 1108, 904, 351, 1524, 161, 1498, 1791, 397, 170, 1518, 1786, 1485, 173, 1784, 383, 175, 1555, 1778, 413, 1479, 1852, 1831, 134, 1421, 1833, 1431, 1433, 906, 141, 1474, 444, 442, 146, 429, 1472, 1473, 1777, 189, 191, 270, 309, 1737, 296, 1736, 1658, 281, 1685, 1567, 263, 1724, 1688, 234, 257, 1718, 1626, 314, 215, 1750, 212, 320, 1752, 1760, 1610, 331, 1763, 1766, 336, 346, 348, 1227, 1580, 1401, 456, 1909, 1914, 1294, 582, 581, 1927, 571, 62, 1310, 74, 1312, 66, 1331, 551, 1332, 1338, 1943, 591, 1269, 39, 37, 600, 601, 1953, 1261, 610, 1256, 1253, 1965, 625, 1976, 1229, 21, 544, 1701, 1391, 1880, 496, 1394, 1879, 1361, 1870, 514, 532, 1860, 1392, 90, 1864, 107, 1345, 1343, 1385, 110, 1322, 1157, 573, 933, 1205, 1178, 635, 1218, 570, 713, 563, 1311, 1378, 1221, 556, 1165, 1947, 1328, 921, 539, 698, 1980, 52, 675, 22, 922, 1156, 1931, 1348, 1292, 547, 705, 923, 1984, 1380, 1972, 1925, 46, 57, 894, 1236, 685, 201, 1381, 386, 153, 1809, 312, 150, 1812, 790, 1814, 653, 142, 857, 1054, 334, 1600, 1596, 1589, 858, 781, 503, 1564, 1563, 1847, 374, 123, 122, 1076, 157, 798, 1030, 186, 991, 1758, 209, 1755, 830, 216, 219, 194, 190, 230, 1773, 1694, 800, 180, 812, 259, 1689, 265, 272, 1026, 1662, 1655, 1654, 1799, 1533, 356, 387, 1484, 1478, 424, 1465, 432, 944, 1871, 1454, 1106, 1451, 446, 876, 735, 1882, 734, 464, 1429, 731, 81, 477, 1406, 77, 1402, 486, 948, 326, 392, 1848, 1861, 1096, 1100, 119, 1097, 1937, 1921, 1884, 1538, 528, 950, 1505, 535, 756, 1111, 534, 1113, 1510, 1349, 1089, 1316, 461, 1900, 565, 121, 1335, 1428, 1908, 719, 60, 1894, 1124, 701, 542, 880, 84, 1866, 832, 1125, 707, 1452, 1883, 885, 423, 723, 1930, 1396, 748, 68, 1482, 1483, 1336, 702, 1152, 1435, 947, 302, 1267, 971, 845, 618, 1672, 1982, 848, 967, 1787, 1661, 965, 1657, 1254, 1255, 289, 1797, 665, 19, 20, 1194, 1637, 1539, 1193, 604, 1016, 1987, 1241, 1720, 208, 648, 647, 992, 644, 5, 995, 1725, 1004, 1722, 818, 179, 1711, 1775, 1703, 1702, 182, 248, 249, 181, 1237, 1013, 313, 1901, 1568, 1844, 682, 130, 1181, 1840, 958, 1301, 1552, 363, 1545, 339, 337, 1826, 1966, 1066, 1280, 1606, 1272, 1557, 1270, 367, 599, 952, 1542, 1296, 1541, 771, 322, 1617, 742, 100, 316, 310, 1622, 354, 1448, 1035, 1633, 304, 1044, 1801, 1874, 297, 1110, 160, 162, 875, 1443, 18, 454, 1926, 671, 676, 1813, 750, 689, 1321, 768, 1849, 1841, 1504, 113, 1168, 1492, 1960, 1101, 1065, 864, 1487, 1869, 1583, 1185, 1830, 586, 1591, 1288, 746, 49, 745, 329, 744, 946, 1462, 941, 291, 1715, 1203, 1896, 518, 1776, 888, 242, 1235, 76, 492, 987, 1393, 637, 1002, 495, 639, 641, 642, 1746, 717, 3, 646, 1388, 829, 1386, 502, 1136, 833, 650, 1764, 204, 1696, 567, 1782, 663, 86, 9, 1981, 1785, 619, 1678, 1025, 1244, 1015, 1986, 843, 264, 1222, 828, 649, 1286, 1745, 609, 223, 667, 1204, 1681, 614, 267, 1240, 1202, 256, 620, 1029, 1141, 1636, 1346, 690, 1499, 408, 419, 692, 428, 1104, 1161, 1437, 1186, 460, 1432, 1360, 1147, 1420, 1366, 487, 505, 1314, 1509, 687, 381, 681, 1037, 1621, 319, 1607, 330, 785, 1295, 1587, 1586, 1370, 1582, 776, 1067, 1562, 1304, 1549, 578, 652, 1768, 128, 1804, 156, 1890, 1837, 889, 1969, 1862, 1996, 1997, 1912, 850, 55, 98, 27, 834, 197, 83, 1916, 1820, 2, 893, 1942, 890, 1868, 1080, 349, 811, 376, 1686, 14, 1507, 1569, 400, 779, 1666, 1759, 1834, 168, 622, 896, 919, 1825, 1649, 1815, 1045, 1648, 1975, 898, 1627, 1643, 343, 1326, 306, 467, 1744, 1365, 1123, 994, 226, 455, 983, 1877, 1928, 437, 482, 1232, 1403, 1340, 1467, 1367, 1007, 882, 245, 1863, 1135, 1488, 1489, 1362, 288, 1885, 447, 1445, 1726, 465, 1751, 1749, 1422, 1456, 82, 1407, 1756, 481, 940, 188, 1468, 1713, 1460, 283, 1020, 1632, 1018, 1805, 1588, 1059, 1010, 1074, 372, 760, 405, 1494, 801, 434, 1382, 1439, 1935, 1249, 536, 703, 664, 524, 1162, 568, 640, 926, 929, 61, 605, 580, 1274, 711, 1195, 1459, 1300, 853, 672, 295, 1283, 1033, 154, 1036, 1902, 783, 1508, 1262, 117, 200, 51, 458, 1354, 522, 1886, 1416, 1913, 1646, 856, 279, 1682, 1990, 10, 1692, 1700, 1011, 11, 1223]\n",
      "500\n",
      "500\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3223 - accuracy: 0.8829 - val_loss: 0.4006 - val_accuracy: 0.8680\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2841 - accuracy: 0.9036 - val_loss: 0.3224 - val_accuracy: 0.8680\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2733 - accuracy: 0.9036 - val_loss: 0.3058 - val_accuracy: 0.8680\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2748 - accuracy: 0.9036 - val_loss: 0.3186 - val_accuracy: 0.8680\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2704 - accuracy: 0.9036 - val_loss: 0.3089 - val_accuracy: 0.8680\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2535 - accuracy: 0.9036 - val_loss: 0.2998 - val_accuracy: 0.8660\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2410 - accuracy: 0.9060 - val_loss: 0.3172 - val_accuracy: 0.8680\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2262 - accuracy: 0.9091 - val_loss: 0.2955 - val_accuracy: 0.8680\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2216 - accuracy: 0.9149 - val_loss: 0.2909 - val_accuracy: 0.8740\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2137 - accuracy: 0.9140 - val_loss: 0.3425 - val_accuracy: 0.8700\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1904 - accuracy: 0.9187 - val_loss: 0.3509 - val_accuracy: 0.8840\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1656 - accuracy: 0.9316 - val_loss: 0.3209 - val_accuracy: 0.8820\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1625 - accuracy: 0.9320 - val_loss: 0.3734 - val_accuracy: 0.8780\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1313 - accuracy: 0.9478 - val_loss: 0.3619 - val_accuracy: 0.8660\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1293 - accuracy: 0.9493 - val_loss: 0.3532 - val_accuracy: 0.8800\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1016 - accuracy: 0.9578 - val_loss: 0.4500 - val_accuracy: 0.8640\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0698 - accuracy: 0.9722 - val_loss: 0.5415 - val_accuracy: 0.8820\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0538 - accuracy: 0.9802 - val_loss: 0.6275 - val_accuracy: 0.8900\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0549 - accuracy: 0.9778 - val_loss: 0.6195 - val_accuracy: 0.8720\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0436 - accuracy: 0.9858 - val_loss: 0.6987 - val_accuracy: 0.8720\n",
      "Test loss: 0.523842453956604\n",
      "Test accuracy: 0.9079999923706055\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.0075\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3542 - accuracy: 0.8982 - val_loss: 0.3482 - val_accuracy: 0.8680\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2861 - accuracy: 0.9036 - val_loss: 0.3560 - val_accuracy: 0.8680\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2760 - accuracy: 0.9036 - val_loss: 0.3177 - val_accuracy: 0.8680\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2648 - accuracy: 0.9036 - val_loss: 0.3104 - val_accuracy: 0.8680\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2551 - accuracy: 0.9036 - val_loss: 0.3186 - val_accuracy: 0.8680\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2475 - accuracy: 0.9036 - val_loss: 0.3106 - val_accuracy: 0.8680\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2445 - accuracy: 0.9047 - val_loss: 0.3375 - val_accuracy: 0.8700\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2410 - accuracy: 0.9040 - val_loss: 0.3601 - val_accuracy: 0.8680\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2193 - accuracy: 0.9124 - val_loss: 0.3014 - val_accuracy: 0.8700\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2112 - accuracy: 0.9124 - val_loss: 0.3477 - val_accuracy: 0.8680\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1950 - accuracy: 0.9220 - val_loss: 0.3186 - val_accuracy: 0.8740\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1710 - accuracy: 0.9278 - val_loss: 0.3443 - val_accuracy: 0.8720\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1746 - accuracy: 0.9267 - val_loss: 0.4361 - val_accuracy: 0.8680\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1477 - accuracy: 0.9364 - val_loss: 0.3697 - val_accuracy: 0.8880\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1321 - accuracy: 0.9431 - val_loss: 0.3801 - val_accuracy: 0.8820\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1217 - accuracy: 0.9476 - val_loss: 0.3861 - val_accuracy: 0.8800\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0937 - accuracy: 0.9631 - val_loss: 0.5521 - val_accuracy: 0.8820\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0716 - accuracy: 0.9729 - val_loss: 0.4741 - val_accuracy: 0.8840\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0688 - accuracy: 0.9722 - val_loss: 0.5435 - val_accuracy: 0.8700\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0671 - accuracy: 0.9727 - val_loss: 0.4777 - val_accuracy: 0.8680\n",
      "Test loss: 0.39449307322502136\n",
      "Test accuracy: 0.8939999938011169\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.0485\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3272 - accuracy: 0.9009 - val_loss: 0.4033 - val_accuracy: 0.8680\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2907 - accuracy: 0.9036 - val_loss: 0.3224 - val_accuracy: 0.8680\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2789 - accuracy: 0.9036 - val_loss: 0.3084 - val_accuracy: 0.8680\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2608 - accuracy: 0.9036 - val_loss: 0.3974 - val_accuracy: 0.8680\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2557 - accuracy: 0.9036 - val_loss: 0.3089 - val_accuracy: 0.8680\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2437 - accuracy: 0.9044 - val_loss: 0.3521 - val_accuracy: 0.8700\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2349 - accuracy: 0.9049 - val_loss: 0.2975 - val_accuracy: 0.8660\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2300 - accuracy: 0.9073 - val_loss: 0.3018 - val_accuracy: 0.8740\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2141 - accuracy: 0.9127 - val_loss: 0.2963 - val_accuracy: 0.8720\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2012 - accuracy: 0.9171 - val_loss: 0.2995 - val_accuracy: 0.8600\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2011 - accuracy: 0.9187 - val_loss: 0.3089 - val_accuracy: 0.8700\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1641 - accuracy: 0.9304 - val_loss: 0.3760 - val_accuracy: 0.8720\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1379 - accuracy: 0.9413 - val_loss: 0.3265 - val_accuracy: 0.8660\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1212 - accuracy: 0.9507 - val_loss: 0.4513 - val_accuracy: 0.8560\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1131 - accuracy: 0.9504 - val_loss: 0.5822 - val_accuracy: 0.8620\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0845 - accuracy: 0.9673 - val_loss: 0.4905 - val_accuracy: 0.8680\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0622 - accuracy: 0.9769 - val_loss: 0.6539 - val_accuracy: 0.8860\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0457 - accuracy: 0.9816 - val_loss: 0.7195 - val_accuracy: 0.8840\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1126 - accuracy: 0.9553 - val_loss: 0.4160 - val_accuracy: 0.8800\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0479 - accuracy: 0.9800 - val_loss: 0.5353 - val_accuracy: 0.8780\n",
      "Test loss: 0.37619298696517944\n",
      "Test accuracy: 0.9089999794960022\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.077\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3328 - accuracy: 0.9009 - val_loss: 0.3810 - val_accuracy: 0.8680\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2815 - accuracy: 0.9036 - val_loss: 0.3360 - val_accuracy: 0.8680\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2670 - accuracy: 0.9036 - val_loss: 0.3206 - val_accuracy: 0.8680\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2652 - accuracy: 0.9036 - val_loss: 0.3019 - val_accuracy: 0.8680\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2566 - accuracy: 0.9047 - val_loss: 0.3408 - val_accuracy: 0.8680\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2399 - accuracy: 0.9042 - val_loss: 0.3057 - val_accuracy: 0.8720\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2344 - accuracy: 0.9080 - val_loss: 0.2987 - val_accuracy: 0.8720\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2201 - accuracy: 0.9144 - val_loss: 0.4121 - val_accuracy: 0.8720\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2087 - accuracy: 0.9176 - val_loss: 0.3115 - val_accuracy: 0.8620\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1859 - accuracy: 0.9253 - val_loss: 0.2933 - val_accuracy: 0.8780\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1665 - accuracy: 0.9298 - val_loss: 0.4388 - val_accuracy: 0.8780\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1525 - accuracy: 0.9347 - val_loss: 0.3153 - val_accuracy: 0.8740\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1330 - accuracy: 0.9398 - val_loss: 0.3994 - val_accuracy: 0.8740\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1192 - accuracy: 0.9518 - val_loss: 0.4532 - val_accuracy: 0.8840\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0859 - accuracy: 0.9633 - val_loss: 0.4348 - val_accuracy: 0.8700\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0771 - accuracy: 0.9671 - val_loss: 0.4882 - val_accuracy: 0.8840\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0617 - accuracy: 0.9758 - val_loss: 0.5448 - val_accuracy: 0.8580\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0531 - accuracy: 0.9769 - val_loss: 0.6904 - val_accuracy: 0.8800\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0448 - accuracy: 0.9820 - val_loss: 0.6019 - val_accuracy: 0.8760\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0320 - accuracy: 0.9887 - val_loss: 0.7318 - val_accuracy: 0.8860\n",
      "Test loss: 0.550622820854187\n",
      "Test accuracy: 0.906000018119812\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.2185\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3206 - accuracy: 0.8924 - val_loss: 0.3658 - val_accuracy: 0.8680\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2787 - accuracy: 0.9036 - val_loss: 0.3138 - val_accuracy: 0.8680\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2732 - accuracy: 0.9036 - val_loss: 0.3066 - val_accuracy: 0.8680\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2583 - accuracy: 0.9036 - val_loss: 0.3716 - val_accuracy: 0.8680\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2670 - accuracy: 0.9033 - val_loss: 0.3322 - val_accuracy: 0.8680\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2499 - accuracy: 0.9040 - val_loss: 0.3831 - val_accuracy: 0.8680\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2466 - accuracy: 0.9044 - val_loss: 0.3234 - val_accuracy: 0.8760\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2276 - accuracy: 0.9091 - val_loss: 0.3147 - val_accuracy: 0.8720\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2077 - accuracy: 0.9144 - val_loss: 0.3443 - val_accuracy: 0.8680\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1977 - accuracy: 0.9182 - val_loss: 0.3358 - val_accuracy: 0.8680\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1840 - accuracy: 0.9204 - val_loss: 0.3331 - val_accuracy: 0.8640\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1597 - accuracy: 0.9344 - val_loss: 0.3608 - val_accuracy: 0.8680\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1612 - accuracy: 0.9331 - val_loss: 0.3653 - val_accuracy: 0.8740\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1439 - accuracy: 0.9351 - val_loss: 0.3960 - val_accuracy: 0.8740\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1041 - accuracy: 0.9600 - val_loss: 0.4288 - val_accuracy: 0.8720\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0850 - accuracy: 0.9642 - val_loss: 0.5651 - val_accuracy: 0.8640\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0755 - accuracy: 0.9702 - val_loss: 0.5123 - val_accuracy: 0.8880\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0526 - accuracy: 0.9811 - val_loss: 0.7852 - val_accuracy: 0.8820\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0371 - accuracy: 0.9864 - val_loss: 0.7174 - val_accuracy: 0.8800\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0369 - accuracy: 0.9849 - val_loss: 1.0926 - val_accuracy: 0.8820\n",
      "Test loss: 0.869717538356781\n",
      "Test accuracy: 0.9039999842643738\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.0015\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3429 - accuracy: 0.9011 - val_loss: 0.3581 - val_accuracy: 0.8680\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2839 - accuracy: 0.9036 - val_loss: 0.3473 - val_accuracy: 0.8680\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2878 - accuracy: 0.9036 - val_loss: 0.3140 - val_accuracy: 0.8680\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2692 - accuracy: 0.9036 - val_loss: 0.3180 - val_accuracy: 0.8680\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2569 - accuracy: 0.9036 - val_loss: 0.2958 - val_accuracy: 0.8680\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2432 - accuracy: 0.9040 - val_loss: 0.2982 - val_accuracy: 0.8680\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2301 - accuracy: 0.9076 - val_loss: 0.3294 - val_accuracy: 0.8680\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2222 - accuracy: 0.9109 - val_loss: 0.3045 - val_accuracy: 0.8700\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2254 - accuracy: 0.9107 - val_loss: 0.3152 - val_accuracy: 0.8700\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2116 - accuracy: 0.9124 - val_loss: 0.2951 - val_accuracy: 0.8720\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1932 - accuracy: 0.9178 - val_loss: 0.3192 - val_accuracy: 0.8700\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1725 - accuracy: 0.9251 - val_loss: 0.3760 - val_accuracy: 0.8680\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1544 - accuracy: 0.9378 - val_loss: 0.4463 - val_accuracy: 0.8660\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1391 - accuracy: 0.9367 - val_loss: 0.4656 - val_accuracy: 0.8640\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1043 - accuracy: 0.9584 - val_loss: 0.5351 - val_accuracy: 0.8780\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0905 - accuracy: 0.9613 - val_loss: 0.5321 - val_accuracy: 0.8860\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0724 - accuracy: 0.9727 - val_loss: 0.6299 - val_accuracy: 0.8880\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0772 - accuracy: 0.9691 - val_loss: 0.5724 - val_accuracy: 0.8880\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0531 - accuracy: 0.9784 - val_loss: 0.6746 - val_accuracy: 0.8760\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0373 - accuracy: 0.9844 - val_loss: 0.6640 - val_accuracy: 0.8760\n",
      "Test loss: 0.5336779356002808\n",
      "Test accuracy: 0.8939999938011169\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.081\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3347 - accuracy: 0.8864 - val_loss: 0.3447 - val_accuracy: 0.8680\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2818 - accuracy: 0.9036 - val_loss: 0.3060 - val_accuracy: 0.8680\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2690 - accuracy: 0.9036 - val_loss: 0.3495 - val_accuracy: 0.8680\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2635 - accuracy: 0.9036 - val_loss: 0.3092 - val_accuracy: 0.8680\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2557 - accuracy: 0.9036 - val_loss: 0.3202 - val_accuracy: 0.8680\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2430 - accuracy: 0.9042 - val_loss: 0.3155 - val_accuracy: 0.8680\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2325 - accuracy: 0.9062 - val_loss: 0.2972 - val_accuracy: 0.8760\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2212 - accuracy: 0.9133 - val_loss: 0.3441 - val_accuracy: 0.8700\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2076 - accuracy: 0.9140 - val_loss: 0.3504 - val_accuracy: 0.8740\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1946 - accuracy: 0.9207 - val_loss: 0.3212 - val_accuracy: 0.8760\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1918 - accuracy: 0.9198 - val_loss: 0.4221 - val_accuracy: 0.8680\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1697 - accuracy: 0.9282 - val_loss: 0.3346 - val_accuracy: 0.8760\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1492 - accuracy: 0.9378 - val_loss: 0.4042 - val_accuracy: 0.8800\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1297 - accuracy: 0.9491 - val_loss: 0.3998 - val_accuracy: 0.8740\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1061 - accuracy: 0.9542 - val_loss: 0.5198 - val_accuracy: 0.8800\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0859 - accuracy: 0.9629 - val_loss: 0.5911 - val_accuracy: 0.8720\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0576 - accuracy: 0.9769 - val_loss: 0.6991 - val_accuracy: 0.8860\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0453 - accuracy: 0.9833 - val_loss: 0.7217 - val_accuracy: 0.8500\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0798 - accuracy: 0.9689 - val_loss: 0.7251 - val_accuracy: 0.8740\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0538 - accuracy: 0.9809 - val_loss: 0.7628 - val_accuracy: 0.8820\n",
      "Test loss: 0.5415087342262268\n",
      "Test accuracy: 0.9160000085830688\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.063\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3498 - accuracy: 0.8987 - val_loss: 0.3438 - val_accuracy: 0.8680\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.3003 - accuracy: 0.9036 - val_loss: 0.3931 - val_accuracy: 0.8680\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2876 - accuracy: 0.9036 - val_loss: 0.3100 - val_accuracy: 0.8680\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2643 - accuracy: 0.9036 - val_loss: 0.3417 - val_accuracy: 0.8680\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2566 - accuracy: 0.9036 - val_loss: 0.2953 - val_accuracy: 0.8680\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2553 - accuracy: 0.9038 - val_loss: 0.3112 - val_accuracy: 0.8680\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2429 - accuracy: 0.9062 - val_loss: 0.3143 - val_accuracy: 0.8680\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2319 - accuracy: 0.9076 - val_loss: 0.3359 - val_accuracy: 0.8700\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2201 - accuracy: 0.9113 - val_loss: 0.3654 - val_accuracy: 0.8680\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2226 - accuracy: 0.9116 - val_loss: 0.3055 - val_accuracy: 0.8660\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2117 - accuracy: 0.9142 - val_loss: 0.3785 - val_accuracy: 0.8720\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2033 - accuracy: 0.9176 - val_loss: 0.3398 - val_accuracy: 0.8540\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2076 - accuracy: 0.9176 - val_loss: 0.3224 - val_accuracy: 0.8700\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1665 - accuracy: 0.9296 - val_loss: 0.3761 - val_accuracy: 0.8620\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1515 - accuracy: 0.9362 - val_loss: 0.4051 - val_accuracy: 0.8600\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1314 - accuracy: 0.9462 - val_loss: 0.3849 - val_accuracy: 0.8760\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1122 - accuracy: 0.9533 - val_loss: 0.5177 - val_accuracy: 0.8660\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0869 - accuracy: 0.9651 - val_loss: 0.4347 - val_accuracy: 0.8720\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0788 - accuracy: 0.9676 - val_loss: 0.5254 - val_accuracy: 0.8700\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0524 - accuracy: 0.9778 - val_loss: 0.6268 - val_accuracy: 0.8740\n",
      "Test loss: 0.4959636330604553\n",
      "Test accuracy: 0.9089999794960022\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.053\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3325 - accuracy: 0.8927 - val_loss: 0.3464 - val_accuracy: 0.8680\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2759 - accuracy: 0.9036 - val_loss: 0.3146 - val_accuracy: 0.8680\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2631 - accuracy: 0.9036 - val_loss: 0.3151 - val_accuracy: 0.8680\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2550 - accuracy: 0.9038 - val_loss: 0.3149 - val_accuracy: 0.8680\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2433 - accuracy: 0.9036 - val_loss: 0.3245 - val_accuracy: 0.8700\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2364 - accuracy: 0.9067 - val_loss: 0.3060 - val_accuracy: 0.8720\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2356 - accuracy: 0.9067 - val_loss: 0.2903 - val_accuracy: 0.8760\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2108 - accuracy: 0.9147 - val_loss: 0.2988 - val_accuracy: 0.8720\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1987 - accuracy: 0.9167 - val_loss: 0.3362 - val_accuracy: 0.8700\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1911 - accuracy: 0.9180 - val_loss: 0.2778 - val_accuracy: 0.8820\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1581 - accuracy: 0.9349 - val_loss: 0.3315 - val_accuracy: 0.8860\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1453 - accuracy: 0.9400 - val_loss: 0.3208 - val_accuracy: 0.8820\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1293 - accuracy: 0.9458 - val_loss: 0.3247 - val_accuracy: 0.8820\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1003 - accuracy: 0.9607 - val_loss: 0.3340 - val_accuracy: 0.8860\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0720 - accuracy: 0.9713 - val_loss: 0.4802 - val_accuracy: 0.8760\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0648 - accuracy: 0.9760 - val_loss: 0.3995 - val_accuracy: 0.8600\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0506 - accuracy: 0.9787 - val_loss: 0.7252 - val_accuracy: 0.8860\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0381 - accuracy: 0.9864 - val_loss: 0.5200 - val_accuracy: 0.8660\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0266 - accuracy: 0.9896 - val_loss: 0.6898 - val_accuracy: 0.8900\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0338 - accuracy: 0.9876 - val_loss: 0.5832 - val_accuracy: 0.8640\n",
      "Test loss: 0.5343471765518188\n",
      "Test accuracy: 0.8939999938011169\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.1745\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3184 - accuracy: 0.8991 - val_loss: 0.3328 - val_accuracy: 0.8680\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2854 - accuracy: 0.9036 - val_loss: 0.3514 - val_accuracy: 0.8680\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2719 - accuracy: 0.9036 - val_loss: 0.3118 - val_accuracy: 0.8680\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2570 - accuracy: 0.9038 - val_loss: 0.3690 - val_accuracy: 0.8680\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2522 - accuracy: 0.9042 - val_loss: 0.3372 - val_accuracy: 0.8700\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2529 - accuracy: 0.9040 - val_loss: 0.3320 - val_accuracy: 0.8680\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2287 - accuracy: 0.9071 - val_loss: 0.3004 - val_accuracy: 0.8680\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2141 - accuracy: 0.9124 - val_loss: 0.2998 - val_accuracy: 0.8720\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2056 - accuracy: 0.9182 - val_loss: 0.3383 - val_accuracy: 0.8700\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1872 - accuracy: 0.9249 - val_loss: 0.2967 - val_accuracy: 0.8600\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1865 - accuracy: 0.9238 - val_loss: 0.3299 - val_accuracy: 0.8780\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1529 - accuracy: 0.9324 - val_loss: 0.3796 - val_accuracy: 0.8800\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1207 - accuracy: 0.9500 - val_loss: 0.4702 - val_accuracy: 0.8760\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1099 - accuracy: 0.9551 - val_loss: 0.5030 - val_accuracy: 0.8820\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0930 - accuracy: 0.9584 - val_loss: 0.4608 - val_accuracy: 0.8680\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0905 - accuracy: 0.9633 - val_loss: 0.4028 - val_accuracy: 0.8660\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0722 - accuracy: 0.9704 - val_loss: 0.5089 - val_accuracy: 0.8760\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0449 - accuracy: 0.9844 - val_loss: 0.6028 - val_accuracy: 0.8800\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0226 - accuracy: 0.9924 - val_loss: 0.9897 - val_accuracy: 0.8920\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0207 - accuracy: 0.9938 - val_loss: 0.7121 - val_accuracy: 0.8860\n",
      "Test loss: 0.62602698802948\n",
      "Test accuracy: 0.8980000019073486\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.183\n",
      "      通し番号  カウント\n",
      "0        0     3\n",
      "1        1     2\n",
      "2        2     1\n",
      "3        3     0\n",
      "4        4     1\n",
      "...    ...   ...\n",
      "1995  1995     0\n",
      "1996  1996     2\n",
      "1997  1997     0\n",
      "1998  1998     1\n",
      "1999  1999     1\n",
      "\n",
      "[2000 rows x 2 columns]\n",
      "[0.0075, 0.0485, 0.077, 0.2185, 0.0015, 0.081, 0.063, 0.053, 0.1745, 0.183]\n",
      "11\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[1529, 1326, 1418, 1321, 1325, 1322, 1398, 1400, 1324, 188, 1531, 1399, 1528, 1419, 1530, 1449, 1330, 139, 166, 1514, 1426, 1334, 1425, 145, 1516, 1395, 1517, 186, 1520, 167, 1396, 1332, 1331, 140, 1533, 1523, 1328, 187, 1526, 1319, 1538, 1534, 1549, 1306, 1305, 1304, 1551, 1405, 1302, 135, 1413, 1554, 1555, 1556, 1407, 168, 134, 132, 1301, 131, 1300, 1299, 1561, 1297, 1296, 1562, 1563, 1410, 1550, 136, 1535, 1307, 1536, 1537, 1336, 1402, 1318, 1417, 1416, 1540, 1316, 191, 1314, 1541, 138, 1403, 1414, 1313, 1543, 192, 1311, 1310, 1545, 193, 1546, 1308, 1404, 1427, 171, 146, 1479, 1441, 1372, 1371, 1370, 1467, 1468, 1469, 173, 1471, 1386, 1472, 1439, 1368, 1367, 1473, 1474, 1366, 1387, 1365, 1475, 1476, 1364, 1438, 1477, 176, 1465, 1373, 156, 1454, 1383, 1382, 1381, 1450, 1384, 1447, 1379, 1378, 1377, 175, 1453, 1455, 157, 1446, 162, 1457, 1458, 1374, 1459, 1460, 1444, 1442, 1461, 159, 1478, 177, 1511, 1437, 1495, 1392, 1497, 1498, 182, 1499, 1500, 183, 184, 1503, 1504, 1505, 1344, 1343, 1342, 1507, 148, 185, 1340, 1338, 1448, 1429, 1509, 1428, 147, 1432, 1565, 1391, 1389, 1436, 1481, 1388, 1483, 153, 178, 1485, 179, 1357, 1356, 1486, 1488, 1351, 1489, 1490, 1491, 1492, 1434, 1355, 181, 1493, 1494, 1353, 1352, 169, 1634, 1566, 1860, 1868, 1867, 1866, 48, 1864, 1863, 49, 1861, 1859, 1870, 1858, 1857, 1856, 1855, 1854, 1849, 53, 1847, 1869, 1871, 1842, 1883, 1892, 1891, 43, 44, 1888, 1887, 1885, 45, 46, 1872, 1880, 1879, 1878, 1877, 1876, 1875, 47, 1873, 1844, 1840, 41, 1796, 1809, 1808, 67, 1805, 1803, 1801, 1800, 1797, 1795, 1811, 1794, 1793, 1792, 1791, 1789, 70, 1787, 1785, 1810, 1812, 55, 1828, 1838, 1836, 58, 59, 1832, 60, 1830, 1829, 63, 1813, 1824, 1822, 64, 1818, 1817, 1816, 1815, 66, 42, 1895, 1783, 1963, 1971, 1970, 1969, 11, 1967, 1966, 1965, 12, 1962, 1973, 13, 1959, 15, 1956, 16, 1953, 1952, 1951, 1972, 1974, 1949, 6, 1997, 1995, 1994, 3, 1992, 1991, 1989, 1987, 1985, 8, 1984, 1983, 1982, 7, 1980, 1979, 1978, 1977, 21, 1948, 1897, 1908, 1919, 1918, 1916, 1914, 1913, 1912, 36, 1909, 1907, 34, 1906, 38, 1904, 1902, 1901, 1900, 40, 1898, 1920, 33, 1947, 1936, 1946, 1945, 1944, 1942, 25, 1940, 1938, 1937, 1935, 1924, 1934, 29, 1931, 30, 1929, 1928, 31, 32, 1784, 1781, 1567, 113, 1644, 1643, 1642, 1639, 1637, 1635, 1632, 1631, 1629, 111, 1627, 1626, 114, 1624, 1622, 1620, 1619, 1618, 1645, 1647, 1613, 107, 1670, 1669, 1668, 1667, 1665, 1664, 1663, 1662, 1660, 1648, 1658, 108, 1656, 1655, 1654, 1652, 1651, 1649, 116, 1612, 104, 1577, 126, 1585, 127, 1583, 1582, 1581, 128, 1579, 1576, 124, 1575, 1574, 1573, 1572, 1571, 1570, 1569, 1568, 125, 1589, 118, 1600, 1610, 1609, 1608, 1607, 1606, 1605, 1604, 1602, 1599, 1590, 121, 1597, 1596, 1595, 122, 1593, 1592, 123, 105, 103, 1780, 83, 1749, 1748, 81, 82, 1745, 1744, 1743, 1742, 1740, 1751, 1739, 1738, 1737, 1736, 84, 1734, 85, 1731, 1750, 1752, 86, 74, 1779, 71, 72, 1774, 1773, 1772, 1771, 73, 1768, 80, 1765, 75, 1762, 1761, 1758, 1757, 1756, 1755, 1730, 1728, 1674, 1685, 93, 1696, 95, 1692, 1691, 1688, 1687, 1686, 98, 1699, 1683, 1682, 99, 1679, 101, 102, 1676, 1675, 1698, 1700, 1727, 1714, 1725, 1724, 1723, 1721, 1720, 1717, 1716, 1715, 87, 1701, 1712, 1710, 89, 1708, 1707, 1706, 1705, 91, 1295, 407, 1293, 359, 704, 703, 702, 700, 336, 697, 337, 338, 694, 693, 692, 691, 690, 689, 688, 687, 686, 685, 684, 705, 707, 709, 722, 733, 732, 731, 730, 727, 726, 725, 723, 334, 710, 720, 719, 335, 717, 715, 714, 713, 712, 683, 682, 339, 356, 352, 353, 354, 643, 642, 355, 639, 638, 357, 651, 358, 634, 631, 630, 629, 628, 627, 626, 650, 652, 680, 666, 679, 678, 677, 340, 674, 673, 672, 669, 347, 653, 663, 348, 661, 349, 658, 657, 655, 654, 734, 735, 737, 799, 807, 806, 805, 804, 803, 802, 801, 800, 316, 809, 797, 796, 317, 794, 793, 791, 790, 789, 808, 810, 319, 824, 832, 312, 314, 829, 828, 827, 826, 825, 823, 811, 821, 820, 818, 817, 816, 815, 315, 812, 788, 786, 738, 748, 757, 327, 755, 754, 752, 751, 750, 749, 747, 761, 746, 329, 744, 743, 330, 741, 331, 739, 759, 762, 785, 775, 783, 782, 781, 780, 779, 778, 777, 320, 774, 325, 322, 772, 771, 769, 768, 767, 766, 764, 625, 623, 1292, 622, 387, 487, 485, 484, 482, 481, 478, 477, 475, 474, 473, 472, 390, 469, 467, 465, 464, 463, 462, 489, 490, 491, 503, 512, 383, 510, 508, 507, 506, 505, 504, 502, 492, 501, 499, 385, 386, 496, 495, 494, 493, 461, 460, 393, 419, 429, 427, 426, 403, 424, 423, 422, 404, 418, 431, 417, 416, 415, 414, 413, 405, 411, 409, 430, 432, 458, 448, 457, 394, 455, 454, 395, 396, 451, 397, 447, 433, 400, 444, 442, 441, 440, 439, 438, 402, 514, 515, 516, 583, 367, 592, 368, 369, 589, 587, 586, 370, 582, 595, 581, 371, 579, 578, 577, 576, 372, 573, 594, 596, 570, 609, 621, 360, 617, 361, 614, 613, 612, 610, 608, 598, 362, 606, 364, 603, 365, 601, 600, 599, 572, 569, 517, 378, 539, 538, 537, 536, 535, 534, 533, 532, 530, 541, 529, 527, 526, 525, 523, 381, 521, 382, 540, 542, 565, 554, 375, 563, 562, 561, 560, 559, 558, 555, 553, 543, 552, 551, 550, 548, 377, 546, 545, 544, 833, 311, 835, 837, 233, 234, 1150, 1149, 1148, 1146, 1145, 1144, 1141, 236, 1139, 1138, 1136, 1135, 1134, 237, 238, 239, 1129, 1153, 232, 1156, 226, 1180, 1176, 224, 225, 1173, 1172, 1169, 1168, 1166, 230, 227, 1164, 1163, 1162, 1161, 228, 229, 1158, 1128, 1127, 1126, 251, 1099, 1096, 1094, 1093, 1092, 1090, 247, 250, 1086, 246, 1084, 1083, 1082, 1081, 1079, 1077, 1076, 252, 1100, 1103, 1125, 1115, 1124, 1123, 1122, 1121, 240, 1118, 1117, 1116, 1114, 1105, 1113, 1112, 241, 242, 244, 1108, 1107, 245, 221, 220, 1184, 1253, 1267, 1265, 1262, 203, 1258, 1256, 1255, 1254, 204, 1270, 1250, 1249, 1248, 205, 1246, 206, 1241, 1240, 1269, 1271, 1237, 1282, 1291, 196, 197, 1288, 1287, 1286, 1284, 1283, 1281, 1272, 198, 1279, 199, 1277, 1276, 1275, 1274, 200, 1239, 1236, 1185, 1200, 1210, 1209, 1208, 1207, 1206, 218, 1204, 1201, 1199, 215, 1198, 1197, 219, 1193, 1192, 1191, 1190, 1189, 1211, 1214, 1235, 1226, 209, 1233, 1232, 1231, 210, 1229, 1228, 211, 1225, 1215, 1223, 212, 1221, 1220, 1219, 213, 1217, 1216, 1074, 1073, 1072, 904, 912, 911, 910, 909, 908, 907, 286, 905, 903, 914, 902, 901, 898, 287, 896, 894, 893, 293, 913, 285, 888, 932, 945, 944, 943, 942, 941, 939, 938, 937, 931, 917, 930, 928, 926, 925, 922, 921, 920, 284, 294, 887, 280, 849, 857, 856, 855, 304, 853, 305, 306, 307, 308, 859, 847, 846, 844, 843, 842, 310, 839, 838, 858, 303, 886, 875, 884, 297, 882, 881, 880, 879, 878, 877, 874, 861, 300, 871, 870, 301, 867, 866, 865, 862, 946, 949, 1071, 1028, 1039, 1038, 1037, 1036, 1034, 262, 264, 1029, 1027, 1046, 1025, 1023, 1022, 1021, 1017, 1015, 1014, 1013, 1045, 1047, 1011, 1059, 1068, 1067, 1066, 1065, 1063, 254, 1061, 1060, 1058, 258, 256, 1056, 257, 1053, 1052, 1051, 1050, 1049, 1012, 1008, 950, 276, 978, 976, 975, 974, 970, 969, 968, 966, 277, 981, 961, 960, 956, 278, 279, 953, 952, 951, 979, 982, 268, 998, 1006, 1005, 1004, 1003, 1002, 1001, 269, 999, 996, 983, 995, 994, 993, 989, 987, 986, 985, 272, 1203, 1098, 1097, 1754, 1452, 1095, 716, 1091, 1451, 711, 1080, 160, 724, 1482, 765, 1480, 88, 758, 1064, 1718, 753, 1719, 1722, 1069, 253, 1726, 1470, 1733, 1078, 736, 706, 332, 728, 1085, 708, 1999, 1101, 1137, 1799, 1422, 1132, 1802, 647, 1420, 644, 1807, 640, 656, 1415, 1142, 633, 632, 1412, 65, 1147, 1821, 1798, 1424, 1759, 1782, 701, 699, 1104, 1764, 1767, 1775, 1777, 1435, 165, 659, 1120, 1431, 342, 670, 1430, 343, 69, 346, 1766, 1044, 1054, 972, 1601, 295, 889, 119, 885, 1539, 980, 298, 1532, 117, 299, 115, 1617, 869, 988, 271, 1621, 864, 302, 991, 1623, 973, 971, 1702, 899, 1564, 936, 281, 934, 947, 929, 927, 924, 923, 1578, 916, 1552, 957, 958, 959, 963, 137, 275, 967, 1544, 900, 992, 1628, 270, 1525, 1666, 1024, 1026, 149, 266, 1032, 1035, 1681, 1496, 261, 1041, 318, 260, 259, 1409, 96, 1690, 784, 1693, 1694, 1487, 1506, 814, 1020, 836, 1524, 1633, 1636, 1638, 845, 1521, 1640, 112, 840, 1009, 1019, 267, 110, 1513, 1653, 1016, 822, 1659, 1018, 819, 1823, 1786, 519, 1917, 520, 62, 35, 513, 1915, 1350, 509, 1224, 1903, 1348, 1922, 1345, 1925, 1339, 1933, 1337, 214, 1360, 568, 1881, 1182, 174, 1186, 1187, 1188, 556, 1375, 549, 1363, 1195, 1196, 1886, 1369, 1202, 408, 1896, 207, 1335, 486, 1303, 446, 1268, 443, 437, 401, 435, 428, 421, 27, 4, 1285, 1990, 194, 2, 406, 1998, 1266, 399, 201, 1260, 388, 1243, 480, 479, 1244, 1245, 1329, 391, 468, 1252, 17, 1957, 1257, 14, 1259, 566, 940, 54, 1846, 585, 1841, 1171, 1397, 1843, 611, 1853, 588, 616, 575, 51, 597, 1850, 604, 1170, 1178, 61, 1393, 618, 57, 1401, 223, 1835, 620, 571, 615, 696, 665, 619, 667, 607, 662, 813, 830, 434, 675, 425, 420, 664, 528, 792, 593, 773, 452, 721, 649, 483, 602, 641, 497, 500, 646, 522, 742, 584, 1261, 851, 1650, 1735, 1732, 1729, 1713, 1709, 1689, 1673, 1671, 1661, 1616, 1746, 1615, 1614, 1603, 1591, 1558, 1542, 1527, 1512, 1510, 1741, 1753, 852, 1837, 1996, 1981, 1964, 1954, 1941, 1889, 1882, 1862, 1848, 1833, 1760, 1831, 1827, 1826, 1820, 1814, 1806, 1778, 1776, 1763, 1508, 1501, 1466, 1031, 1159, 1152, 1143, 1133, 1130, 1110, 1075, 1043, 1033, 1, 1464, 977, 915, 906, 897, 891, 890, 872, 860, 854, 1165, 1175, 1179, 1183, 1463, 1462, 1443, 1440, 1433, 1394, 1359, 1354, 1341, 1327, 1317, 1312, 1294, 1278, 1263, 410, 1251, 1234, 1218, 412, 1000, 380, 222, 341, 392, 90, 152, 155, 290, 163, 10, 164, 384, 376, 190, 273, 345, 52, 202, 189, 68, 350, 143, 235, 324, 24, 389, 379, 282, 129, 170, 77, 172, 231, 283, 326, 373, 144, 195, 255, 1055, 795, 216, 763, 868, 848, 876, 760, 217, 309, 883, 1194, 695, 292, 1181, 770, 328, 1106, 274, 1089, 1119, 745, 984, 776, 997, 248, 895, 1154, 1157, 291, 1174, 718, 1177, 740, 0, 208, 97, 511, 1747, 518, 524, 547, 1711, 94, 564, 1680, 1547, 1677, 1657, 1641, 1238, 120, 366, 130, 1559, 488, 1788, 471, 466, 1988, 1975, 1961, 1958, 20, 1950, 23, 445, 28, 1930, 37, 1905, 1894, 56, 1834, 456, 459, 1548, 1611, 363, 180, 1421, 1406, 351, 1362, 1361, 1358, 660, 648, 1349, 1346, 1315, 344, 1280, 676, 1423, 1380, 635, 1515, 151, 645, 1456, 624, 1484, 637, 154, 1584, 1557, 1553, 1222, 671, 1227, 1070, 1289, 1273, 698, 1309, 1320, 142, 161, 1167, 1376, 249, 729, 150, 1102, 1151, 834, 1411, 1131, 1586, 567, 1588, 1899, 1770, 935, 919, 476, 918, 1048, 787, 453, 1839, 1852, 50, 398, 1893, 39, 79, 1911, 1923, 1927, 798, 18, 436, 1955, 1960, 863, 9, 1976, 5, 1993, 954, 681, 962, 1704, 1230, 964, 580, 1678, 100, 1646, 1030, 1010, 1630, 1697, 1007, 557, 591, 1042, 1040, 109, 92, 76, 1594, 1088, 1695, 323, 1502, 498, 990, 1087, 590, 78, 1519, 955, 265, 263, 1684, 470, 1804, 1390, 19, 1943, 1205, 1939, 668, 1333, 1910, 892, 1347, 449, 1884, 1264, 313, 1385, 1851, 288, 1819, 1825, 321, 1140, 1968, 1290, 1408, 1247, 1986, 1155, 948, 158, 333, 1111, 1703, 1769, 243, 289, 1845, 841, 1921, 756, 1598, 1560, 850, 1057, 831, 133, 1625, 1062, 605, 873, 106, 374, 26, 141, 1323, 1932, 296, 933, 574, 1926, 1522, 1874, 1672, 22, 1298, 531, 1518, 1213, 965, 1109, 636, 1242, 1212, 1445, 1790, 1160, 1890, 1587, 1865, 450, 1580]\n",
      "500\n",
      "500\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3445 - accuracy: 0.8933 - val_loss: 0.3437 - val_accuracy: 0.8820\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2970 - accuracy: 0.9020 - val_loss: 0.3177 - val_accuracy: 0.8820\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2769 - accuracy: 0.9020 - val_loss: 0.3204 - val_accuracy: 0.8820\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2682 - accuracy: 0.9020 - val_loss: 0.2830 - val_accuracy: 0.8820\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2423 - accuracy: 0.9076 - val_loss: 0.2683 - val_accuracy: 0.8820\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2397 - accuracy: 0.9058 - val_loss: 0.2720 - val_accuracy: 0.8880\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2235 - accuracy: 0.9127 - val_loss: 0.2881 - val_accuracy: 0.9080\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2406 - accuracy: 0.9082 - val_loss: 0.2569 - val_accuracy: 0.9000\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2079 - accuracy: 0.9182 - val_loss: 0.2582 - val_accuracy: 0.9060\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1942 - accuracy: 0.9242 - val_loss: 0.2469 - val_accuracy: 0.9060\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1932 - accuracy: 0.9256 - val_loss: 0.2457 - val_accuracy: 0.9060\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1628 - accuracy: 0.9362 - val_loss: 0.2700 - val_accuracy: 0.9040\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1387 - accuracy: 0.9424 - val_loss: 0.2905 - val_accuracy: 0.9140\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1349 - accuracy: 0.9471 - val_loss: 0.2791 - val_accuracy: 0.9180\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1080 - accuracy: 0.9622 - val_loss: 0.2935 - val_accuracy: 0.9100\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0811 - accuracy: 0.9676 - val_loss: 0.3266 - val_accuracy: 0.9140\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0762 - accuracy: 0.9702 - val_loss: 0.3199 - val_accuracy: 0.9040\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0719 - accuracy: 0.9722 - val_loss: 0.3433 - val_accuracy: 0.9160\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0583 - accuracy: 0.9784 - val_loss: 0.3589 - val_accuracy: 0.8980\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0297 - accuracy: 0.9889 - val_loss: 0.4781 - val_accuracy: 0.9160\n",
      "Test loss: 0.43756797909736633\n",
      "Test accuracy: 0.9150000214576721\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.519\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3684 - accuracy: 0.8993 - val_loss: 0.3560 - val_accuracy: 0.8820\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.3080 - accuracy: 0.9020 - val_loss: 0.3761 - val_accuracy: 0.8820\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2960 - accuracy: 0.9020 - val_loss: 0.3139 - val_accuracy: 0.8820\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2735 - accuracy: 0.9020 - val_loss: 0.2914 - val_accuracy: 0.8820\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2576 - accuracy: 0.9020 - val_loss: 0.2879 - val_accuracy: 0.8820\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2381 - accuracy: 0.9096 - val_loss: 0.2674 - val_accuracy: 0.8840\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2426 - accuracy: 0.9120 - val_loss: 0.2567 - val_accuracy: 0.9060\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2197 - accuracy: 0.9176 - val_loss: 0.2659 - val_accuracy: 0.9060\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2056 - accuracy: 0.9204 - val_loss: 0.2676 - val_accuracy: 0.9080\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1822 - accuracy: 0.9264 - val_loss: 0.2407 - val_accuracy: 0.9180\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1631 - accuracy: 0.9351 - val_loss: 0.2683 - val_accuracy: 0.9100\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1534 - accuracy: 0.9378 - val_loss: 0.2759 - val_accuracy: 0.8920\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1453 - accuracy: 0.9442 - val_loss: 0.2752 - val_accuracy: 0.8980\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1108 - accuracy: 0.9549 - val_loss: 0.2936 - val_accuracy: 0.9000\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0851 - accuracy: 0.9687 - val_loss: 0.3177 - val_accuracy: 0.9020\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0748 - accuracy: 0.9704 - val_loss: 0.4015 - val_accuracy: 0.8980\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0522 - accuracy: 0.9831 - val_loss: 0.4271 - val_accuracy: 0.8800\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0513 - accuracy: 0.9818 - val_loss: 0.5361 - val_accuracy: 0.9180\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0317 - accuracy: 0.9887 - val_loss: 0.6577 - val_accuracy: 0.8980\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0221 - accuracy: 0.9936 - val_loss: 0.5188 - val_accuracy: 0.8960\n",
      "Test loss: 0.5098799467086792\n",
      "Test accuracy: 0.8939999938011169\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.7465\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3301 - accuracy: 0.8993 - val_loss: 0.3370 - val_accuracy: 0.8820\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2818 - accuracy: 0.9022 - val_loss: 0.3260 - val_accuracy: 0.8820\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2704 - accuracy: 0.9024 - val_loss: 0.3458 - val_accuracy: 0.8820\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2550 - accuracy: 0.9080 - val_loss: 0.2589 - val_accuracy: 0.8960\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2425 - accuracy: 0.9111 - val_loss: 0.2737 - val_accuracy: 0.8880\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2252 - accuracy: 0.9138 - val_loss: 0.3072 - val_accuracy: 0.8980\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2137 - accuracy: 0.9156 - val_loss: 0.2534 - val_accuracy: 0.9120\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2160 - accuracy: 0.9180 - val_loss: 0.2409 - val_accuracy: 0.9100\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2030 - accuracy: 0.9224 - val_loss: 0.2474 - val_accuracy: 0.9060\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1908 - accuracy: 0.9256 - val_loss: 0.2269 - val_accuracy: 0.9140\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1712 - accuracy: 0.9349 - val_loss: 0.2513 - val_accuracy: 0.9140\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1527 - accuracy: 0.9402 - val_loss: 0.2551 - val_accuracy: 0.9200\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1231 - accuracy: 0.9504 - val_loss: 0.2410 - val_accuracy: 0.9140\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1144 - accuracy: 0.9556 - val_loss: 0.2787 - val_accuracy: 0.9080\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0937 - accuracy: 0.9684 - val_loss: 0.2980 - val_accuracy: 0.9000\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0654 - accuracy: 0.9769 - val_loss: 0.3654 - val_accuracy: 0.9100\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0546 - accuracy: 0.9791 - val_loss: 0.4465 - val_accuracy: 0.9040\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0460 - accuracy: 0.9853 - val_loss: 0.3627 - val_accuracy: 0.9060\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0865 - accuracy: 0.9664 - val_loss: 0.4124 - val_accuracy: 0.9000\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0220 - accuracy: 0.9929 - val_loss: 0.5758 - val_accuracy: 0.9060\n",
      "Test loss: 0.5662656426429749\n",
      "Test accuracy: 0.9169999957084656\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.5175\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3496 - accuracy: 0.8882 - val_loss: 0.3742 - val_accuracy: 0.8820\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.3061 - accuracy: 0.9020 - val_loss: 0.3409 - val_accuracy: 0.8820\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2927 - accuracy: 0.9020 - val_loss: 0.3581 - val_accuracy: 0.8820\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2851 - accuracy: 0.9024 - val_loss: 0.3310 - val_accuracy: 0.8840\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2600 - accuracy: 0.9027 - val_loss: 0.2986 - val_accuracy: 0.9000\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2446 - accuracy: 0.9064 - val_loss: 0.2823 - val_accuracy: 0.9020\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2378 - accuracy: 0.9089 - val_loss: 0.2768 - val_accuracy: 0.9040\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2213 - accuracy: 0.9153 - val_loss: 0.3166 - val_accuracy: 0.8880\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2165 - accuracy: 0.9158 - val_loss: 0.2784 - val_accuracy: 0.8980\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2101 - accuracy: 0.9167 - val_loss: 0.2637 - val_accuracy: 0.8960\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1987 - accuracy: 0.9249 - val_loss: 0.2482 - val_accuracy: 0.9000\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1758 - accuracy: 0.9267 - val_loss: 0.2504 - val_accuracy: 0.9040\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1586 - accuracy: 0.9396 - val_loss: 0.3771 - val_accuracy: 0.8900\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1455 - accuracy: 0.9440 - val_loss: 0.2535 - val_accuracy: 0.9120\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1080 - accuracy: 0.9613 - val_loss: 0.2799 - val_accuracy: 0.8920\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0870 - accuracy: 0.9689 - val_loss: 0.4647 - val_accuracy: 0.9020\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0708 - accuracy: 0.9740 - val_loss: 0.3466 - val_accuracy: 0.9100\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0409 - accuracy: 0.9858 - val_loss: 0.4801 - val_accuracy: 0.9000\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0313 - accuracy: 0.9884 - val_loss: 0.5177 - val_accuracy: 0.9000\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0308 - accuracy: 0.9896 - val_loss: 0.5232 - val_accuracy: 0.9100\n",
      "Test loss: 0.5920723080635071\n",
      "Test accuracy: 0.8999999761581421\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.6215\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3406 - accuracy: 0.8971 - val_loss: 0.3428 - val_accuracy: 0.8820\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2823 - accuracy: 0.9020 - val_loss: 0.3840 - val_accuracy: 0.8820\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2767 - accuracy: 0.9020 - val_loss: 0.2999 - val_accuracy: 0.8820\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2630 - accuracy: 0.9040 - val_loss: 0.2755 - val_accuracy: 0.8880\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2402 - accuracy: 0.9087 - val_loss: 0.3066 - val_accuracy: 0.8940\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2279 - accuracy: 0.9122 - val_loss: 0.2477 - val_accuracy: 0.9080\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2050 - accuracy: 0.9198 - val_loss: 0.2543 - val_accuracy: 0.9080\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2027 - accuracy: 0.9216 - val_loss: 0.2574 - val_accuracy: 0.9120\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1758 - accuracy: 0.9307 - val_loss: 0.2580 - val_accuracy: 0.9200\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1718 - accuracy: 0.9309 - val_loss: 0.2463 - val_accuracy: 0.9140\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1500 - accuracy: 0.9424 - val_loss: 0.2619 - val_accuracy: 0.9200\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1263 - accuracy: 0.9524 - val_loss: 0.2653 - val_accuracy: 0.9160\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1018 - accuracy: 0.9609 - val_loss: 0.2559 - val_accuracy: 0.9160\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0720 - accuracy: 0.9753 - val_loss: 0.3420 - val_accuracy: 0.9260\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0574 - accuracy: 0.9800 - val_loss: 0.3420 - val_accuracy: 0.8680\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0448 - accuracy: 0.9840 - val_loss: 0.3855 - val_accuracy: 0.9300\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0519 - accuracy: 0.9833 - val_loss: 0.4210 - val_accuracy: 0.9080\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0235 - accuracy: 0.9929 - val_loss: 0.5110 - val_accuracy: 0.9260\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0169 - accuracy: 0.9949 - val_loss: 0.5260 - val_accuracy: 0.9080\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0274 - accuracy: 0.9900 - val_loss: 0.4666 - val_accuracy: 0.9120\n",
      "Test loss: 0.58290034532547\n",
      "Test accuracy: 0.902999997138977\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.7545\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3557 - accuracy: 0.8800 - val_loss: 0.3476 - val_accuracy: 0.8820\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.3072 - accuracy: 0.9020 - val_loss: 0.3380 - val_accuracy: 0.8820\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2903 - accuracy: 0.9020 - val_loss: 0.3259 - val_accuracy: 0.8820\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2860 - accuracy: 0.9020 - val_loss: 0.3218 - val_accuracy: 0.8820\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2803 - accuracy: 0.9022 - val_loss: 0.3245 - val_accuracy: 0.8820\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2559 - accuracy: 0.9058 - val_loss: 0.2486 - val_accuracy: 0.8980\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2388 - accuracy: 0.9076 - val_loss: 0.2531 - val_accuracy: 0.9040\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2325 - accuracy: 0.9093 - val_loss: 0.2656 - val_accuracy: 0.9060\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2128 - accuracy: 0.9167 - val_loss: 0.2783 - val_accuracy: 0.9040\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2008 - accuracy: 0.9247 - val_loss: 0.2452 - val_accuracy: 0.9200\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1940 - accuracy: 0.9213 - val_loss: 0.2460 - val_accuracy: 0.8960\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1767 - accuracy: 0.9304 - val_loss: 0.2567 - val_accuracy: 0.9140\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1597 - accuracy: 0.9380 - val_loss: 0.3279 - val_accuracy: 0.9040\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1520 - accuracy: 0.9413 - val_loss: 0.2598 - val_accuracy: 0.9180\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1135 - accuracy: 0.9576 - val_loss: 0.4034 - val_accuracy: 0.9040\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1013 - accuracy: 0.9589 - val_loss: 0.3023 - val_accuracy: 0.9020\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0801 - accuracy: 0.9724 - val_loss: 0.3895 - val_accuracy: 0.9120\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0564 - accuracy: 0.9784 - val_loss: 0.3954 - val_accuracy: 0.9060\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0441 - accuracy: 0.9864 - val_loss: 0.3725 - val_accuracy: 0.9160\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0296 - accuracy: 0.9891 - val_loss: 0.5867 - val_accuracy: 0.9120\n",
      "Test loss: 0.5405881404876709\n",
      "Test accuracy: 0.9079999923706055\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.3095\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3326 - accuracy: 0.8800 - val_loss: 0.3311 - val_accuracy: 0.8820\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2988 - accuracy: 0.9020 - val_loss: 0.3169 - val_accuracy: 0.8820\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2693 - accuracy: 0.9011 - val_loss: 0.2798 - val_accuracy: 0.8920\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2505 - accuracy: 0.9047 - val_loss: 0.2622 - val_accuracy: 0.9080\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2288 - accuracy: 0.9120 - val_loss: 0.2674 - val_accuracy: 0.9120\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2256 - accuracy: 0.9147 - val_loss: 0.3419 - val_accuracy: 0.8860\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2173 - accuracy: 0.9171 - val_loss: 0.2452 - val_accuracy: 0.9200\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1899 - accuracy: 0.9262 - val_loss: 0.2732 - val_accuracy: 0.8980\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1704 - accuracy: 0.9338 - val_loss: 0.2868 - val_accuracy: 0.9220\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1646 - accuracy: 0.9336 - val_loss: 0.2568 - val_accuracy: 0.9080\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1528 - accuracy: 0.9402 - val_loss: 0.3342 - val_accuracy: 0.9200\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1212 - accuracy: 0.9533 - val_loss: 0.2944 - val_accuracy: 0.9220\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1122 - accuracy: 0.9556 - val_loss: 0.3230 - val_accuracy: 0.8960\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0767 - accuracy: 0.9718 - val_loss: 0.3011 - val_accuracy: 0.9040\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1107 - accuracy: 0.9578 - val_loss: 0.4564 - val_accuracy: 0.9200\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0578 - accuracy: 0.9773 - val_loss: 0.3562 - val_accuracy: 0.9180\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0321 - accuracy: 0.9887 - val_loss: 0.4101 - val_accuracy: 0.9040\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0371 - accuracy: 0.9887 - val_loss: 0.5137 - val_accuracy: 0.9240\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0158 - accuracy: 0.9962 - val_loss: 0.5233 - val_accuracy: 0.9200\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0085 - accuracy: 0.9978 - val_loss: 0.4559 - val_accuracy: 0.9260\n",
      "Test loss: 0.564409613609314\n",
      "Test accuracy: 0.8939999938011169\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.718\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3430 - accuracy: 0.8893 - val_loss: 0.3380 - val_accuracy: 0.8820\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2839 - accuracy: 0.9020 - val_loss: 0.3130 - val_accuracy: 0.8820\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2608 - accuracy: 0.9020 - val_loss: 0.2924 - val_accuracy: 0.8820\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2528 - accuracy: 0.9047 - val_loss: 0.3903 - val_accuracy: 0.8820\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2585 - accuracy: 0.9036 - val_loss: 0.3054 - val_accuracy: 0.8840\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2347 - accuracy: 0.9122 - val_loss: 0.2468 - val_accuracy: 0.9060\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2197 - accuracy: 0.9187 - val_loss: 0.2714 - val_accuracy: 0.9060\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2081 - accuracy: 0.9196 - val_loss: 0.2620 - val_accuracy: 0.9060\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2041 - accuracy: 0.9211 - val_loss: 0.2475 - val_accuracy: 0.9160\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1911 - accuracy: 0.9267 - val_loss: 0.2870 - val_accuracy: 0.9180\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1710 - accuracy: 0.9349 - val_loss: 0.3073 - val_accuracy: 0.8980\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1584 - accuracy: 0.9398 - val_loss: 0.2651 - val_accuracy: 0.9140\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1283 - accuracy: 0.9476 - val_loss: 0.2704 - val_accuracy: 0.9280\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1070 - accuracy: 0.9587 - val_loss: 0.2799 - val_accuracy: 0.9080\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0852 - accuracy: 0.9687 - val_loss: 0.2970 - val_accuracy: 0.9060\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0770 - accuracy: 0.9729 - val_loss: 0.3953 - val_accuracy: 0.9080\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0487 - accuracy: 0.9813 - val_loss: 0.4227 - val_accuracy: 0.9040\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0394 - accuracy: 0.9853 - val_loss: 0.4874 - val_accuracy: 0.9120\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0552 - accuracy: 0.9811 - val_loss: 0.4367 - val_accuracy: 0.9140\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0153 - accuracy: 0.9958 - val_loss: 0.5447 - val_accuracy: 0.9040\n",
      "Test loss: 0.5479967594146729\n",
      "Test accuracy: 0.9150000214576721\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.5765\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3448 - accuracy: 0.8804 - val_loss: 0.3677 - val_accuracy: 0.8820\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.3010 - accuracy: 0.9020 - val_loss: 0.3210 - val_accuracy: 0.8820\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2682 - accuracy: 0.9002 - val_loss: 0.3028 - val_accuracy: 0.8820\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2602 - accuracy: 0.9031 - val_loss: 0.3105 - val_accuracy: 0.8960\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2483 - accuracy: 0.9058 - val_loss: 0.2486 - val_accuracy: 0.9060\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2290 - accuracy: 0.9102 - val_loss: 0.2622 - val_accuracy: 0.9020\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2112 - accuracy: 0.9162 - val_loss: 0.2612 - val_accuracy: 0.9080\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1992 - accuracy: 0.9227 - val_loss: 0.2710 - val_accuracy: 0.9060\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1957 - accuracy: 0.9236 - val_loss: 0.2609 - val_accuracy: 0.9140\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1782 - accuracy: 0.9304 - val_loss: 0.2761 - val_accuracy: 0.9020\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1550 - accuracy: 0.9373 - val_loss: 0.2753 - val_accuracy: 0.9000\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1496 - accuracy: 0.9387 - val_loss: 0.2719 - val_accuracy: 0.9140\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1278 - accuracy: 0.9469 - val_loss: 0.3030 - val_accuracy: 0.9240\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0929 - accuracy: 0.9649 - val_loss: 0.3224 - val_accuracy: 0.9080\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0760 - accuracy: 0.9698 - val_loss: 0.3327 - val_accuracy: 0.9140\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0598 - accuracy: 0.9771 - val_loss: 0.4037 - val_accuracy: 0.9120\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0433 - accuracy: 0.9844 - val_loss: 0.4499 - val_accuracy: 0.9100\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0309 - accuracy: 0.9887 - val_loss: 0.4947 - val_accuracy: 0.8940\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0349 - accuracy: 0.9876 - val_loss: 0.5054 - val_accuracy: 0.9020\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0237 - accuracy: 0.9904 - val_loss: 0.5389 - val_accuracy: 0.9180\n",
      "Test loss: 0.597958505153656\n",
      "Test accuracy: 0.9129999876022339\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.5665\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3417 - accuracy: 0.8918 - val_loss: 0.3512 - val_accuracy: 0.8820\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2889 - accuracy: 0.9020 - val_loss: 0.3604 - val_accuracy: 0.8840\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2708 - accuracy: 0.9018 - val_loss: 0.3125 - val_accuracy: 0.8820\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2543 - accuracy: 0.9064 - val_loss: 0.2602 - val_accuracy: 0.9000\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2402 - accuracy: 0.9098 - val_loss: 0.2790 - val_accuracy: 0.8920\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2236 - accuracy: 0.9173 - val_loss: 0.2857 - val_accuracy: 0.8980\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2398 - accuracy: 0.9142 - val_loss: 0.2519 - val_accuracy: 0.9000\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1996 - accuracy: 0.9247 - val_loss: 0.2946 - val_accuracy: 0.8940\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1851 - accuracy: 0.9258 - val_loss: 0.3085 - val_accuracy: 0.9000\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1664 - accuracy: 0.9356 - val_loss: 0.2766 - val_accuracy: 0.9160\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1556 - accuracy: 0.9402 - val_loss: 0.2772 - val_accuracy: 0.9140\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1277 - accuracy: 0.9487 - val_loss: 0.3127 - val_accuracy: 0.9060\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1189 - accuracy: 0.9567 - val_loss: 0.2816 - val_accuracy: 0.9220\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0908 - accuracy: 0.9629 - val_loss: 0.3417 - val_accuracy: 0.9140\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0657 - accuracy: 0.9753 - val_loss: 0.3816 - val_accuracy: 0.9080\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0828 - accuracy: 0.9656 - val_loss: 0.4624 - val_accuracy: 0.8960\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0450 - accuracy: 0.9833 - val_loss: 0.5666 - val_accuracy: 0.9160\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0244 - accuracy: 0.9911 - val_loss: 0.7344 - val_accuracy: 0.9160\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0164 - accuracy: 0.9953 - val_loss: 0.6208 - val_accuracy: 0.8920\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0130 - accuracy: 0.9953 - val_loss: 0.5713 - val_accuracy: 0.9040\n",
      "Test loss: 0.5235806703567505\n",
      "Test accuracy: 0.9039999842643738\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.593\n",
      "      通し番号  カウント\n",
      "0        0     3\n",
      "1        1     7\n",
      "2        2     7\n",
      "3        3     4\n",
      "4        4     3\n",
      "...    ...   ...\n",
      "1995  1995    10\n",
      "1996  1996     9\n",
      "1997  1997     7\n",
      "1998  1998    10\n",
      "1999  1999     4\n",
      "\n",
      "[2000 rows x 2 columns]\n",
      "[0.519, 0.7465, 0.5175, 0.6215, 0.7545, 0.3095, 0.718, 0.5765, 0.5665, 0.593]\n",
      "11\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[1921, 1360, 1932, 170, 1062, 1233, 60, 1356, 1237, 1284, 1496, 192, 186, 191, 1277, 1090, 1110, 1426, 1086, 1069, 1503, 1247, 1416, 1368, 1113, 1112, 1936, 1197, 1397, 1183, 1182, 1201, 1207, 1174, 1173, 45, 1315, 130, 1946, 91, 1276, 88, 1471, 1211, 1381, 142, 1433, 1222, 20, 1120, 1116, 1981, 471, 1575, 1050, 1663, 1815, 1817, 386, 715, 741, 742, 1667, 367, 1829, 332, 1658, 358, 774, 1838, 1643, 785, 793, 815, 393, 690, 401, 1805, 510, 512, 1779, 519, 444, 439, 557, 433, 578, 1791, 596, 635, 644, 652, 1700, 670, 407, 1847, 1630, 1046, 998, 479, 1574, 945, 948, 960, 1895, 978, 987, 999, 323, 1539, 216, 1012, 1017, 1023, 1908, 1027, 1522, 944, 941, 1882, 1583, 832, 1624, 310, 1859, 848, 850, 1613, 301, 1611, 294, 889, 281, 892, 1592, 276, 275, 925, 1364, 225, 1887, 1772, 49, 258, 1983, 5, 30, 464, 1991, 203, 1892, 208, 240, 458, 1885, 434, 1902, 262, 51, 315, 390, 154, 92, 1851, 99, 326, 1845, 335, 374, 1823, 368, 145, 1830, 1831, 394, 171, 304, 1873, 197, 1879, 55, 273, 1916, 188, 66, 1968, 1796, 420, 1969, 299, 1862, 1803, 1794, 703, 787, 734, 1466, 864, 1461, 1181, 1617, 835, 1450, 831, 1444, 1631, 826, 824, 823, 1058, 1210, 781, 1653, 1654, 1655, 758, 756, 1423, 1413, 869, 873, 1467, 1491, 1032, 1070, 1506, 1075, 997, 996, 1094, 1555, 971, 966, 1562, 1136, 951, 949, 1488, 924, 920, 912, 1479, 911, 1121, 905, 737, 1515, 717, 576, 1301, 1305, 1390, 640, 1710, 626, 625, 598, 1327, 1380, 1348, 539, 1398, 1374, 1352, 538, 514, 1753, 1362, 1761, 1763, 1764, 486, 484, 1395, 630, 673, 684, 1405, 1367, 694, 1298, 1688, 712, 701, 1695, 1945, 1219, 1964, 94, 83, 1464, 1828, 1454, 1194, 1193, 1178, 731, 106, 109, 1001, 400, 1989, 1300, 563, 438, 446, 1987, 1319, 1990, 1291, 1349, 1376, 507, 505, 462, 482, 39, 588, 1802, 623, 69, 409, 650, 638, 1261, 1153, 1265, 1727, 1266, 1272, 601, 597, 431, 1282, 1263, 360, 469, 185, 1621, 239, 1108, 963, 861, 207, 1909, 181, 887, 1605, 282, 958, 184, 895, 957, 840, 187, 134, 904, 280, 907, 1568, 908, 950, 1523, 946, 930, 1913, 1580, 1518, 843, 307, 1489, 230, 1939, 149, 1842, 349, 807, 993, 780, 809, 1538, 817, 1548, 150, 1550, 986, 324, 141, 1486, 1536, 219, 352, 1016, 1839, 272, 902, 1618, 279, 306, 302, 865, 991, 1552, 981, 1867, 288, 1563, 1581, 1871, 899, 234, 959, 894, 1576, 259, 1589, 269, 1604, 888, 243, 0, 312, 666, 421, 422, 622, 1720, 603, 1793, 594, 590, 1790, 1734, 436, 544, 541, 537, 532, 529, 451, 511, 460, 498, 466, 656, 1807, 834, 398, 1628, 1850, 334, 350, 1646, 779, 778, 771, 755, 753, 751, 748, 369, 1541, 733, 377, 380, 1678, 388, 697, 685, 226, 246, 1159, 1409, 68, 1443, 95, 151, 65, 1410, 1511, 1209, 1060, 1192, 195, 1955, 1490, 1403, 1071, 1072, 1288, 1495, 1109, 1231, 1966, 1242, 1103, 1245, 1098, 155, 1928, 1218, 86, 1085, 183, 1249, 1043, 1224, 1911, 122, 1537, 1472, 19, 1147, 1015, 1140, 1354, 11, 1334, 22, 1164, 1316, 1165, 1527, 121, 1117, 1526, 217, 1309, 1302, 1984, 117, 4, 1148, 1114, 202, 17, 1972, 1378, 1377, 1978, 1383, 1953, 1528, 1947, 1480, 1439, 1762, 1759, 1755, 1731, 1712, 1365, 1684, 1482, 1388, 1672, 1669, 1657, 1644, 1497, 1637, 1620, 1519, 1438, 1799, 1800, 1436, 1938, 1934, 1929, 1926, 1917, 1404, 1406, 1407, 1408, 1894, 1891, 1858, 1843, 1841, 1834, 1832, 1809, 1445, 1999, 373, 896, 1189, 383, 710, 705, 704, 1198, 387, 919, 693, 396, 1217, 689, 688, 78, 268, 677, 676, 844, 70, 674, 199, 1044, 654, 103, 1179, 1255, 747, 318, 792, 176, 351, 783, 1125, 138, 177, 1142, 775, 884, 353, 356, 770, 764, 363, 760, 1161, 754, 1172, 118, 1074, 1175, 413, 1234, 1258, 975, 552, 934, 1020, 28, 1312, 961, 536, 535, 1321, 1325, 238, 566, 524, 447, 1342, 450, 1009, 1351, 459, 508, 503, 3, 561, 845, 568, 585, 267, 425, 1040, 620, 618, 614, 612, 1029, 54, 1028, 1286, 249, 580, 1290, 475, 42, 81, 1229, 382, 1821, 1962, 1810, 74, 417, 364, 1806, 1822, 1963, 359, 370, 1428, 82, 1220, 682, 1425, 1306, 213, 1905, 1289, 1922, 1296, 169, 168, 153, 1901, 111, 144, 1942, 1313, 137, 1324, 124, 104, 1900, 1243, 292, 337, 319, 1250, 1960, 1252, 1864, 300, 286, 1271, 1880, 1881, 264, 1415, 263, 1268, 1269, 1213, 572, 1344, 1692, 13, 1081, 829, 828, 827, 820, 1986, 794, 1641, 33, 1101, 763, 761, 1662, 1487, 725, 1481, 1118, 1677, 1124, 706, 1683, 1130, 1079, 1076, 1073, 927, 1011, 1033, 1542, 985, 983, 982, 1554, 1363, 1559, 939, 926, 1610, 1586, 1587, 1591, 1593, 1596, 901, 1597, 1598, 1599, 1068, 1685, 686, 683, 575, 1458, 1950, 554, 553, 1740, 533, 527, 523, 1186, 1760, 499, 465, 1195, 463, 1530, 461, 1199, 455, 432, 427, 426, 423, 1798, 573, 1948, 64, 1152, 668, 667, 662, 1702, 1703, 1706, 1707, 636, 634, 1150, 633, 631, 1155, 628, 619, 616, 1162, 605, 1463, 602, 1728, 1484, 1273, 1063, 1205, 1264, 1299, 1372, 1214, 1371, 1129, 1215, 1067, 1077, 1254, 1502, 1167, 1424, 1308, 1083, 1244, 1328, 1307, 1392, 1501, 1160, 1177, 1176, 1337, 1230, 1037, 1225, 1223, 1131, 1435, 1091, 1092, 1353, 1449, 1366, 96, 728, 708, 1679, 1890, 714, 93, 718, 419, 719, 236, 231, 46, 722, 101, 727, 1980, 389, 228, 744, 1982, 1666, 480, 1660, 220, 1769, 35, 102, 343, 1642, 31, 384, 1973, 257, 1975, 700, 87, 591, 1726, 1723, 339, 604, 333, 320, 607, 1840, 313, 1713, 61, 629, 549, 528, 1865, 296, 1874, 1876, 517, 658, 660, 1883, 669, 1974, 261, 692, 500, 1640, 218, 801, 953, 159, 1952, 457, 916, 805, 152, 402, 928, 929, 79, 940, 1572, 1567, 955, 163, 1943, 967, 404, 973, 979, 135, 1944, 132, 1004, 1006, 115, 67, 1019, 162, 345, 1777, 1629, 1776, 200, 1910, 1907, 1623, 1625, 204, 856, 395, 821, 212, 818, 810, 105, 854, 851, 858, 399, 860, 882, 874, 863, 107, 871, 182, 1304, 1935, 156, 947, 1725, 938, 1681, 599, 1570, 160, 1569, 1579, 1933, 1447, 1126, 1915, 1904, 906, 582, 1059, 211, 583, 1906, 1401, 201, 1918, 165, 1919, 1057, 1923, 1477, 592, 175, 1394, 1052, 709, 1168, 113, 1941, 1311, 1375, 56, 681, 1036, 1, 1005, 1979, 1357, 36, 1696, 1985, 29, 653, 1994, 671, 14, 10, 6, 1997, 2, 1026, 1711, 1967, 1343, 1119, 954, 1166, 133, 698, 127, 126, 1163, 1949, 119, 968, 76, 970, 613, 1556, 1335, 1041, 1716, 1038, 1341, 988, 1283, 721, 581, 1084, 757, 1188, 1106, 1819, 1107, 1232, 1429, 1835, 1836, 348, 749, 1190, 1184, 838, 1510, 1750, 841, 530, 1747, 1080, 1619, 325, 759, 410, 1745, 788, 472, 1649, 1765, 1647, 1200, 1202, 1100, 784, 448, 442, 492, 1104, 766, 765, 1789, 1204, 429, 796, 1795, 1440, 495, 497, 1853, 520, 1422, 293, 254, 1417, 1607, 569, 1868, 866, 1419, 1066, 284, 732, 1259, 1739, 565, 1875, 266, 1606, 260, 1603, 1893, 314, 540, 543, 473, 1278, 1602, 546, 1878, 297, 1256, 893, 248, 1459, 570, 1687, 1139, 1535, 1025, 695, 1689, 1543, 977, 992, 1697, 1520, 1476, 1022, 1698, 1532, 1135, 1549, 1035, 797, 699, 702, 885, 881, 879, 750, 1509, 1664, 867, 1612, 1105, 1504, 1494, 857, 852, 847, 842, 1475, 837, 1087, 1633, 819, 1636, 808, 1097, 790, 802, 1096, 1095, 746, 891, 745, 1053, 1128, 1682, 707, 962, 716, 1565, 956, 720, 1571, 1115, 943, 931, 1055, 1601, 922, 1056, 1673, 917, 1513, 1588, 1590, 1061, 1670, 743, 897, 1064, 839, 1000, 665, 470, 328, 327, 661, 1854, 309, 305, 1861, 1420, 298, 295, 1257, 289, 283, 278, 277, 270, 265, 1414, 1267, 251, 1889, 1412, 237, 329, 1246, 338, 1801, 468, 1203, 440, 1786, 437, 1788, 1206, 1437, 416, 415, 406, 340, 1434, 1432, 392, 391, 1813, 381, 378, 1825, 1827, 1241, 227, 223, 1280, 53, 1956, 1957, 1338, 1339, 1340, 80, 77, 62, 58, 1976, 52, 1332, 1977, 48, 47, 1358, 1370, 24, 21, 1992, 16, 9, 1333, 112, 1287, 158, 210, 206, 193, 1925, 1297, 180, 178, 173, 166, 161, 157, 1951, 1937, 147, 1940, 143, 140, 1314, 1317, 1318, 125, 1385, 1771, 1524, 600, 564, 1470, 1709, 608, 1170, 1151, 1169, 1469, 1724, 610, 545, 627, 494, 504, 1714, 1525, 1757, 509, 611, 1715, 1185, 621, 559, 1146, 637, 548, 491, 483, 1766, 1733, 1143, 1746, 1460, 488, 1704, 1718, 649, 646, 1729, 1462, 550, 586, 1111, 1645, 642, 1741, 560, 547, 435, 443, 1639, 739, 663, 782, 1743, 1694, 1775, 1441, 729, 1675, 441, 1785, 791, 556, 648, 1699, 1455, 1781, 647, 555, 738, 651, 452, 675, 454, 645, 672, 593, 641, 1478, 1133, 1656, 518, 584, 587, 551, 489, 1465, 1122, 768, 606, 516, 767, 696, 589, 1102, 1721, 762, 515, 1191, 1754, 501, 502, 1127, 1187, 691, 1717, 1196, 1171, 534, 567, 1773, 639, 1708, 726, 679, 680, 1665, 1137, 571, 1453, 1452, 1154, 474, 773, 526, 476, 478, 624, 1134, 687, 1451, 1690, 579, 1149, 1752, 205, 1547, 1346, 221, 1281, 1903, 1594, 1512, 909, 1345, 798, 271, 1400, 198, 1294, 71, 72, 189, 73, 921, 1279, 63, 1899, 898, 1262, 877, 1007, 1042, 50, 886, 1540, 253, 250, 57, 994, 1065, 59, 1274, 232, 1898, 229, 990, 1399, 923, 136, 1564, 1959, 131, 1386, 129, 1561, 965, 1322, 1558, 116, 1517, 1958, 1382, 1384, 974, 1330, 1331, 1336, 89, 174, 1516, 172, 1931, 1551, 984, 1303, 933, 937, 1051, 1578, 1039, 1577, 1573, 1391, 148, 85, 1310, 952, 876, 1954, 1008, 1430, 385, 1226, 379, 1088, 1228, 376, 1824, 372, 1826, 1240, 12, 366, 1632, 362, 361, 875, 357, 1031, 1818, 1816, 1499, 1635, 799, 424, 800, 1498, 1024, 414, 1996, 1093, 1638, 408, 1529, 7, 403, 811, 1811, 8, 816, 1238, 1833, 344, 1609, 1869, 26, 1863, 1253, 342, 1361, 1013, 287, 859, 1507, 290, 32, 34, 38, 1251, 1521, 308, 846, 1626, 836, 1872, 1531, 1533, 1857, 1849, 1870, 322, 849, 1855, 1856, 1701, 880, 1608, 1260, 274, 1877, 1756, 513, 1418, 1668, 878, 1493, 752, 1884, 883, 1886, 1888, 1270, 256, 255, 1751, 521, 872, 870, 890, 1505, 769, 1078, 490, 1860, 853, 303, 493, 855, 496, 1614, 1758, 1866, 862, 291, 1659, 1508, 1661, 285, 868, 506, 252, 522, 190, 913, 1595, 1742, 542, 215, 214, 428, 910, 209, 1402, 736, 903, 1292, 914, 1293, 1912, 1914, 196, 915, 194, 735, 740, 222, 525, 235, 247, 1600, 245, 244, 242, 241, 1896, 1749, 1275, 1897, 1744, 233, 1492, 1411, 531, 1748, 1180, 900, 1671, 224, 311, 487, 1421, 1099, 1431, 1783, 1812, 1782, 786, 449, 1814, 1780, 453, 1227, 397, 1089, 1820, 456, 1778, 375, 822, 1442, 371, 1634, 814, 813, 1615, 412, 430, 1792, 1797, 1208, 1212, 418, 1787, 803, 804, 411, 1221, 806, 789, 1804, 405, 1216, 1784, 445, 812, 1808, 1774, 1446, 365, 481, 1844, 1846, 1768, 1848, 331, 330, 1082, 1448, 1622, 1767, 825, 1852, 772, 1652, 321, 1616, 1248, 485, 317, 316, 336, 477, 833, 341, 467, 1648, 777, 1235, 1236, 776, 1770, 355, 354, 1500, 1837, 1427, 1650, 1239, 830, 347, 346, 1651, 1627, 1456, 1285, 1674, 75, 980, 84, 1553, 1468, 1691, 1379, 1965, 989, 1158, 1961, 1157, 1156, 1970, 1971, 1693, 1347, 1350, 632, 617, 615, 1373, 1557, 595, 1323, 114, 969, 1722, 110, 1326, 108, 1329, 90, 1132, 972, 100, 97, 609, 976, 1686, 1719, 1546, 995, 711, 1369, 1145, 655, 1993, 18, 1018, 1144, 15, 1030, 657, 23, 1995, 1021, 659, 1474, 1138, 1141, 1998, 664, 1988, 25, 1545, 43, 1544, 678, 1002, 1003, 1473, 1034, 1355, 44, 41, 27, 40, 643, 37, 1010, 1359, 1534, 1014, 1705, 1680, 98, 795, 1054, 1049, 1930, 146, 577, 562, 1732, 1048, 723, 1738, 1047, 139, 1389, 1676, 1387, 1737, 574, 1927, 1735, 164, 1736, 932, 1485, 935, 936, 1582, 1396, 1514, 1483, 942, 167, 1457, 724, 1584, 1393, 1566, 558, 120, 964, 918, 1045, 123, 1920, 1320, 713, 1295, 1560, 1123, 1924, 128, 730, 1730, 179, 1585]\n",
      "500\n",
      "500\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3098 - accuracy: 0.8818 - val_loss: 0.2698 - val_accuracy: 0.9060\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2688 - accuracy: 0.8993 - val_loss: 0.2436 - val_accuracy: 0.9060\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2540 - accuracy: 0.8993 - val_loss: 0.2461 - val_accuracy: 0.9060\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2486 - accuracy: 0.8991 - val_loss: 0.2123 - val_accuracy: 0.9060\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2291 - accuracy: 0.9047 - val_loss: 0.2392 - val_accuracy: 0.9060\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2396 - accuracy: 0.9036 - val_loss: 0.2083 - val_accuracy: 0.9160\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2213 - accuracy: 0.9133 - val_loss: 0.2243 - val_accuracy: 0.9160\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2078 - accuracy: 0.9167 - val_loss: 0.1878 - val_accuracy: 0.9360\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1893 - accuracy: 0.9262 - val_loss: 0.2461 - val_accuracy: 0.9280\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2005 - accuracy: 0.9240 - val_loss: 0.2484 - val_accuracy: 0.9220\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1747 - accuracy: 0.9313 - val_loss: 0.1908 - val_accuracy: 0.9340\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1562 - accuracy: 0.9413 - val_loss: 0.1832 - val_accuracy: 0.9380\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1266 - accuracy: 0.9511 - val_loss: 0.2134 - val_accuracy: 0.9360\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1247 - accuracy: 0.9507 - val_loss: 0.1829 - val_accuracy: 0.9340\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0980 - accuracy: 0.9642 - val_loss: 0.2036 - val_accuracy: 0.9300\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0877 - accuracy: 0.9653 - val_loss: 0.1820 - val_accuracy: 0.9380\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0833 - accuracy: 0.9644 - val_loss: 0.2343 - val_accuracy: 0.9400\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0923 - accuracy: 0.9627 - val_loss: 0.3123 - val_accuracy: 0.9380\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0681 - accuracy: 0.9753 - val_loss: 0.2447 - val_accuracy: 0.9360\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0365 - accuracy: 0.9856 - val_loss: 0.3433 - val_accuracy: 0.9360\n",
      "Test loss: 0.3755337595939636\n",
      "Test accuracy: 0.9309999942779541\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.594\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3241 - accuracy: 0.8918 - val_loss: 0.2849 - val_accuracy: 0.9060\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2732 - accuracy: 0.8993 - val_loss: 0.2544 - val_accuracy: 0.9060\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2550 - accuracy: 0.8993 - val_loss: 0.2633 - val_accuracy: 0.9060\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2423 - accuracy: 0.8998 - val_loss: 0.2347 - val_accuracy: 0.9100\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2310 - accuracy: 0.9051 - val_loss: 0.2182 - val_accuracy: 0.9120\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2158 - accuracy: 0.9084 - val_loss: 0.2121 - val_accuracy: 0.9240\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2110 - accuracy: 0.9162 - val_loss: 0.2120 - val_accuracy: 0.9040\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1903 - accuracy: 0.9209 - val_loss: 0.2283 - val_accuracy: 0.9180\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1966 - accuracy: 0.9220 - val_loss: 0.2135 - val_accuracy: 0.9160\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1628 - accuracy: 0.9338 - val_loss: 0.2139 - val_accuracy: 0.9180\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1466 - accuracy: 0.9442 - val_loss: 0.1763 - val_accuracy: 0.9420\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1352 - accuracy: 0.9460 - val_loss: 0.1759 - val_accuracy: 0.9360\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1124 - accuracy: 0.9558 - val_loss: 0.3030 - val_accuracy: 0.9240\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1312 - accuracy: 0.9491 - val_loss: 0.1750 - val_accuracy: 0.9420\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0843 - accuracy: 0.9689 - val_loss: 0.2209 - val_accuracy: 0.9360\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0880 - accuracy: 0.9638 - val_loss: 0.2063 - val_accuracy: 0.9340\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0638 - accuracy: 0.9740 - val_loss: 0.2143 - val_accuracy: 0.9400\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0411 - accuracy: 0.9856 - val_loss: 0.3102 - val_accuracy: 0.9360\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0433 - accuracy: 0.9824 - val_loss: 0.2515 - val_accuracy: 0.9360\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0342 - accuracy: 0.9887 - val_loss: 0.3378 - val_accuracy: 0.9360\n",
      "Test loss: 0.37193557620048523\n",
      "Test accuracy: 0.9399999976158142\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.6225\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3147 - accuracy: 0.8853 - val_loss: 0.2641 - val_accuracy: 0.9060\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2685 - accuracy: 0.8993 - val_loss: 0.2631 - val_accuracy: 0.9060\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2646 - accuracy: 0.8993 - val_loss: 0.2504 - val_accuracy: 0.9060\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2422 - accuracy: 0.8993 - val_loss: 0.2280 - val_accuracy: 0.9100\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2285 - accuracy: 0.9020 - val_loss: 0.2224 - val_accuracy: 0.9140\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2174 - accuracy: 0.9093 - val_loss: 0.2947 - val_accuracy: 0.8980\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2568 - accuracy: 0.9033 - val_loss: 0.2050 - val_accuracy: 0.9140\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2189 - accuracy: 0.9084 - val_loss: 0.2381 - val_accuracy: 0.9060\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2038 - accuracy: 0.9167 - val_loss: 0.2138 - val_accuracy: 0.9200\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1882 - accuracy: 0.9262 - val_loss: 0.2070 - val_accuracy: 0.9160\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1785 - accuracy: 0.9284 - val_loss: 0.1846 - val_accuracy: 0.9320\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1582 - accuracy: 0.9358 - val_loss: 0.1688 - val_accuracy: 0.9340\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1448 - accuracy: 0.9436 - val_loss: 0.1740 - val_accuracy: 0.9400\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1206 - accuracy: 0.9527 - val_loss: 0.1814 - val_accuracy: 0.9380\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1123 - accuracy: 0.9553 - val_loss: 0.1908 - val_accuracy: 0.9220\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0951 - accuracy: 0.9667 - val_loss: 0.2361 - val_accuracy: 0.9320\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0761 - accuracy: 0.9693 - val_loss: 0.1942 - val_accuracy: 0.9440\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0599 - accuracy: 0.9744 - val_loss: 0.2174 - val_accuracy: 0.9320\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0480 - accuracy: 0.9827 - val_loss: 0.2445 - val_accuracy: 0.9340\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0537 - accuracy: 0.9809 - val_loss: 0.3006 - val_accuracy: 0.9000\n",
      "Test loss: 0.3757144808769226\n",
      "Test accuracy: 0.902999997138977\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.857\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3134 - accuracy: 0.8947 - val_loss: 0.2756 - val_accuracy: 0.9060\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2775 - accuracy: 0.8991 - val_loss: 0.2554 - val_accuracy: 0.9060\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2575 - accuracy: 0.8993 - val_loss: 0.2401 - val_accuracy: 0.9060\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2543 - accuracy: 0.8991 - val_loss: 0.2312 - val_accuracy: 0.9060\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2378 - accuracy: 0.8991 - val_loss: 0.2303 - val_accuracy: 0.9120\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2324 - accuracy: 0.9036 - val_loss: 0.2137 - val_accuracy: 0.9240\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2273 - accuracy: 0.9076 - val_loss: 0.2140 - val_accuracy: 0.9240\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2112 - accuracy: 0.9111 - val_loss: 0.2054 - val_accuracy: 0.9180\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1950 - accuracy: 0.9191 - val_loss: 0.1983 - val_accuracy: 0.9240\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1755 - accuracy: 0.9304 - val_loss: 0.2455 - val_accuracy: 0.9200\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1524 - accuracy: 0.9364 - val_loss: 0.2000 - val_accuracy: 0.9300\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1419 - accuracy: 0.9429 - val_loss: 0.2982 - val_accuracy: 0.9180\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1341 - accuracy: 0.9511 - val_loss: 0.2039 - val_accuracy: 0.9420\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1000 - accuracy: 0.9627 - val_loss: 0.1784 - val_accuracy: 0.9340\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0981 - accuracy: 0.9596 - val_loss: 0.2551 - val_accuracy: 0.9320\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0747 - accuracy: 0.9738 - val_loss: 0.2029 - val_accuracy: 0.9300\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0627 - accuracy: 0.9758 - val_loss: 0.2551 - val_accuracy: 0.9440\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0679 - accuracy: 0.9742 - val_loss: 0.2800 - val_accuracy: 0.9360\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0397 - accuracy: 0.9849 - val_loss: 0.3151 - val_accuracy: 0.9440\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0240 - accuracy: 0.9920 - val_loss: 0.3324 - val_accuracy: 0.9320\n",
      "Test loss: 0.3119296729564667\n",
      "Test accuracy: 0.9369999766349792\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.817\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3113 - accuracy: 0.8838 - val_loss: 0.2654 - val_accuracy: 0.9060\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2626 - accuracy: 0.8991 - val_loss: 0.2391 - val_accuracy: 0.9060\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2497 - accuracy: 0.8991 - val_loss: 0.2354 - val_accuracy: 0.9080\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2402 - accuracy: 0.9009 - val_loss: 0.2145 - val_accuracy: 0.9120\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2195 - accuracy: 0.9082 - val_loss: 0.2215 - val_accuracy: 0.9120\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2130 - accuracy: 0.9136 - val_loss: 0.2618 - val_accuracy: 0.9100\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2140 - accuracy: 0.9147 - val_loss: 0.1945 - val_accuracy: 0.9380\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1874 - accuracy: 0.9247 - val_loss: 0.1972 - val_accuracy: 0.9260\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1667 - accuracy: 0.9360 - val_loss: 0.3610 - val_accuracy: 0.8140\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1789 - accuracy: 0.9278 - val_loss: 0.1944 - val_accuracy: 0.9160\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1382 - accuracy: 0.9467 - val_loss: 0.1763 - val_accuracy: 0.9400\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1257 - accuracy: 0.9482 - val_loss: 0.1825 - val_accuracy: 0.9180\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1080 - accuracy: 0.9587 - val_loss: 0.1897 - val_accuracy: 0.9300\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0997 - accuracy: 0.9596 - val_loss: 0.1864 - val_accuracy: 0.9400\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0654 - accuracy: 0.9767 - val_loss: 0.2467 - val_accuracy: 0.9380\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0654 - accuracy: 0.9744 - val_loss: 0.2141 - val_accuracy: 0.9240\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0511 - accuracy: 0.9816 - val_loss: 0.2618 - val_accuracy: 0.9340\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0537 - accuracy: 0.9798 - val_loss: 0.2214 - val_accuracy: 0.9440\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0309 - accuracy: 0.9891 - val_loss: 0.2588 - val_accuracy: 0.9400\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0196 - accuracy: 0.9949 - val_loss: 0.2985 - val_accuracy: 0.9360\n",
      "Test loss: 0.3956240117549896\n",
      "Test accuracy: 0.9340000152587891\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.7525\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3354 - accuracy: 0.8876 - val_loss: 0.2680 - val_accuracy: 0.9060\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2673 - accuracy: 0.8993 - val_loss: 0.2461 - val_accuracy: 0.9060\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2609 - accuracy: 0.8993 - val_loss: 0.2583 - val_accuracy: 0.9060\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2464 - accuracy: 0.8993 - val_loss: 0.2336 - val_accuracy: 0.9080\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2359 - accuracy: 0.9016 - val_loss: 0.2153 - val_accuracy: 0.9100\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2225 - accuracy: 0.9067 - val_loss: 0.1971 - val_accuracy: 0.9160\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2089 - accuracy: 0.9169 - val_loss: 0.2321 - val_accuracy: 0.9240\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1958 - accuracy: 0.9244 - val_loss: 0.1969 - val_accuracy: 0.9240\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1719 - accuracy: 0.9313 - val_loss: 0.2206 - val_accuracy: 0.8900\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1755 - accuracy: 0.9318 - val_loss: 0.2462 - val_accuracy: 0.8860\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1663 - accuracy: 0.9364 - val_loss: 0.1879 - val_accuracy: 0.9240\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1405 - accuracy: 0.9422 - val_loss: 0.2864 - val_accuracy: 0.8620\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1495 - accuracy: 0.9427 - val_loss: 0.1731 - val_accuracy: 0.9400\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1108 - accuracy: 0.9560 - val_loss: 0.2033 - val_accuracy: 0.9300\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1083 - accuracy: 0.9580 - val_loss: 0.2176 - val_accuracy: 0.9360\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0876 - accuracy: 0.9647 - val_loss: 0.2634 - val_accuracy: 0.9380\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0740 - accuracy: 0.9736 - val_loss: 0.2647 - val_accuracy: 0.9440\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0563 - accuracy: 0.9769 - val_loss: 0.2363 - val_accuracy: 0.9380\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0452 - accuracy: 0.9822 - val_loss: 0.3343 - val_accuracy: 0.9080\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0417 - accuracy: 0.9840 - val_loss: 0.2751 - val_accuracy: 0.9300\n",
      "Test loss: 0.2706514000892639\n",
      "Test accuracy: 0.9319999814033508\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.4685\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3141 - accuracy: 0.8882 - val_loss: 0.2806 - val_accuracy: 0.9060\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2889 - accuracy: 0.8993 - val_loss: 0.2510 - val_accuracy: 0.9060\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2589 - accuracy: 0.8993 - val_loss: 0.2308 - val_accuracy: 0.9060\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2442 - accuracy: 0.9002 - val_loss: 0.2331 - val_accuracy: 0.9060\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2318 - accuracy: 0.9022 - val_loss: 0.2283 - val_accuracy: 0.9260\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2115 - accuracy: 0.9136 - val_loss: 0.2107 - val_accuracy: 0.9260\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1979 - accuracy: 0.9184 - val_loss: 0.2568 - val_accuracy: 0.8620\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1940 - accuracy: 0.9227 - val_loss: 0.2394 - val_accuracy: 0.9200\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1834 - accuracy: 0.9253 - val_loss: 0.1765 - val_accuracy: 0.9340\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2049 - accuracy: 0.9209 - val_loss: 0.1746 - val_accuracy: 0.9380\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1595 - accuracy: 0.9384 - val_loss: 0.1776 - val_accuracy: 0.9400\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1325 - accuracy: 0.9487 - val_loss: 0.1706 - val_accuracy: 0.9300\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1161 - accuracy: 0.9544 - val_loss: 0.1879 - val_accuracy: 0.9400\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1080 - accuracy: 0.9556 - val_loss: 0.1887 - val_accuracy: 0.9260\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0884 - accuracy: 0.9656 - val_loss: 0.2018 - val_accuracy: 0.9420\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0685 - accuracy: 0.9751 - val_loss: 0.2108 - val_accuracy: 0.9120\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0588 - accuracy: 0.9751 - val_loss: 0.3779 - val_accuracy: 0.8600\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0623 - accuracy: 0.9773 - val_loss: 0.2410 - val_accuracy: 0.9280\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0967 - accuracy: 0.9673 - val_loss: 0.2245 - val_accuracy: 0.9360\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0373 - accuracy: 0.9867 - val_loss: 0.2374 - val_accuracy: 0.9360\n",
      "Test loss: 0.2912013828754425\n",
      "Test accuracy: 0.9359999895095825\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.495\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3171 - accuracy: 0.8884 - val_loss: 0.2925 - val_accuracy: 0.9060\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2799 - accuracy: 0.8993 - val_loss: 0.2883 - val_accuracy: 0.9060\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2757 - accuracy: 0.8993 - val_loss: 0.2553 - val_accuracy: 0.9060\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2491 - accuracy: 0.9002 - val_loss: 0.2242 - val_accuracy: 0.9080\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2573 - accuracy: 0.9011 - val_loss: 0.2438 - val_accuracy: 0.9060\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2267 - accuracy: 0.9044 - val_loss: 0.2571 - val_accuracy: 0.9160\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2393 - accuracy: 0.9084 - val_loss: 0.2314 - val_accuracy: 0.9180\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2109 - accuracy: 0.9173 - val_loss: 0.2183 - val_accuracy: 0.9100\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1947 - accuracy: 0.9207 - val_loss: 0.2517 - val_accuracy: 0.8960\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1850 - accuracy: 0.9284 - val_loss: 0.2103 - val_accuracy: 0.9300\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1632 - accuracy: 0.9351 - val_loss: 0.2151 - val_accuracy: 0.9180\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1372 - accuracy: 0.9473 - val_loss: 0.2089 - val_accuracy: 0.9200\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1188 - accuracy: 0.9542 - val_loss: 0.2153 - val_accuracy: 0.9200\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1074 - accuracy: 0.9544 - val_loss: 0.2973 - val_accuracy: 0.9220\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0852 - accuracy: 0.9653 - val_loss: 0.2559 - val_accuracy: 0.9240\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0666 - accuracy: 0.9729 - val_loss: 0.2641 - val_accuracy: 0.9120\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0466 - accuracy: 0.9820 - val_loss: 0.3575 - val_accuracy: 0.9260\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0392 - accuracy: 0.9851 - val_loss: 0.5813 - val_accuracy: 0.9240\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0508 - accuracy: 0.9804 - val_loss: 0.3578 - val_accuracy: 0.9080\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0246 - accuracy: 0.9893 - val_loss: 0.4279 - val_accuracy: 0.9160\n",
      "Test loss: 0.37664613127708435\n",
      "Test accuracy: 0.9359999895095825\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.417\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3224 - accuracy: 0.8931 - val_loss: 0.2711 - val_accuracy: 0.9060\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2775 - accuracy: 0.8993 - val_loss: 0.2502 - val_accuracy: 0.9060\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2696 - accuracy: 0.8989 - val_loss: 0.2703 - val_accuracy: 0.9060\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2464 - accuracy: 0.8991 - val_loss: 0.2305 - val_accuracy: 0.9060\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2345 - accuracy: 0.9022 - val_loss: 0.2134 - val_accuracy: 0.9100\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2157 - accuracy: 0.9109 - val_loss: 0.2141 - val_accuracy: 0.9160\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2512 - accuracy: 0.9033 - val_loss: 0.2310 - val_accuracy: 0.9180\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2268 - accuracy: 0.9102 - val_loss: 0.2052 - val_accuracy: 0.9280\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2111 - accuracy: 0.9202 - val_loss: 0.2051 - val_accuracy: 0.9220\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1949 - accuracy: 0.9204 - val_loss: 0.2041 - val_accuracy: 0.9220\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1793 - accuracy: 0.9284 - val_loss: 0.2679 - val_accuracy: 0.9140\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1562 - accuracy: 0.9360 - val_loss: 0.2029 - val_accuracy: 0.9360\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1356 - accuracy: 0.9436 - val_loss: 0.2041 - val_accuracy: 0.9440\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1255 - accuracy: 0.9524 - val_loss: 0.2171 - val_accuracy: 0.9320\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1107 - accuracy: 0.9564 - val_loss: 0.2594 - val_accuracy: 0.9260\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0977 - accuracy: 0.9598 - val_loss: 0.2011 - val_accuracy: 0.9340\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0811 - accuracy: 0.9662 - val_loss: 0.2184 - val_accuracy: 0.9320\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0754 - accuracy: 0.9693 - val_loss: 0.2042 - val_accuracy: 0.9360\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0499 - accuracy: 0.9820 - val_loss: 0.2585 - val_accuracy: 0.9300\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0549 - accuracy: 0.9784 - val_loss: 0.2333 - val_accuracy: 0.9220\n",
      "Test loss: 0.3308927118778229\n",
      "Test accuracy: 0.9279999732971191\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.63\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3291 - accuracy: 0.8980 - val_loss: 0.2725 - val_accuracy: 0.9060\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2800 - accuracy: 0.8993 - val_loss: 0.2578 - val_accuracy: 0.9060\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2614 - accuracy: 0.8993 - val_loss: 0.2577 - val_accuracy: 0.9060\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2583 - accuracy: 0.8996 - val_loss: 0.2399 - val_accuracy: 0.9060\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2461 - accuracy: 0.8987 - val_loss: 0.2370 - val_accuracy: 0.9100\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2353 - accuracy: 0.9018 - val_loss: 0.2486 - val_accuracy: 0.9000\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2212 - accuracy: 0.9051 - val_loss: 0.2170 - val_accuracy: 0.9280\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2088 - accuracy: 0.9176 - val_loss: 0.2076 - val_accuracy: 0.9240\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1873 - accuracy: 0.9262 - val_loss: 0.1792 - val_accuracy: 0.9400\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1781 - accuracy: 0.9278 - val_loss: 0.1972 - val_accuracy: 0.9160\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2028 - accuracy: 0.9164 - val_loss: 0.2209 - val_accuracy: 0.9260\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1520 - accuracy: 0.9420 - val_loss: 0.1860 - val_accuracy: 0.9380\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1383 - accuracy: 0.9456 - val_loss: 0.2120 - val_accuracy: 0.9240\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1288 - accuracy: 0.9487 - val_loss: 0.1737 - val_accuracy: 0.9440\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1235 - accuracy: 0.9522 - val_loss: 0.2177 - val_accuracy: 0.9400\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0888 - accuracy: 0.9620 - val_loss: 0.2130 - val_accuracy: 0.9400\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0767 - accuracy: 0.9698 - val_loss: 0.2168 - val_accuracy: 0.9420\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0681 - accuracy: 0.9744 - val_loss: 0.2503 - val_accuracy: 0.9460\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0489 - accuracy: 0.9816 - val_loss: 0.2465 - val_accuracy: 0.9460\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0371 - accuracy: 0.9864 - val_loss: 0.2693 - val_accuracy: 0.9480\n",
      "Test loss: 0.26651135087013245\n",
      "Test accuracy: 0.9380000233650208\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.5695\n",
      "      通し番号  カウント\n",
      "0        0     8\n",
      "1        1    10\n",
      "2        2     3\n",
      "3        3     7\n",
      "4        4    10\n",
      "...    ...   ...\n",
      "1995  1995    10\n",
      "1996  1996    10\n",
      "1997  1997    10\n",
      "1998  1998     1\n",
      "1999  1999     8\n",
      "\n",
      "[2000 rows x 2 columns]\n",
      "[0.594, 0.6225, 0.857, 0.817, 0.7525, 0.4685, 0.495, 0.417, 0.63, 0.5695]\n",
      "11\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[967, 1246, 960, 790, 1944, 1936, 1118, 1935, 1923, 307, 529, 995, 213, 1916, 217, 1473, 523, 1239, 1662, 695, 1472, 973, 1244, 524, 478, 1644, 1437, 1439, 1978, 265, 16, 1982, 901, 267, 1986, 489, 14, 387, 498, 279, 752, 1600, 284, 285, 18, 500, 798, 1621, 1421, 704, 1466, 303, 828, 518, 34, 1572, 710, 1002, 712, 715, 1460, 377, 1626, 1312, 1302, 210, 1894, 208, 1065, 628, 1825, 1089, 1751, 1368, 1398, 1366, 451, 166, 455, 835, 1074, 354, 171, 639, 459, 640, 641, 317, 1094, 1161, 1095, 1518, 609, 1117, 1784, 839, 138, 1390, 1511, 136, 599, 1760, 1508, 1133, 793, 859, 580, 1393, 126, 887, 1541, 1851, 1560, 1853, 1207, 1887, 1208, 1558, 671, 365, 1691, 1216, 535, 1221, 1681, 1012, 1476, 1009, 65, 1008, 1007, 1225, 1005, 1696, 1206, 1330, 655, 176, 647, 1444, 1545, 651, 182, 1717, 1196, 656, 1881, 1871, 1709, 1707, 544, 1040, 543, 1331, 664, 1594, 1502, 718, 1998, 1449, 610, 121, 396, 287, 1097, 723, 1799, 1431, 615, 135, 746, 1105, 788, 346, 619, 814, 1400, 670, 1038, 82, 821, 54, 56, 689, 1026, 994, 1834, 1482, 685, 811, 410, 765, 1477, 70, 1039, 1873, 1928, 1052, 637, 1496, 1463, 374, 106, 676, 959, 972, 46, 99, 1933, 1058, 1055, 93, 894, 1797, 820, 468, 1651, 1689, 1614, 571, 771, 1338, 567, 556, 1549, 1527, 1618, 1584, 165, 1563, 1759, 222, 259, 1740, 564, 242, 512, 542, 1181, 252, 561, 848, 1262, 1787, 1159, 1562, 1231, 1190, 492, 1569, 1601, 183, 438, 148, 150, 796, 1382, 601, 312, 189, 586, 1299, 1686, 1321, 579, 1278, 1665, 1667, 154, 525, 1212, 1033, 889, 1184, 1017, 1224, 1063, 101, 1859, 360, 1489, 1488, 1885, 1884, 1195, 1867, 559, 470, 1047, 1555, 417, 1353, 642, 1522, 1155, 836, 1526, 1391, 1810, 1140, 592, 883, 1521, 1807, 1777, 441, 614, 1791, 431, 430, 1178, 1746, 1848, 460, 1015, 457, 636, 1402, 565, 841, 1086, 118, 777, 568, 882, 1821, 1682, 435, 1680, 1943, 979, 947, 1327, 499, 733, 1977, 1616, 486, 728, 1248, 1939, 1568, 1646, 1984, 1645, 403, 505, 402, 241, 797, 1635, 248, 854, 1967, 1423, 1958, 1243, 305, 1441, 1290, 409, 1288, 682, 757, 212, 694, 753, 10, 691, 1991, 950, 1922, 1414, 1663, 1666, 51, 1292, 1714, 275, 260, 1612, 1279, 1723, 178, 268, 1726, 1617, 1731, 1647, 188, 1703, 1648, 1649, 515, 1650, 221, 1658, 514, 1736, 1659, 1258, 215, 530, 1687, 1259, 772, 1698, 1205, 1265, 844, 1702, 392, 167, 1950, 1889, 74, 73, 71, 890, 1908, 984, 1924, 45, 40, 1949, 952, 1744, 826, 825, 945, 1970, 1971, 1973, 729, 732, 738, 912, 2, 1028, 659, 657, 808, 1745, 566, 1750, 588, 495, 151, 607, 142, 1790, 611, 1112, 1110, 1109, 1108, 1814, 1818, 625, 1088, 1832, 1077, 1075, 112, 1852, 1779, 1186, 1479, 1339, 361, 1487, 1433, 1336, 1337, 298, 1427, 476, 1408, 1495, 1317, 1415, 794, 1404, 461, 1405, 1550, 1503, 1328, 344, 1440, 437, 393, 309, 1298, 389, 1514, 385, 355, 379, 1505, 384, 1467, 1480, 865, 362, 1742, 1529, 1831, 1725, 1738, 1739, 1748, 160, 1756, 1766, 840, 1775, 1809, 125, 1819, 1833, 185, 1838, 1865, 806, 1868, 76, 68, 1909, 1915, 1948, 1972, 17, 1989, 179, 186, 318, 1592, 858, 1543, 1548, 856, 311, 1556, 1565, 299, 1579, 1580, 853, 289, 288, 193, 1609, 254, 1632, 1637, 240, 237, 225, 846, 1683, 199, 194, 1697, 1446, 1450, 497, 413, 545, 1332, 621, 1100, 626, 538, 424, 1084, 631, 1227, 1071, 1069, 1054, 1053, 415, 546, 1119, 548, 445, 1174, 1171, 1359, 1177, 449, 448, 581, 1188, 585, 1375, 587, 768, 442, 605, 1019, 1059, 562, 981, 1310, 954, 1304, 1250, 876, 716, 897, 875, 958, 775, 1416, 964, 1426, 1316, 776, 744, 1257, 906, 911, 1282, 1320, 739, 328, 1373, 1374, 1519, 1506, 453, 870, 1319, 301, 475, 480, 482, 471, 1582, 1303, 343, 249, 349, 433, 1274, 487, 488, 491, 852, 1291, 1499, 1546, 1347, 272, 1350, 319, 1263, 1465, 513, 832, 892, 1910, 1016, 75, 1021, 1888, 1024, 668, 1030, 84, 661, 1878, 1044, 137, 654, 648, 1064, 1849, 110, 375, 1830, 122, 124, 400, 1808, 1106, 764, 1926, 1927, 696, 823, 9, 759, 748, 1987, 920, 736, 735, 1974, 1438, 1968, 940, 1966, 717, 1962, 1954, 705, 383, 38, 963, 970, 971, 48, 1931, 976, 1251, 1805, 1793, 540, 141, 555, 1722, 552, 1720, 549, 1198, 1202, 1700, 363, 1694, 198, 1732, 537, 202, 531, 1220, 1222, 207, 773, 1238, 1664, 1661, 232, 770, 370, 440, 1462, 886, 1126, 152, 1772, 1136, 335, 1176, 1143, 606, 1149, 1150, 146, 1154, 1762, 1761, 1420, 1163, 572, 391, 408, 598, 155, 1763, 862, 1764, 1137, 350, 1765, 1315, 1139, 156, 1313, 785, 519, 769, 582, 1401, 1146, 1311, 1704, 578, 502, 1500, 180, 1678, 1620, 1189, 1716, 1218, 551, 508, 200, 1286, 1215, 264, 1711, 1706, 1399, 1229, 426, 236, 795, 1758, 1160, 1162, 1755, 1624, 161, 1268, 292, 1729, 172, 526, 1235, 527, 842, 174, 1670, 368, 634, 1013, 1964, 1349, 997, 686, 861, 896, 1004, 1906, 62, 1010, 69, 1778, 1346, 1893, 1890, 1027, 78, 1516, 1969, 1877, 1041, 1043, 87, 1528, 1914, 993, 27, 57, 707, 1363, 1361, 1947, 760, 41, 965, 968, 701, 1358, 949, 454, 1535, 23, 320, 697, 978, 327, 1352, 985, 986, 989, 991, 89, 1050, 933, 932, 123, 914, 1376, 1820, 1461, 1817, 127, 1378, 622, 131, 751, 620, 472, 1324, 333, 616, 1566, 804, 1802, 612, 822, 1783, 1574, 1091, 347, 916, 1845, 378, 395, 92, 98, 1387, 443, 734, 1855, 1062, 857, 1846, 1985, 113, 1076, 117, 1080, 745, 1524, 1087, 1827, 31, 900, 1287, 667, 767, 341, 1879, 662, 1544, 1037, 315, 1876, 1385, 1474, 466, 1045, 88, 1432, 467, 874, 1734, 1340, 1455, 97, 604, 60, 1200, 1435, 61, 281, 64, 831, 187, 1434, 1194, 669, 673, 1899, 1475, 72, 1345, 1344, 1343, 1023, 1539, 95, 650, 496, 1774, 1581, 1147, 1098, 399, 1307, 158, 1309, 805, 348, 304, 100, 1798, 1796, 1577, 1789, 871, 1120, 147, 600, 1776, 1093, 1151, 119, 1583, 405, 164, 1854, 102, 1753, 105, 373, 1588, 109, 1072, 1073, 1587, 1457, 1837, 1836, 297, 630, 629, 308, 1913, 1124, 1668, 1269, 21, 919, 1959, 1233, 1232, 774, 706, 326, 747, 452, 521, 1942, 246, 800, 962, 239, 921, 1675, 329, 928, 1979, 258, 15, 730, 511, 358, 934, 935, 444, 420, 1983, 1241, 1367, 1240, 321, 1254, 1930, 966, 50, 1214, 458, 52, 754, 1611, 692, 988, 904, 1610, 1918, 903, 197, 3, 1280, 1606, 364, 1260, 1372, 700, 1377, 792, 1633, 1223, 1619, 1636, 1990, 504, 1938, 206, 1925, 824, 909, 1905, 917, 910, 1901, 829, 1992, 1822, 1795, 1863, 1988, 850, 885, 888, 1866, 1963, 1869, 1870, 867, 1965, 1860, 1975, 1856, 843, 878, 1946, 895, 1847, 899, 1843, 1957, 830, 1882, 1800, 1003, 1794, 1424, 1121, 1395, 1113, 1111, 1107, 1396, 1418, 1428, 1127, 1085, 1443, 1448, 1079, 1501, 1517, 1061, 1386, 1371, 1786, 1326, 1211, 1217, 1226, 1247, 1271, 1169, 1294, 1333, 1370, 1335, 1355, 1134, 1364, 1365, 1130, 1129, 1057, 1525, 1530, 944, 969, 1672, 1676, 1684, 951, 1699, 1701, 941, 1531, 1752, 1757, 937, 1767, 931, 1770, 927, 1669, 975, 983, 1653, 1533, 1538, 1553, 1554, 1570, 1593, 1599, 1018, 1608, 1613, 1622, 1630, 1634, 990, 1652, 0, 1000, 414, 432, 517, 509, 507, 490, 485, 484, 477, 429, 539, 421, 397, 394, 372, 369, 359, 352, 528, 554, 332, 675, 721, 720, 703, 698, 687, 681, 680, 672, 560, 665, 624, 596, 595, 584, 577, 575, 336, 330, 755, 58, 133, 130, 115, 91, 90, 86, 67, 42, 140, 37, 35, 25, 20, 19, 8, 6, 134, 157, 316, 278, 314, 313, 302, 300, 294, 291, 280, 262, 159, 251, 238, 218, 211, 192, 190, 173, 750, 1999, 801, 786, 817, 813, 1029, 1025, 998, 974, 849, 1201, 1167, 557, 996, 845, 992, 802, 803, 980, 678, 1191, 1020, 1173, 1179, 1006, 834, 702, 923, 589, 1166, 1096, 644, 891, 722, 618, 762, 898, 758, 724, 725, 726, 749, 1165, 731, 918, 1083, 926, 1078, 632, 742, 635, 924, 1081, 645, 652, 608, 1123, 860, 957, 863, 1032, 576, 1158, 953, 1152, 1148, 583, 1141, 1036, 590, 713, 593, 594, 784, 783, 1128, 1048, 779, 684, 1413, 541, 390, 1551, 85, 1874, 1557, 1576, 1578, 1590, 290, 1591, 283, 277, 274, 266, 263, 1209, 257, 256, 253, 94, 1542, 1880, 1536, 1891, 1458, 371, 1483, 1484, 1498, 1892, 339, 337, 334, 1534, 1520, 1886, 1523, 331, 77, 79, 81, 83, 1631, 1861, 1638, 120, 181, 177, 175, 1733, 168, 162, 1828, 1754, 1826, 1710, 1768, 1811, 1773, 1803, 1781, 149, 1801, 143, 1712, 1705, 245, 107, 244, 1641, 1858, 103, 233, 1654, 227, 1656, 216, 1835, 1671, 108, 204, 203, 1688, 111, 195, 114, 381, 1513, 1903, 1980, 1296, 1297, 1301, 479, 1318, 1323, 474, 1325, 1329, 494, 1334, 465, 464, 463, 1342, 1351, 456, 1357, 1289, 1285, 450, 1242, 536, 5, 534, 533, 1219, 1234, 1236, 1237, 1245, 1283, 11, 1252, 516, 1255, 1264, 1267, 1270, 1277, 1362, 462, 1389, 1419, 1951, 406, 1417, 1381, 412, 1383, 436, 1945, 1410, 1941, 419, 1392, 47, 43, 427, 1921, 1940, 1955, 446, 1920, 36, 32, 447, 398, 29, 55, 1442, 818, 342, 1493, 1494, 353, 1497, 351, 1070, 1068, 1504, 1507, 1509, 345, 1510, 1512, 1067, 323, 340, 1066, 338, 643, 1515, 646, 1060, 649, 1056, 653, 1532, 1051, 325, 356, 357, 1492, 1491, 1082, 1447, 388, 386, 1451, 1452, 1453, 382, 633, 380, 1454, 1456, 376, 1459, 1464, 1468, 1469, 1470, 1471, 1478, 367, 366, 1481, 638, 1485, 1486, 1490, 324, 322, 1629, 1204, 1597, 1022, 282, 1598, 1602, 1603, 1014, 276, 1604, 674, 273, 1605, 271, 269, 1049, 1607, 1011, 677, 1615, 679, 261, 1623, 1625, 1627, 1001, 1, 255, 1628, 1596, 286, 1595, 1031, 1537, 1046, 1540, 658, 1547, 1042, 1552, 660, 310, 1035, 1559, 1561, 306, 1564, 1567, 663, 1571, 1573, 1575, 1034, 1585, 296, 295, 1586, 293, 1589, 666, 1445, 1090, 1436, 1295, 503, 1275, 501, 1276, 1172, 1281, 1170, 1284, 1168, 493, 569, 1293, 570, 1300, 1430, 573, 1305, 483, 1306, 481, 1308, 574, 1314, 1164, 1322, 473, 1157, 1156, 1273, 1272, 506, 563, 1210, 1213, 1199, 1197, 547, 1193, 532, 1192, 550, 1228, 1230, 1187, 553, 1185, 1183, 522, 1182, 520, 1249, 1253, 558, 1180, 1256, 1261, 1266, 510, 1175, 1153, 469, 1145, 617, 1397, 423, 422, 1403, 1406, 418, 1407, 416, 1409, 1104, 1411, 1103, 411, 1412, 819, 1102, 407, 1101, 623, 404, 1099, 1422, 401, 1425, 1092, 627, 1429, 425, 613, 1144, 428, 1142, 1341, 1138, 1348, 1354, 591, 1356, 1135, 1360, 1132, 597, 1131, 1369, 602, 603, 1379, 1380, 1125, 439, 1384, 1122, 434, 1388, 1116, 1115, 1394, 1114, 683, 270, 1824, 104, 1850, 1857, 763, 893, 96, 1862, 766, 884, 1864, 881, 880, 879, 1872, 877, 1875, 873, 872, 869, 778, 80, 780, 1883, 781, 782, 1895, 1896, 1897, 761, 1844, 1900, 756, 740, 741, 743, 1804, 1806, 132, 922, 1812, 129, 128, 1813, 1815, 1816, 1823, 250, 915, 913, 1829, 908, 116, 1839, 907, 1840, 1841, 905, 1842, 902, 1898, 868, 1792, 838, 837, 28, 1956, 26, 24, 1960, 22, 1961, 807, 833, 809, 1976, 810, 1981, 812, 13, 12, 827, 815, 1993, 1994, 7, 1995, 816, 4, 1996, 1997, 30, 33, 1902, 1953, 66, 787, 1904, 63, 866, 1907, 1911, 59, 1912, 1917, 1919, 789, 864, 53, 791, 1929, 49, 1932, 1934, 1937, 44, 855, 851, 847, 39, 799, 1952, 139, 1203, 231, 946, 711, 1695, 948, 1655, 226, 977, 191, 228, 714, 1708, 943, 719, 1713, 229, 1715, 184, 230, 1718, 1719, 942, 1721, 1724, 224, 196, 1788, 1693, 214, 1673, 1674, 956, 1660, 209, 1677, 1679, 219, 220, 955, 205, 708, 1685, 1657, 699, 201, 709, 1690, 223, 1692, 1727, 961, 690, 163, 1643, 1642, 727, 936, 247, 1640, 144, 1769, 930, 1771, 1639, 153, 243, 929, 145, 1780, 737, 1785, 688, 925, 1782, 1749, 1747, 1728, 982, 939, 1730, 234, 235, 693, 1735, 1737, 170, 987, 169, 938, 999, 1741, 1743]\n",
      "500\n",
      "500\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3440 - accuracy: 0.8784 - val_loss: 0.3252 - val_accuracy: 0.8960\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2903 - accuracy: 0.9000 - val_loss: 0.2927 - val_accuracy: 0.8960\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2742 - accuracy: 0.9018 - val_loss: 0.2775 - val_accuracy: 0.8960\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2563 - accuracy: 0.9031 - val_loss: 0.2737 - val_accuracy: 0.9120\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2563 - accuracy: 0.9053 - val_loss: 0.2719 - val_accuracy: 0.9040\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2289 - accuracy: 0.9124 - val_loss: 0.2597 - val_accuracy: 0.9140\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2411 - accuracy: 0.9111 - val_loss: 0.2539 - val_accuracy: 0.9160\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2090 - accuracy: 0.9227 - val_loss: 0.3896 - val_accuracy: 0.9060\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2098 - accuracy: 0.9253 - val_loss: 0.2335 - val_accuracy: 0.9180\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1933 - accuracy: 0.9324 - val_loss: 0.2411 - val_accuracy: 0.9120\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1679 - accuracy: 0.9396 - val_loss: 0.2122 - val_accuracy: 0.9140\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1504 - accuracy: 0.9444 - val_loss: 0.2462 - val_accuracy: 0.9180\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1319 - accuracy: 0.9491 - val_loss: 0.2660 - val_accuracy: 0.9240\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1070 - accuracy: 0.9593 - val_loss: 0.2385 - val_accuracy: 0.9280\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1141 - accuracy: 0.9542 - val_loss: 0.2747 - val_accuracy: 0.9240\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0875 - accuracy: 0.9687 - val_loss: 0.2460 - val_accuracy: 0.9300\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0659 - accuracy: 0.9767 - val_loss: 0.2671 - val_accuracy: 0.9220\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0413 - accuracy: 0.9853 - val_loss: 0.2936 - val_accuracy: 0.9420\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0776 - accuracy: 0.9722 - val_loss: 0.2627 - val_accuracy: 0.9220\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0574 - accuracy: 0.9769 - val_loss: 0.2849 - val_accuracy: 0.9320\n",
      "Test loss: 0.30367064476013184\n",
      "Test accuracy: 0.9340000152587891\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.663\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3502 - accuracy: 0.8927 - val_loss: 0.3524 - val_accuracy: 0.8960\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2997 - accuracy: 0.9020 - val_loss: 0.3081 - val_accuracy: 0.8960\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2722 - accuracy: 0.9042 - val_loss: 0.3269 - val_accuracy: 0.8960\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2631 - accuracy: 0.9020 - val_loss: 0.2711 - val_accuracy: 0.9080\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2376 - accuracy: 0.9122 - val_loss: 0.2494 - val_accuracy: 0.9200\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2255 - accuracy: 0.9164 - val_loss: 0.2580 - val_accuracy: 0.9120\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2034 - accuracy: 0.9271 - val_loss: 0.2415 - val_accuracy: 0.9280\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1780 - accuracy: 0.9344 - val_loss: 0.2446 - val_accuracy: 0.9220\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1636 - accuracy: 0.9373 - val_loss: 0.2258 - val_accuracy: 0.9200\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1359 - accuracy: 0.9493 - val_loss: 0.2816 - val_accuracy: 0.8800\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1259 - accuracy: 0.9533 - val_loss: 0.2031 - val_accuracy: 0.9360\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0890 - accuracy: 0.9676 - val_loss: 0.2848 - val_accuracy: 0.9420\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0700 - accuracy: 0.9733 - val_loss: 0.1638 - val_accuracy: 0.9500\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0542 - accuracy: 0.9778 - val_loss: 0.2270 - val_accuracy: 0.9360\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0393 - accuracy: 0.9853 - val_loss: 0.2664 - val_accuracy: 0.9220\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0459 - accuracy: 0.9836 - val_loss: 0.2772 - val_accuracy: 0.9020\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0320 - accuracy: 0.9880 - val_loss: 0.2901 - val_accuracy: 0.9060\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0296 - accuracy: 0.9882 - val_loss: 0.3002 - val_accuracy: 0.9420\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0157 - accuracy: 0.9944 - val_loss: 0.2571 - val_accuracy: 0.9520\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0131 - accuracy: 0.9956 - val_loss: 0.2846 - val_accuracy: 0.9420\n",
      "Test loss: 0.32367247343063354\n",
      "Test accuracy: 0.9330000281333923\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.7545\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3304 - accuracy: 0.8776 - val_loss: 0.2999 - val_accuracy: 0.9020\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2828 - accuracy: 0.9011 - val_loss: 0.2922 - val_accuracy: 0.8960\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2697 - accuracy: 0.9042 - val_loss: 0.2823 - val_accuracy: 0.9020\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2602 - accuracy: 0.9064 - val_loss: 0.2703 - val_accuracy: 0.9040\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2471 - accuracy: 0.9067 - val_loss: 0.2644 - val_accuracy: 0.9080\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2307 - accuracy: 0.9160 - val_loss: 0.2381 - val_accuracy: 0.9260\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2093 - accuracy: 0.9196 - val_loss: 0.2401 - val_accuracy: 0.9120\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1826 - accuracy: 0.9311 - val_loss: 0.2024 - val_accuracy: 0.9240\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1598 - accuracy: 0.9422 - val_loss: 0.2109 - val_accuracy: 0.9220\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1442 - accuracy: 0.9476 - val_loss: 0.1938 - val_accuracy: 0.9240\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1161 - accuracy: 0.9558 - val_loss: 0.2527 - val_accuracy: 0.9300\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1030 - accuracy: 0.9624 - val_loss: 0.1787 - val_accuracy: 0.9300\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0869 - accuracy: 0.9680 - val_loss: 0.2003 - val_accuracy: 0.9480\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0559 - accuracy: 0.9787 - val_loss: 0.2363 - val_accuracy: 0.9280\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0340 - accuracy: 0.9867 - val_loss: 0.2728 - val_accuracy: 0.9240\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0262 - accuracy: 0.9916 - val_loss: 0.2863 - val_accuracy: 0.9340\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0210 - accuracy: 0.9924 - val_loss: 0.3431 - val_accuracy: 0.9380\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0344 - accuracy: 0.9869 - val_loss: 0.3580 - val_accuracy: 0.9320\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0206 - accuracy: 0.9931 - val_loss: 0.3252 - val_accuracy: 0.9380\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0076 - accuracy: 0.9989 - val_loss: 0.3825 - val_accuracy: 0.9480\n",
      "Test loss: 0.4185940623283386\n",
      "Test accuracy: 0.9369999766349792\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.6145\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3366 - accuracy: 0.8860 - val_loss: 0.3074 - val_accuracy: 0.8960\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2798 - accuracy: 0.9004 - val_loss: 0.2944 - val_accuracy: 0.8980\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2655 - accuracy: 0.9069 - val_loss: 0.2724 - val_accuracy: 0.9000\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2583 - accuracy: 0.9082 - val_loss: 0.2617 - val_accuracy: 0.9120\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2295 - accuracy: 0.9153 - val_loss: 0.2157 - val_accuracy: 0.9200\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2143 - accuracy: 0.9247 - val_loss: 0.2280 - val_accuracy: 0.9160\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1953 - accuracy: 0.9280 - val_loss: 0.2179 - val_accuracy: 0.9200\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1674 - accuracy: 0.9369 - val_loss: 0.2052 - val_accuracy: 0.9160\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1552 - accuracy: 0.9418 - val_loss: 0.2100 - val_accuracy: 0.9280\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1422 - accuracy: 0.9456 - val_loss: 0.2588 - val_accuracy: 0.9180\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1282 - accuracy: 0.9498 - val_loss: 0.1872 - val_accuracy: 0.9320\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1064 - accuracy: 0.9587 - val_loss: 0.2280 - val_accuracy: 0.9120\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0860 - accuracy: 0.9667 - val_loss: 0.2984 - val_accuracy: 0.9200\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0712 - accuracy: 0.9718 - val_loss: 0.2500 - val_accuracy: 0.9200\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0452 - accuracy: 0.9853 - val_loss: 0.3016 - val_accuracy: 0.9300\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0450 - accuracy: 0.9836 - val_loss: 0.3172 - val_accuracy: 0.9320\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0323 - accuracy: 0.9880 - val_loss: 0.3065 - val_accuracy: 0.9220\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0470 - accuracy: 0.9800 - val_loss: 0.3455 - val_accuracy: 0.9300\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0167 - accuracy: 0.9951 - val_loss: 0.3848 - val_accuracy: 0.9260\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0121 - accuracy: 0.9962 - val_loss: 0.5200 - val_accuracy: 0.9280\n",
      "Test loss: 0.4990442395210266\n",
      "Test accuracy: 0.9359999895095825\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.674\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3694 - accuracy: 0.8769 - val_loss: 0.4275 - val_accuracy: 0.8960\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.3251 - accuracy: 0.9004 - val_loss: 0.3050 - val_accuracy: 0.8980\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2793 - accuracy: 0.9016 - val_loss: 0.2841 - val_accuracy: 0.8960\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2629 - accuracy: 0.9047 - val_loss: 0.2719 - val_accuracy: 0.9040\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2484 - accuracy: 0.9111 - val_loss: 0.2743 - val_accuracy: 0.9100\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2311 - accuracy: 0.9171 - val_loss: 0.2920 - val_accuracy: 0.9120\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2061 - accuracy: 0.9244 - val_loss: 0.2097 - val_accuracy: 0.9220\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1856 - accuracy: 0.9338 - val_loss: 0.2110 - val_accuracy: 0.9300\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1848 - accuracy: 0.9320 - val_loss: 0.2055 - val_accuracy: 0.9260\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1558 - accuracy: 0.9422 - val_loss: 0.2158 - val_accuracy: 0.9240\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1387 - accuracy: 0.9467 - val_loss: 0.2024 - val_accuracy: 0.9260\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1243 - accuracy: 0.9540 - val_loss: 0.2080 - val_accuracy: 0.9360\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0994 - accuracy: 0.9627 - val_loss: 0.2290 - val_accuracy: 0.9240\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0904 - accuracy: 0.9647 - val_loss: 0.2287 - val_accuracy: 0.9320\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0750 - accuracy: 0.9738 - val_loss: 0.2397 - val_accuracy: 0.9300\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0592 - accuracy: 0.9773 - val_loss: 0.2516 - val_accuracy: 0.9320\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0700 - accuracy: 0.9762 - val_loss: 0.2845 - val_accuracy: 0.9340\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0337 - accuracy: 0.9871 - val_loss: 0.3115 - val_accuracy: 0.9340\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0246 - accuracy: 0.9911 - val_loss: 0.3470 - val_accuracy: 0.9320\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0223 - accuracy: 0.9940 - val_loss: 0.4337 - val_accuracy: 0.9300\n",
      "Test loss: 0.38680288195610046\n",
      "Test accuracy: 0.9340000152587891\n",
      "63/63 [==============================] - 0s 2ms/step\n",
      "0.5515\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3465 - accuracy: 0.8798 - val_loss: 0.3492 - val_accuracy: 0.8960\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2908 - accuracy: 0.9007 - val_loss: 0.3005 - val_accuracy: 0.8960\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2664 - accuracy: 0.9020 - val_loss: 0.2882 - val_accuracy: 0.8980\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2474 - accuracy: 0.9073 - val_loss: 0.2499 - val_accuracy: 0.9140\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2372 - accuracy: 0.9127 - val_loss: 0.2316 - val_accuracy: 0.9080\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2141 - accuracy: 0.9238 - val_loss: 0.2157 - val_accuracy: 0.9120\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2043 - accuracy: 0.9231 - val_loss: 0.2227 - val_accuracy: 0.9180\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1745 - accuracy: 0.9340 - val_loss: 0.2284 - val_accuracy: 0.9180\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1574 - accuracy: 0.9389 - val_loss: 0.1822 - val_accuracy: 0.9300\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1360 - accuracy: 0.9489 - val_loss: 0.1890 - val_accuracy: 0.9300\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1235 - accuracy: 0.9547 - val_loss: 0.1778 - val_accuracy: 0.9280\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1033 - accuracy: 0.9607 - val_loss: 0.1997 - val_accuracy: 0.9320\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0743 - accuracy: 0.9724 - val_loss: 0.1864 - val_accuracy: 0.9460\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0604 - accuracy: 0.9776 - val_loss: 0.2424 - val_accuracy: 0.9320\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0443 - accuracy: 0.9844 - val_loss: 0.3020 - val_accuracy: 0.9380\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0478 - accuracy: 0.9833 - val_loss: 0.2480 - val_accuracy: 0.9320\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0243 - accuracy: 0.9909 - val_loss: 0.2528 - val_accuracy: 0.9220\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0129 - accuracy: 0.9958 - val_loss: 0.3315 - val_accuracy: 0.9300\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0119 - accuracy: 0.9964 - val_loss: 0.3632 - val_accuracy: 0.9360\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0081 - accuracy: 0.9980 - val_loss: 0.3837 - val_accuracy: 0.9280\n",
      "Test loss: 0.4355529844760895\n",
      "Test accuracy: 0.9369999766349792\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.664\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3743 - accuracy: 0.8893 - val_loss: 0.3395 - val_accuracy: 0.8960\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.3171 - accuracy: 0.9004 - val_loss: 0.3127 - val_accuracy: 0.8960\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2789 - accuracy: 0.9018 - val_loss: 0.2811 - val_accuracy: 0.8980\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2688 - accuracy: 0.9042 - val_loss: 0.2636 - val_accuracy: 0.9040\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2572 - accuracy: 0.9071 - val_loss: 0.2647 - val_accuracy: 0.9060\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2435 - accuracy: 0.9138 - val_loss: 0.2256 - val_accuracy: 0.9260\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2144 - accuracy: 0.9187 - val_loss: 0.2087 - val_accuracy: 0.9200\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1995 - accuracy: 0.9302 - val_loss: 0.2161 - val_accuracy: 0.9360\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1823 - accuracy: 0.9324 - val_loss: 0.1948 - val_accuracy: 0.9360\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1619 - accuracy: 0.9360 - val_loss: 0.2185 - val_accuracy: 0.9260\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1594 - accuracy: 0.9409 - val_loss: 0.2027 - val_accuracy: 0.9260\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1215 - accuracy: 0.9527 - val_loss: 0.2094 - val_accuracy: 0.9140\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1031 - accuracy: 0.9604 - val_loss: 0.2180 - val_accuracy: 0.9260\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0805 - accuracy: 0.9707 - val_loss: 0.2320 - val_accuracy: 0.9240\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0753 - accuracy: 0.9720 - val_loss: 0.2621 - val_accuracy: 0.9040\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0545 - accuracy: 0.9804 - val_loss: 0.3506 - val_accuracy: 0.9160\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0375 - accuracy: 0.9862 - val_loss: 0.2982 - val_accuracy: 0.9200\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0305 - accuracy: 0.9887 - val_loss: 0.3545 - val_accuracy: 0.9340\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0234 - accuracy: 0.9924 - val_loss: 0.4546 - val_accuracy: 0.9260\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0306 - accuracy: 0.9889 - val_loss: 0.2844 - val_accuracy: 0.9300\n",
      "Test loss: 0.2897351384162903\n",
      "Test accuracy: 0.9350000023841858\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.76\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3351 - accuracy: 0.8782 - val_loss: 0.3264 - val_accuracy: 0.8960\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2889 - accuracy: 0.9011 - val_loss: 0.2833 - val_accuracy: 0.9000\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2611 - accuracy: 0.9040 - val_loss: 0.3189 - val_accuracy: 0.9060\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2548 - accuracy: 0.9062 - val_loss: 0.2681 - val_accuracy: 0.9120\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2345 - accuracy: 0.9136 - val_loss: 0.3089 - val_accuracy: 0.9080\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2211 - accuracy: 0.9196 - val_loss: 0.3258 - val_accuracy: 0.9120\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2086 - accuracy: 0.9231 - val_loss: 0.2152 - val_accuracy: 0.9320\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1857 - accuracy: 0.9360 - val_loss: 0.2361 - val_accuracy: 0.9280\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1633 - accuracy: 0.9411 - val_loss: 0.1967 - val_accuracy: 0.9300\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1411 - accuracy: 0.9471 - val_loss: 0.2485 - val_accuracy: 0.9280\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1308 - accuracy: 0.9498 - val_loss: 0.2227 - val_accuracy: 0.9280\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1009 - accuracy: 0.9653 - val_loss: 0.2029 - val_accuracy: 0.9300\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0899 - accuracy: 0.9682 - val_loss: 0.2471 - val_accuracy: 0.9160\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0667 - accuracy: 0.9758 - val_loss: 0.2537 - val_accuracy: 0.9320\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0641 - accuracy: 0.9756 - val_loss: 0.2744 - val_accuracy: 0.9280\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0574 - accuracy: 0.9767 - val_loss: 0.2583 - val_accuracy: 0.9080\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0364 - accuracy: 0.9860 - val_loss: 0.2745 - val_accuracy: 0.9380\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0243 - accuracy: 0.9909 - val_loss: 0.3601 - val_accuracy: 0.9400\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0161 - accuracy: 0.9958 - val_loss: 0.3473 - val_accuracy: 0.9180\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0123 - accuracy: 0.9967 - val_loss: 0.4431 - val_accuracy: 0.9440\n",
      "Test loss: 0.445639967918396\n",
      "Test accuracy: 0.9359999895095825\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.669\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3470 - accuracy: 0.8816 - val_loss: 0.3214 - val_accuracy: 0.8960\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2831 - accuracy: 0.9009 - val_loss: 0.2856 - val_accuracy: 0.9120\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2574 - accuracy: 0.9084 - val_loss: 0.2759 - val_accuracy: 0.9000\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2482 - accuracy: 0.9098 - val_loss: 0.3253 - val_accuracy: 0.8960\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2245 - accuracy: 0.9182 - val_loss: 0.2280 - val_accuracy: 0.9200\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1987 - accuracy: 0.9262 - val_loss: 0.2845 - val_accuracy: 0.8920\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1992 - accuracy: 0.9284 - val_loss: 0.2313 - val_accuracy: 0.9180\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1807 - accuracy: 0.9313 - val_loss: 0.1966 - val_accuracy: 0.9200\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1511 - accuracy: 0.9424 - val_loss: 0.2327 - val_accuracy: 0.9100\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1458 - accuracy: 0.9429 - val_loss: 0.2006 - val_accuracy: 0.9160\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1317 - accuracy: 0.9489 - val_loss: 0.1999 - val_accuracy: 0.9240\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1005 - accuracy: 0.9613 - val_loss: 0.2190 - val_accuracy: 0.9320\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0961 - accuracy: 0.9649 - val_loss: 0.2625 - val_accuracy: 0.9020\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0861 - accuracy: 0.9678 - val_loss: 0.2512 - val_accuracy: 0.9140\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0584 - accuracy: 0.9782 - val_loss: 0.2523 - val_accuracy: 0.9220\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0474 - accuracy: 0.9813 - val_loss: 0.3198 - val_accuracy: 0.9160\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0421 - accuracy: 0.9840 - val_loss: 0.3471 - val_accuracy: 0.9280\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0253 - accuracy: 0.9909 - val_loss: 0.4265 - val_accuracy: 0.9240\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0108 - accuracy: 0.9964 - val_loss: 0.4333 - val_accuracy: 0.9300\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0102 - accuracy: 0.9973 - val_loss: 0.4148 - val_accuracy: 0.9140\n",
      "Test loss: 0.3667128086090088\n",
      "Test accuracy: 0.9399999976158142\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.7\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3471 - accuracy: 0.8867 - val_loss: 0.3369 - val_accuracy: 0.8960\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2954 - accuracy: 0.9011 - val_loss: 0.3047 - val_accuracy: 0.8960\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2774 - accuracy: 0.9020 - val_loss: 0.2820 - val_accuracy: 0.9160\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2591 - accuracy: 0.9073 - val_loss: 0.2636 - val_accuracy: 0.9060\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2360 - accuracy: 0.9120 - val_loss: 0.2454 - val_accuracy: 0.9180\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2176 - accuracy: 0.9160 - val_loss: 0.2343 - val_accuracy: 0.9140\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2067 - accuracy: 0.9253 - val_loss: 0.2182 - val_accuracy: 0.9180\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1857 - accuracy: 0.9298 - val_loss: 0.2399 - val_accuracy: 0.9020\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1753 - accuracy: 0.9362 - val_loss: 0.2292 - val_accuracy: 0.9160\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1507 - accuracy: 0.9487 - val_loss: 0.2044 - val_accuracy: 0.9360\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1284 - accuracy: 0.9544 - val_loss: 0.1781 - val_accuracy: 0.9300\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1083 - accuracy: 0.9589 - val_loss: 0.1915 - val_accuracy: 0.9360\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0915 - accuracy: 0.9696 - val_loss: 0.1915 - val_accuracy: 0.9280\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0746 - accuracy: 0.9724 - val_loss: 0.2589 - val_accuracy: 0.9360\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0563 - accuracy: 0.9816 - val_loss: 0.2646 - val_accuracy: 0.9300\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0493 - accuracy: 0.9820 - val_loss: 0.2773 - val_accuracy: 0.9340\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0308 - accuracy: 0.9916 - val_loss: 0.4266 - val_accuracy: 0.9320\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0258 - accuracy: 0.9893 - val_loss: 0.3957 - val_accuracy: 0.9320\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0132 - accuracy: 0.9960 - val_loss: 0.4739 - val_accuracy: 0.9300\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0113 - accuracy: 0.9967 - val_loss: 0.3787 - val_accuracy: 0.9180\n",
      "Test loss: 0.3898666799068451\n",
      "Test accuracy: 0.9259999990463257\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.75\n",
      "      通し番号  カウント\n",
      "0        0    10\n",
      "1        1     1\n",
      "2        2    10\n",
      "3        3     8\n",
      "4        4     1\n",
      "...    ...   ...\n",
      "1995  1995     9\n",
      "1996  1996    10\n",
      "1997  1997     5\n",
      "1998  1998     1\n",
      "1999  1999    10\n",
      "\n",
      "[2000 rows x 2 columns]\n",
      "[0.663, 0.7545, 0.6145, 0.674, 0.5515, 0.664, 0.76, 0.669, 0.7, 0.75]\n",
      "11\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[1042, 942, 1075, 1947, 945, 1575, 1345, 1067, 133, 1352, 1364, 572, 1939, 1076, 939, 1367, 1018, 1579, 472, 1080, 589, 1584, 601, 64, 74, 607, 1366, 287, 476, 1413, 1464, 1532, 294, 1761, 1438, 1437, 181, 528, 453, 187, 1528, 189, 1964, 477, 1754, 1384, 1739, 543, 1015, 1061, 1028, 1959, 206, 546, 1466, 463, 1317, 260, 925, 272, 1140, 1214, 1216, 1219, 842, 1221, 1867, 269, 1640, 1229, 467, 1742, 1237, 1632, 379, 1141, 1206, 786, 1156, 813, 264, 352, 1842, 47, 1177, 1180, 1857, 44, 256, 1828, 1182, 1153, 39, 865, 870, 19, 871, 1604, 227, 654, 1288, 1104, 224, 648, 1303, 1594, 1102, 821, 1919, 624, 280, 615, 661, 1107, 277, 1802, 27, 708, 1690, 1691, 1803, 1263, 675, 1113, 1115, 1614, 1610, 891, 230, 1606, 631, 1998, 1173, 1969, 381, 164, 1630, 243, 377, 1240, 749, 1523, 1666, 1503, 36, 238, 1207, 1204, 1654, 1202, 1506, 42, 1660, 1179, 37, 4, 1938, 448, 425, 588, 1328, 1326, 1451, 1926, 571, 129, 1836, 127, 1310, 650, 1258, 664, 399, 1605, 568, 1271, 1616, 1467, 1619, 539, 693, 1529, 25, 246, 247, 1122, 979, 291, 1128, 344, 862, 319, 324, 339, 1809, 885, 995, 1121, 948, 889, 1116, 1078, 938, 1081, 1710, 1707, 71, 1059, 1824, 1, 299, 1162, 73, 836, 1674, 1756, 1147, 827, 943, 450, 5, 785, 507, 1779, 1781, 442, 677, 388, 950, 1982, 697, 525, 974, 1765, 709, 715, 304, 309, 458, 1002, 475, 468, 787, 915, 931, 532, 831, 612, 1825, 1911, 423, 850, 1908, 1937, 866, 582, 666, 805, 760, 1804, 562, 1800, 1903, 549, 1954, 668, 41, 794, 673, 330, 23, 436, 61, 913, 828, 1745, 1757, 302, 1280, 1368, 1351, 1574, 1070, 284, 1335, 1580, 1325, 1091, 1703, 1266, 1377, 237, 1256, 1246, 1245, 1244, 1136, 1682, 1228, 1200, 1171, 1370, 1313, 1393, 1426, 1497, 1475, 1527, 1459, 77, 292, 105, 186, 289, 1048, 806, 1205, 1225, 51, 1223, 48, 1227, 810, 766, 772, 778, 801, 1203, 358, 1862, 371, 274, 1165, 263, 1088, 88, 321, 1716, 1778, 1776, 1773, 286, 953, 956, 963, 1733, 1044, 1511, 75, 325, 1106, 331, 1808, 834, 1149, 1144, 347, 848, 1127, 752, 1109, 888, 1119, 57, 1695, 334, 897, 753, 1881, 1239, 426, 541, 545, 11, 547, 1955, 556, 1343, 639, 586, 1334, 1330, 417, 609, 410, 1411, 438, 1547, 517, 1976, 175, 171, 144, 1981, 1530, 451, 1985, 1988, 165, 486, 163, 1501, 637, 1946, 29, 382, 232, 1308, 405, 231, 735, 1598, 1613, 24, 660, 228, 687, 1899, 1907, 1577, 1736, 1738, 1991, 102, 1637, 1815, 1709, 1517, 1758, 1795, 1952, 1595, 69, 1752, 1831, 1925, 1692, 1741, 1944, 1603, 1722, 55, 135, 139, 1620, 146, 1950, 1623, 134, 7, 1642, 1789, 1664, 1878, 1863, 95, 1893, 464, 152, 792, 566, 789, 234, 548, 784, 1110, 1375, 781, 202, 542, 1269, 1397, 329, 534, 394, 428, 1193, 183, 887, 822, 1292, 811, 835, 413, 229, 1318, 606, 605, 350, 846, 1331, 345, 796, 1342, 529, 1103, 393, 1069, 1247, 1427, 1473, 762, 986, 492, 726, 988, 250, 296, 1490, 462, 1011, 1017, 376, 713, 168, 1071, 1452, 1085, 1435, 1265, 1436, 323, 283, 649, 173, 1178, 311, 471, 843, 1643, 1638, 469, 1004, 530, 1444, 474, 535, 759, 538, 1546, 244, 1997, 1817, 440, 1488, 1833, 1740, 314, 1653, 166, 53, 114, 798, 1175, 1476, 38, 1858, 452, 1859, 1470, 1022, 971, 1980, 1025, 1026, 1860, 1669, 461, 1496, 1977, 313, 519, 775, 522, 1864, 1913, 1737, 585, 322, 203, 1378, 690, 1073, 208, 1369, 1566, 421, 877, 209, 1293, 924, 1929, 213, 674, 620, 671, 328, 1806, 1339, 1338, 1918, 1801, 1311, 130, 60, 1561, 736, 320, 742, 1555, 552, 239, 1105, 555, 729, 1401, 859, 1060, 374, 1137, 98, 580, 1387, 1065, 1783, 932, 201, 1185, 1562, 1921, 91, 1099, 906, 909, 1093, 1337, 408, 409, 282, 1376, 1184, 610, 577, 1357, 1362, 928, 1565, 1072, 1713, 1956, 1777, 569, 1033, 1974, 1539, 1538, 1471, 1531, 973, 1479, 1481, 496, 493, 981, 982, 987, 1012, 1010, 1993, 1515, 72, 470, 151, 177, 1035, 178, 1420, 1398, 433, 1730, 1051, 1050, 1049, 403, 1418, 1957, 1047, 437, 435, 954, 1961, 1040, 540, 180, 1434, 959, 1440, 898, 920, 307, 1685, 1680, 1273, 872, 1889, 1609, 696, 1126, 337, 1631, 685, 1124, 1169, 225, 833, 1882, 367, 380, 99, 725, 30, 1224, 730, 1672, 767, 341, 1875, 757, 743, 120, 750, 756, 1652, 689, 855, 93, 1694, 110, 359, 1807, 362, 1300, 1909, 56, 1305, 353, 1845, 1897, 1315, 658, 1190, 817, 1656, 1296, 653, 499, 1633, 1871, 497, 1251, 763, 738, 1877, 998, 1469, 1621, 1883, 1983, 143, 506, 387, 508, 705, 1869, 1487, 454, 1987, 812, 1839, 1510, 1509, 1508, 1507, 800, 1197, 1198, 363, 157, 1519, 473, 149, 481, 1211, 1215, 780, 116, 1222, 169, 1644, 1226, 233, 1895, 1278, 1927, 1551, 1425, 1552, 1423, 632, 630, 1960, 1415, 618, 1410, 1923, 1928, 182, 1930, 1407, 1932, 592, 1933, 1374, 431, 195, 204, 1949, 197, 1332, 636, 1890, 141, 449, 391, 1455, 123, 578, 1541, 682, 679, 125, 1896, 1542, 672, 1430, 1302, 222, 1905, 1906, 659, 655, 1587, 641, 10, 1327, 1916, 357, 734, 867, 1810, 847, 261, 1818, 873, 1767, 1083, 922, 265, 1053, 952, 1154, 1037, 1152, 1711, 1151, 1714, 1787, 79, 854, 955, 929, 78, 856, 1732, 936, 1686, 964, 316, 1139, 1698, 941, 994, 1003, 1704, 1101, 896, 869, 1009, 1811, 58, 907, 1095, 290, 1145, 1749, 917, 1826, 967, 968, 1771, 1827, 288, 1020, 1744, 944, 916, 305, 1241, 155, 1008, 1001, 81, 1615, 1500, 242, 1268, 1617, 1062, 1448, 1729, 1249, 1454, 1491, 1495, 1034, 303, 118, 1524, 1474, 148, 1750, 1533, 162, 1545, 249, 236, 117, 295, 1641, 1645, 1262, 1016, 1635, 1041, 1482, 1724, 1320, 1549, 1341, 1188, 1290, 1187, 1186, 1572, 1294, 1626, 1132, 1573, 1297, 1662, 132, 1142, 1340, 1212, 1336, 217, 1582, 1676, 1307, 1309, 126, 104, 1160, 1670, 1324, 1314, 107, 1356, 1358, 1359, 1361, 1431, 1428, 1721, 184, 84, 190, 86, 1409, 1208, 191, 1084, 113, 1706, 1558, 1201, 1199, 1394, 1392, 1386, 1701, 1385, 1560, 1382, 1608, 1567, 1192, 1696, 194, 1000, 990, 912, 881, 667, 662, 656, 1915, 643, 900, 1917, 904, 635, 634, 633, 815, 629, 338, 627, 619, 411, 20, 923, 416, 594, 930, 590, 1935, 1936, 584, 581, 880, 691, 427, 1819, 808, 819, 1834, 823, 45, 43, 52, 1853, 790, 788, 1823, 1822, 770, 849, 875, 851, 769, 1868, 1872, 373, 747, 863, 383, 718, 385, 1886, 868, 704, 575, 911, 1775, 533, 1972, 500, 551, 3, 485, 8, 553, 487, 456, 1951, 993, 969, 1967, 1962, 947, 1966, 13, 494, 12, 791, 825, 40, 1166, 826, 364, 1832, 252, 1855, 259, 1174, 783, 748, 258, 832, 1243, 1168, 1629, 1213, 1191, 754, 1848, 1657, 777, 1841, 776, 1218, 366, 1217, 804, 1209, 360, 816, 1647, 1661, 771, 368, 1195, 1196, 248, 782, 1236, 372, 1634, 46, 755, 795, 336, 348, 80, 957, 1039, 1052, 951, 949, 1772, 1057, 946, 1728, 1780, 1768, 1782, 1066, 933, 1723, 1074, 1788, 1082, 327, 1089, 958, 317, 1164, 1751, 1753, 1006, 310, 1760, 1013, 1762, 985, 983, 1014, 1764, 966, 978, 977, 315, 70, 1021, 972, 970, 76, 301, 1090, 914, 62, 268, 1130, 1131, 1812, 1133, 1134, 270, 1813, 1681, 340, 100, 910, 342, 267, 1816, 101, 1150, 852, 844, 1163, 1821, 97, 273, 879, 1118, 908, 1096, 1097, 1793, 1098, 1794, 899, 1700, 1108, 894, 893, 1699, 1111, 886, 276, 746, 883, 882, 275, 119, 378, 745, 614, 1570, 212, 211, 1365, 600, 599, 420, 1568, 207, 1564, 583, 1940, 1388, 16, 574, 14, 570, 1945, 1399, 613, 214, 565, 1349, 1321, 1914, 1322, 404, 1323, 642, 1586, 640, 131, 407, 1583, 1581, 1578, 1344, 626, 625, 1920, 623, 1348, 196, 1402, 652, 512, 142, 1465, 1468, 502, 501, 1477, 1984, 147, 455, 490, 161, 1521, 1989, 1494, 1992, 1498, 1994, 1995, 150, 510, 446, 561, 445, 560, 193, 554, 1556, 1554, 1963, 1544, 536, 1441, 1442, 1443, 1445, 1447, 439, 1973, 1540, 520, 1458, 1975, 21, 216, 997, 1257, 724, 1611, 1281, 390, 694, 1891, 1261, 1607, 1285, 124, 688, 1600, 728, 1260, 1894, 1618, 1267, 698, 714, 1272, 1888, 711, 712, 706, 1612, 716, 699, 1276, 1910, 703, 702, 1277, 389, 122, 727, 1599, 1755, 737, 1902, 1596, 241, 240, 1624, 1312, 733, 1299, 676, 1301, 1904, 128, 219, 680, 1589, 1248, 0, 1005, 961, 962, 965, 975, 976, 980, 984, 989, 991, 992, 996, 999, 1007, 1275, 1019, 1023, 1024, 1027, 1029, 1030, 1031, 1032, 1036, 1038, 1043, 1045, 960, 940, 937, 935, 841, 845, 853, 857, 858, 860, 861, 864, 874, 876, 878, 884, 890, 892, 895, 901, 902, 903, 905, 918, 919, 921, 926, 927, 934, 1046, 1054, 1055, 1161, 1170, 1172, 1176, 1181, 1183, 1189, 1194, 1210, 1220, 1230, 1231, 1232, 1233, 1234, 1235, 1238, 1242, 1250, 1252, 1253, 1254, 1255, 1259, 1264, 1270, 1167, 1159, 1056, 1158, 1058, 1063, 1064, 1068, 1077, 1079, 1086, 1087, 1092, 1094, 1100, 1112, 1114, 1117, 1120, 1123, 1125, 1129, 1135, 1138, 1143, 1146, 1148, 1155, 1157, 840, 839, 838, 537, 550, 557, 558, 559, 563, 564, 567, 573, 576, 579, 587, 591, 593, 595, 596, 597, 598, 602, 603, 604, 608, 611, 616, 617, 621, 544, 531, 628, 527, 478, 479, 480, 482, 483, 484, 488, 489, 491, 495, 498, 503, 504, 505, 509, 511, 513, 514, 515, 516, 518, 521, 523, 524, 526, 622, 638, 837, 732, 740, 741, 744, 751, 758, 761, 764, 765, 768, 773, 774, 779, 793, 797, 799, 802, 803, 807, 809, 814, 818, 820, 824, 829, 830, 739, 731, 644, 723, 645, 646, 647, 651, 657, 663, 665, 669, 670, 678, 681, 683, 684, 686, 692, 695, 700, 701, 707, 710, 717, 719, 720, 721, 722, 1274, 1279, 465, 1748, 1718, 1719, 1720, 1725, 1726, 1727, 1731, 1734, 1735, 1743, 1746, 1747, 1759, 1282, 1763, 1766, 1769, 1770, 1774, 1784, 1785, 1786, 1790, 1791, 1792, 1796, 1717, 1715, 1712, 1708, 1649, 1650, 1651, 1655, 1658, 1659, 1663, 1665, 1667, 1668, 1671, 1673, 1675, 1677, 1678, 1679, 1683, 1684, 1687, 1688, 1689, 1693, 1697, 1702, 1705, 1797, 1798, 1799, 1884, 1887, 1892, 1898, 1900, 1901, 1912, 1922, 1924, 1931, 1934, 1941, 1942, 1943, 1948, 1953, 1958, 1965, 1968, 1970, 1971, 1978, 1979, 1986, 1990, 1996, 1885, 1880, 1805, 1879, 1814, 1820, 1829, 1830, 1835, 1837, 1838, 1840, 1843, 1844, 1846, 1847, 1849, 1850, 1851, 1852, 1854, 1856, 1861, 1865, 1866, 1870, 1873, 1874, 1876, 1648, 1646, 1639, 1381, 1389, 1390, 1391, 1395, 1396, 1400, 1403, 1404, 1405, 1406, 1408, 1412, 1414, 1416, 1417, 1419, 1421, 1422, 1424, 1429, 1432, 1433, 1439, 1446, 1449, 1383, 1380, 1453, 1379, 1283, 1284, 1286, 1287, 1289, 1291, 1295, 1298, 1304, 1306, 1316, 1319, 1329, 1333, 1346, 1347, 1350, 1353, 1354, 1355, 1360, 1363, 1371, 1372, 1373, 1450, 1456, 1636, 1534, 1536, 1537, 1543, 1548, 1550, 1553, 1557, 1559, 1563, 1569, 1571, 1576, 1585, 1588, 1590, 1591, 1592, 1593, 1597, 1601, 1602, 1622, 1625, 1627, 1628, 1535, 1526, 1457, 1525, 1460, 1461, 1462, 1463, 1472, 1478, 1480, 1483, 1484, 1485, 1486, 1489, 1492, 1493, 1499, 1502, 1504, 1505, 1512, 1513, 1514, 1516, 1518, 1520, 1522, 466, 1999, 153, 138, 199, 253, 200, 278, 332, 90, 424, 333, 17, 205, 392, 422, 59, 226, 335, 419, 418, 15, 136, 361, 112, 188, 434, 85, 137, 87, 326, 192, 402, 198, 281, 63, 430, 429, 111, 89, 279, 254, 92, 49, 220, 221, 108, 400, 257, 343, 266, 218, 401, 397, 103, 262, 54, 346, 406, 106, 351, 398, 354, 18, 109, 415, 210, 395, 255, 414, 356, 396, 355, 215, 94, 96, 223, 412, 50, 271, 22, 83, 432, 185, 245, 370, 167, 369, 300, 35, 298, 297, 145, 251, 318, 170, 172, 447, 384, 444, 34, 121, 443, 457, 154, 308, 156, 2, 306, 158, 32, 375, 31, 33, 159, 460, 459, 160, 312, 293, 6, 349, 66, 9, 179, 26, 115, 67, 285, 82, 140, 365, 28, 176, 65, 174, 68, 235, 386, 441]\n",
      "500\n",
      "500\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3471 - accuracy: 0.8891 - val_loss: 0.2547 - val_accuracy: 0.8960\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2479 - accuracy: 0.9004 - val_loss: 0.2769 - val_accuracy: 0.8960\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2261 - accuracy: 0.9062 - val_loss: 0.1884 - val_accuracy: 0.9140\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1899 - accuracy: 0.9200 - val_loss: 0.2469 - val_accuracy: 0.9260\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1964 - accuracy: 0.9244 - val_loss: 0.1834 - val_accuracy: 0.9400\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1530 - accuracy: 0.9384 - val_loss: 0.1630 - val_accuracy: 0.9480\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1295 - accuracy: 0.9493 - val_loss: 0.1812 - val_accuracy: 0.9440\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1281 - accuracy: 0.9484 - val_loss: 0.1802 - val_accuracy: 0.9540\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1046 - accuracy: 0.9596 - val_loss: 0.1711 - val_accuracy: 0.9540\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0823 - accuracy: 0.9662 - val_loss: 0.1812 - val_accuracy: 0.9520\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0693 - accuracy: 0.9736 - val_loss: 0.2428 - val_accuracy: 0.9480\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0563 - accuracy: 0.9796 - val_loss: 0.2351 - val_accuracy: 0.9520\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0432 - accuracy: 0.9838 - val_loss: 0.3190 - val_accuracy: 0.9500\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0341 - accuracy: 0.9851 - val_loss: 0.3616 - val_accuracy: 0.9480\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0370 - accuracy: 0.9856 - val_loss: 0.2736 - val_accuracy: 0.9500\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0219 - accuracy: 0.9920 - val_loss: 0.3426 - val_accuracy: 0.9540\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0202 - accuracy: 0.9924 - val_loss: 0.2845 - val_accuracy: 0.9500\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0208 - accuracy: 0.9931 - val_loss: 0.3044 - val_accuracy: 0.9580\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0110 - accuracy: 0.9967 - val_loss: 0.3502 - val_accuracy: 0.9580\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0036 - accuracy: 0.9991 - val_loss: 0.4092 - val_accuracy: 0.9560\n",
      "Test loss: 0.4272921681404114\n",
      "Test accuracy: 0.9459999799728394\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.6435\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3579 - accuracy: 0.8971 - val_loss: 0.2631 - val_accuracy: 0.8960\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2497 - accuracy: 0.9000 - val_loss: 0.2069 - val_accuracy: 0.8960\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2186 - accuracy: 0.9047 - val_loss: 0.1877 - val_accuracy: 0.9280\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1927 - accuracy: 0.9238 - val_loss: 0.1699 - val_accuracy: 0.9400\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1714 - accuracy: 0.9287 - val_loss: 0.1866 - val_accuracy: 0.9280\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1551 - accuracy: 0.9402 - val_loss: 0.1634 - val_accuracy: 0.9380\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1395 - accuracy: 0.9442 - val_loss: 0.1632 - val_accuracy: 0.9400\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1207 - accuracy: 0.9524 - val_loss: 0.1675 - val_accuracy: 0.9360\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1297 - accuracy: 0.9522 - val_loss: 0.1558 - val_accuracy: 0.9500\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0908 - accuracy: 0.9629 - val_loss: 0.1700 - val_accuracy: 0.9300\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0897 - accuracy: 0.9647 - val_loss: 0.2979 - val_accuracy: 0.9440\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0561 - accuracy: 0.9776 - val_loss: 0.1849 - val_accuracy: 0.9420\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0395 - accuracy: 0.9847 - val_loss: 0.2267 - val_accuracy: 0.9540\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0395 - accuracy: 0.9851 - val_loss: 0.2604 - val_accuracy: 0.9500\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0214 - accuracy: 0.9920 - val_loss: 0.2741 - val_accuracy: 0.9520\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0153 - accuracy: 0.9949 - val_loss: 0.3025 - val_accuracy: 0.9480\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0264 - accuracy: 0.9911 - val_loss: 0.3396 - val_accuracy: 0.9400\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0310 - accuracy: 0.9887 - val_loss: 0.3111 - val_accuracy: 0.9520\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0155 - accuracy: 0.9953 - val_loss: 0.3047 - val_accuracy: 0.9520\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0370 - accuracy: 0.9867 - val_loss: 0.3303 - val_accuracy: 0.9540\n",
      "Test loss: 0.3206939399242401\n",
      "Test accuracy: 0.9340000152587891\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.5205\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3167 - accuracy: 0.9002 - val_loss: 0.2201 - val_accuracy: 0.8960\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2393 - accuracy: 0.9011 - val_loss: 0.2231 - val_accuracy: 0.9060\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2200 - accuracy: 0.9127 - val_loss: 0.1889 - val_accuracy: 0.9300\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1861 - accuracy: 0.9293 - val_loss: 0.1811 - val_accuracy: 0.9360\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1972 - accuracy: 0.9209 - val_loss: 0.1751 - val_accuracy: 0.9280\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1661 - accuracy: 0.9342 - val_loss: 0.1772 - val_accuracy: 0.9320\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1404 - accuracy: 0.9433 - val_loss: 0.1648 - val_accuracy: 0.9400\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1320 - accuracy: 0.9473 - val_loss: 0.1516 - val_accuracy: 0.9600\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1124 - accuracy: 0.9540 - val_loss: 0.2092 - val_accuracy: 0.9360\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0945 - accuracy: 0.9607 - val_loss: 0.1654 - val_accuracy: 0.9440\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0881 - accuracy: 0.9631 - val_loss: 0.3235 - val_accuracy: 0.9280\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0750 - accuracy: 0.9716 - val_loss: 0.2139 - val_accuracy: 0.9380\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0497 - accuracy: 0.9829 - val_loss: 0.2485 - val_accuracy: 0.9520\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0448 - accuracy: 0.9816 - val_loss: 0.2609 - val_accuracy: 0.9540\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0260 - accuracy: 0.9918 - val_loss: 0.3198 - val_accuracy: 0.9400\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0328 - accuracy: 0.9884 - val_loss: 0.2457 - val_accuracy: 0.9360\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0295 - accuracy: 0.9878 - val_loss: 0.3169 - val_accuracy: 0.9260\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0288 - accuracy: 0.9884 - val_loss: 0.2862 - val_accuracy: 0.9380\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0297 - accuracy: 0.9882 - val_loss: 0.2931 - val_accuracy: 0.9500\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0099 - accuracy: 0.9976 - val_loss: 0.3397 - val_accuracy: 0.9560\n",
      "Test loss: 0.31105318665504456\n",
      "Test accuracy: 0.9300000071525574\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.6355\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3078 - accuracy: 0.8929 - val_loss: 0.2218 - val_accuracy: 0.8960\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2382 - accuracy: 0.9018 - val_loss: 0.2300 - val_accuracy: 0.9200\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2249 - accuracy: 0.9089 - val_loss: 0.1998 - val_accuracy: 0.9420\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1955 - accuracy: 0.9213 - val_loss: 0.2144 - val_accuracy: 0.9260\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1717 - accuracy: 0.9304 - val_loss: 0.1634 - val_accuracy: 0.9340\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1587 - accuracy: 0.9342 - val_loss: 0.2232 - val_accuracy: 0.9220\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1497 - accuracy: 0.9393 - val_loss: 0.1491 - val_accuracy: 0.9420\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1155 - accuracy: 0.9553 - val_loss: 0.1559 - val_accuracy: 0.9440\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1149 - accuracy: 0.9553 - val_loss: 0.1582 - val_accuracy: 0.9560\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0957 - accuracy: 0.9642 - val_loss: 0.1699 - val_accuracy: 0.9380\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0714 - accuracy: 0.9713 - val_loss: 0.1568 - val_accuracy: 0.9500\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0498 - accuracy: 0.9827 - val_loss: 0.2538 - val_accuracy: 0.9420\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0683 - accuracy: 0.9724 - val_loss: 0.1884 - val_accuracy: 0.9400\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0389 - accuracy: 0.9869 - val_loss: 0.2108 - val_accuracy: 0.9580\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0270 - accuracy: 0.9907 - val_loss: 0.2453 - val_accuracy: 0.9360\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0215 - accuracy: 0.9916 - val_loss: 0.3228 - val_accuracy: 0.9500\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0162 - accuracy: 0.9947 - val_loss: 0.3601 - val_accuracy: 0.9620\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0289 - accuracy: 0.9889 - val_loss: 0.3797 - val_accuracy: 0.9420\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0142 - accuracy: 0.9953 - val_loss: 0.3443 - val_accuracy: 0.9500\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0058 - accuracy: 0.9991 - val_loss: 0.3793 - val_accuracy: 0.9560\n",
      "Test loss: 0.3692287504673004\n",
      "Test accuracy: 0.9309999942779541\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.816\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3269 - accuracy: 0.8842 - val_loss: 0.2333 - val_accuracy: 0.8960\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2410 - accuracy: 0.9004 - val_loss: 0.1934 - val_accuracy: 0.9020\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2119 - accuracy: 0.9127 - val_loss: 0.1913 - val_accuracy: 0.9240\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1919 - accuracy: 0.9216 - val_loss: 0.1546 - val_accuracy: 0.9380\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1748 - accuracy: 0.9318 - val_loss: 0.1540 - val_accuracy: 0.9360\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1543 - accuracy: 0.9367 - val_loss: 0.1581 - val_accuracy: 0.9440\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1418 - accuracy: 0.9456 - val_loss: 0.1907 - val_accuracy: 0.9400\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1238 - accuracy: 0.9504 - val_loss: 0.1591 - val_accuracy: 0.9380\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1289 - accuracy: 0.9529 - val_loss: 0.1568 - val_accuracy: 0.9520\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0945 - accuracy: 0.9631 - val_loss: 0.1720 - val_accuracy: 0.9540\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0765 - accuracy: 0.9700 - val_loss: 0.2084 - val_accuracy: 0.9460\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1122 - accuracy: 0.9553 - val_loss: 0.1686 - val_accuracy: 0.9360\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0601 - accuracy: 0.9784 - val_loss: 0.1838 - val_accuracy: 0.9480\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0611 - accuracy: 0.9773 - val_loss: 0.1707 - val_accuracy: 0.9460\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0463 - accuracy: 0.9827 - val_loss: 0.1958 - val_accuracy: 0.9480\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0434 - accuracy: 0.9844 - val_loss: 0.2501 - val_accuracy: 0.9540\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0198 - accuracy: 0.9938 - val_loss: 0.2523 - val_accuracy: 0.9540\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0115 - accuracy: 0.9969 - val_loss: 0.2781 - val_accuracy: 0.9560\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0063 - accuracy: 0.9980 - val_loss: 0.3203 - val_accuracy: 0.9580\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0081 - accuracy: 0.9978 - val_loss: 0.3570 - val_accuracy: 0.9440\n",
      "Test loss: 0.33810853958129883\n",
      "Test accuracy: 0.9309999942779541\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.7615\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3098 - accuracy: 0.8951 - val_loss: 0.2361 - val_accuracy: 0.8960\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2383 - accuracy: 0.9004 - val_loss: 0.1978 - val_accuracy: 0.9100\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1978 - accuracy: 0.9162 - val_loss: 0.1634 - val_accuracy: 0.9460\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1835 - accuracy: 0.9291 - val_loss: 0.1628 - val_accuracy: 0.9280\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1611 - accuracy: 0.9382 - val_loss: 0.1613 - val_accuracy: 0.9360\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1417 - accuracy: 0.9418 - val_loss: 0.1689 - val_accuracy: 0.9360\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1275 - accuracy: 0.9498 - val_loss: 0.1663 - val_accuracy: 0.9400\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1073 - accuracy: 0.9573 - val_loss: 0.2138 - val_accuracy: 0.9120\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0953 - accuracy: 0.9631 - val_loss: 0.1937 - val_accuracy: 0.9500\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0760 - accuracy: 0.9716 - val_loss: 0.2161 - val_accuracy: 0.9500\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0665 - accuracy: 0.9727 - val_loss: 0.2183 - val_accuracy: 0.9220\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0684 - accuracy: 0.9760 - val_loss: 0.2425 - val_accuracy: 0.9440\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0368 - accuracy: 0.9884 - val_loss: 0.2801 - val_accuracy: 0.9460\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0182 - accuracy: 0.9936 - val_loss: 0.2842 - val_accuracy: 0.9400\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0251 - accuracy: 0.9913 - val_loss: 0.2762 - val_accuracy: 0.9480\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0253 - accuracy: 0.9911 - val_loss: 0.2970 - val_accuracy: 0.9380\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0136 - accuracy: 0.9947 - val_loss: 0.3265 - val_accuracy: 0.9440\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0061 - accuracy: 0.9984 - val_loss: 0.4300 - val_accuracy: 0.9500\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0043 - accuracy: 0.9987 - val_loss: 0.4565 - val_accuracy: 0.9420\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0057 - accuracy: 0.9984 - val_loss: 0.4425 - val_accuracy: 0.9340\n",
      "Test loss: 0.4115174412727356\n",
      "Test accuracy: 0.925000011920929\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.78\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3222 - accuracy: 0.8973 - val_loss: 0.2224 - val_accuracy: 0.8960\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2659 - accuracy: 0.9004 - val_loss: 0.2044 - val_accuracy: 0.8960\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2285 - accuracy: 0.9027 - val_loss: 0.1944 - val_accuracy: 0.9040\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1928 - accuracy: 0.9189 - val_loss: 0.1888 - val_accuracy: 0.9200\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1774 - accuracy: 0.9251 - val_loss: 0.1666 - val_accuracy: 0.9300\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1784 - accuracy: 0.9320 - val_loss: 0.1721 - val_accuracy: 0.9320\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1528 - accuracy: 0.9427 - val_loss: 0.1738 - val_accuracy: 0.9360\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1317 - accuracy: 0.9487 - val_loss: 0.1519 - val_accuracy: 0.9500\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1204 - accuracy: 0.9524 - val_loss: 0.1605 - val_accuracy: 0.9480\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0971 - accuracy: 0.9613 - val_loss: 0.1660 - val_accuracy: 0.9360\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0857 - accuracy: 0.9638 - val_loss: 0.1959 - val_accuracy: 0.9380\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0738 - accuracy: 0.9716 - val_loss: 0.2108 - val_accuracy: 0.9360\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0605 - accuracy: 0.9771 - val_loss: 0.1992 - val_accuracy: 0.9440\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0323 - accuracy: 0.9896 - val_loss: 0.2674 - val_accuracy: 0.9480\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0243 - accuracy: 0.9909 - val_loss: 0.2694 - val_accuracy: 0.9460\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0221 - accuracy: 0.9924 - val_loss: 0.2921 - val_accuracy: 0.9500\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0411 - accuracy: 0.9867 - val_loss: 0.3783 - val_accuracy: 0.9340\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0280 - accuracy: 0.9893 - val_loss: 0.2553 - val_accuracy: 0.9520\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0132 - accuracy: 0.9958 - val_loss: 0.3241 - val_accuracy: 0.9360\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0043 - accuracy: 0.9989 - val_loss: 0.3854 - val_accuracy: 0.9420\n",
      "Test loss: 0.36823365092277527\n",
      "Test accuracy: 0.9319999814033508\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.803\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3049 - accuracy: 0.8949 - val_loss: 0.2917 - val_accuracy: 0.8960\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2470 - accuracy: 0.9013 - val_loss: 0.2022 - val_accuracy: 0.9040\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2149 - accuracy: 0.9140 - val_loss: 0.1884 - val_accuracy: 0.9080\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1838 - accuracy: 0.9260 - val_loss: 0.1589 - val_accuracy: 0.9400\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1830 - accuracy: 0.9229 - val_loss: 0.1654 - val_accuracy: 0.9300\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1644 - accuracy: 0.9349 - val_loss: 0.1605 - val_accuracy: 0.9380\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1440 - accuracy: 0.9458 - val_loss: 0.4140 - val_accuracy: 0.8060\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1864 - accuracy: 0.9224 - val_loss: 0.1607 - val_accuracy: 0.9460\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1457 - accuracy: 0.9442 - val_loss: 0.1659 - val_accuracy: 0.9340\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1227 - accuracy: 0.9527 - val_loss: 0.1515 - val_accuracy: 0.9500\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0945 - accuracy: 0.9633 - val_loss: 0.1639 - val_accuracy: 0.9580\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0782 - accuracy: 0.9693 - val_loss: 0.1712 - val_accuracy: 0.9520\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0624 - accuracy: 0.9762 - val_loss: 0.1853 - val_accuracy: 0.9620\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0507 - accuracy: 0.9796 - val_loss: 0.2944 - val_accuracy: 0.9440\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0485 - accuracy: 0.9813 - val_loss: 0.2579 - val_accuracy: 0.9460\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0238 - accuracy: 0.9909 - val_loss: 0.2262 - val_accuracy: 0.9480\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0155 - accuracy: 0.9960 - val_loss: 0.2339 - val_accuracy: 0.9520\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0369 - accuracy: 0.9873 - val_loss: 0.2437 - val_accuracy: 0.9540\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0338 - accuracy: 0.9871 - val_loss: 0.2474 - val_accuracy: 0.9520\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0184 - accuracy: 0.9933 - val_loss: 0.3170 - val_accuracy: 0.9560\n",
      "Test loss: 0.318689227104187\n",
      "Test accuracy: 0.9330000281333923\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.626\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3192 - accuracy: 0.8800 - val_loss: 0.2419 - val_accuracy: 0.8960\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2429 - accuracy: 0.9022 - val_loss: 0.2234 - val_accuracy: 0.9020\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2151 - accuracy: 0.9096 - val_loss: 0.1865 - val_accuracy: 0.9180\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1987 - accuracy: 0.9187 - val_loss: 0.1696 - val_accuracy: 0.9300\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1695 - accuracy: 0.9327 - val_loss: 0.1553 - val_accuracy: 0.9420\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1528 - accuracy: 0.9398 - val_loss: 0.1623 - val_accuracy: 0.9300\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1253 - accuracy: 0.9507 - val_loss: 0.1561 - val_accuracy: 0.9360\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1100 - accuracy: 0.9616 - val_loss: 0.1814 - val_accuracy: 0.9440\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1011 - accuracy: 0.9602 - val_loss: 0.1714 - val_accuracy: 0.9440\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0802 - accuracy: 0.9678 - val_loss: 0.1995 - val_accuracy: 0.9360\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0622 - accuracy: 0.9776 - val_loss: 0.1719 - val_accuracy: 0.9440\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0543 - accuracy: 0.9789 - val_loss: 0.1924 - val_accuracy: 0.9420\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0338 - accuracy: 0.9891 - val_loss: 0.2638 - val_accuracy: 0.9440\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0270 - accuracy: 0.9907 - val_loss: 0.3094 - val_accuracy: 0.9440\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0385 - accuracy: 0.9862 - val_loss: 0.2232 - val_accuracy: 0.9380\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0270 - accuracy: 0.9913 - val_loss: 0.2800 - val_accuracy: 0.9520\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0150 - accuracy: 0.9956 - val_loss: 0.2915 - val_accuracy: 0.9480\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0091 - accuracy: 0.9967 - val_loss: 0.3347 - val_accuracy: 0.9520\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0037 - accuracy: 0.9993 - val_loss: 0.3348 - val_accuracy: 0.9520\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0075 - accuracy: 0.9969 - val_loss: 0.3799 - val_accuracy: 0.9560\n",
      "Test loss: 0.37979453802108765\n",
      "Test accuracy: 0.9430000185966492\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.6895\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3347 - accuracy: 0.8962 - val_loss: 0.2499 - val_accuracy: 0.8960\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2413 - accuracy: 0.9009 - val_loss: 0.2003 - val_accuracy: 0.8980\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2133 - accuracy: 0.9147 - val_loss: 0.1822 - val_accuracy: 0.9180\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1872 - accuracy: 0.9207 - val_loss: 0.1542 - val_accuracy: 0.9440\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1774 - accuracy: 0.9318 - val_loss: 0.1572 - val_accuracy: 0.9400\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1580 - accuracy: 0.9382 - val_loss: 0.2794 - val_accuracy: 0.8680\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1726 - accuracy: 0.9282 - val_loss: 0.1581 - val_accuracy: 0.9540\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1363 - accuracy: 0.9482 - val_loss: 0.1423 - val_accuracy: 0.9500\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1040 - accuracy: 0.9578 - val_loss: 0.1817 - val_accuracy: 0.9440\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0852 - accuracy: 0.9684 - val_loss: 0.2110 - val_accuracy: 0.9400\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0946 - accuracy: 0.9613 - val_loss: 0.2492 - val_accuracy: 0.9440\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0663 - accuracy: 0.9742 - val_loss: 0.1784 - val_accuracy: 0.9500\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0647 - accuracy: 0.9733 - val_loss: 0.2334 - val_accuracy: 0.9380\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0383 - accuracy: 0.9858 - val_loss: 0.2555 - val_accuracy: 0.9600\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0210 - accuracy: 0.9929 - val_loss: 0.3218 - val_accuracy: 0.9580\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0217 - accuracy: 0.9929 - val_loss: 0.2708 - val_accuracy: 0.9460\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0105 - accuracy: 0.9969 - val_loss: 0.3217 - val_accuracy: 0.9480\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0100 - accuracy: 0.9962 - val_loss: 0.3178 - val_accuracy: 0.9340\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0586 - accuracy: 0.9762 - val_loss: 0.2386 - val_accuracy: 0.9440\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0293 - accuracy: 0.9882 - val_loss: 0.3005 - val_accuracy: 0.9580\n",
      "Test loss: 0.33178937435150146\n",
      "Test accuracy: 0.9390000104904175\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.494\n",
      "      通し番号  カウント\n",
      "0        0     6\n",
      "1        1     5\n",
      "2        2    10\n",
      "3        3    10\n",
      "4        4     6\n",
      "...    ...   ...\n",
      "1995  1995     8\n",
      "1996  1996     7\n",
      "1997  1997    10\n",
      "1998  1998    10\n",
      "1999  1999     8\n",
      "\n",
      "[2000 rows x 2 columns]\n",
      "[0.6435, 0.5205, 0.6355, 0.816, 0.7615, 0.78, 0.803, 0.626, 0.6895, 0.494]\n",
      "11\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[1201, 1214, 1036, 1202, 802, 11, 1923, 1186, 1216, 786, 970, 1024, 820, 1021, 780, 105, 1239, 1242, 772, 763, 754, 1901, 995, 1040, 908, 85, 947, 927, 1144, 921, 867, 1133, 1969, 1949, 889, 1119, 915, 1114, 903, 1098, 1102, 46, 43, 905, 934, 1149, 1973, 942, 830, 1984, 84, 909, 1173, 1166, 842, 1935, 26, 940, 1054, 848, 1055, 854, 1062, 935, 881, 256, 741, 1581, 1627, 1790, 387, 415, 1607, 1597, 1594, 202, 201, 1591, 1571, 1511, 1564, 194, 192, 1563, 188, 1545, 1531, 183, 1524, 1520, 384, 1787, 381, 378, 1750, 1752, 260, 1754, 1732, 280, 1719, 1708, 319, 231, 1696, 1770, 323, 324, 1688, 1683, 337, 1679, 1676, 1673, 1661, 505, 1504, 713, 1879, 639, 1365, 1364, 1864, 642, 1358, 1357, 652, 665, 668, 1331, 1822, 674, 675, 1322, 680, 683, 691, 1889, 1300, 1297, 1292, 1370, 1859, 635, 1384, 510, 179, 1825, 512, 1827, 528, 529, 1468, 1438, 1437, 1434, 166, 1431, 1425, 1417, 590, 597, 160, 608, 155, 626, 1343, 242, 1796, 1884, 140, 40, 5, 1780, 1811, 1823, 168, 1781, 1831, 175, 1928, 156, 181, 239, 232, 1817, 1764, 1788, 29, 148, 126, 1005, 1502, 532, 1162, 1161, 852, 1442, 567, 1450, 1453, 1465, 1470, 547, 539, 1145, 835, 514, 1143, 746, 885, 1006, 888, 1117, 1115, 1111, 1556, 1557, 1163, 603, 455, 1219, 751, 1284, 1266, 702, 762, 693, 1248, 777, 1333, 785, 1336, 664, 622, 1741, 1344, 1350, 1351, 801, 1359, 1360, 1190, 812, 1379, 1178, 904, 1275, 335, 1090, 1727, 965, 274, 1031, 302, 268, 1058, 1043, 313, 1604, 1600, 376, 1734, 296, 261, 1595, 1639, 1015, 911, 1695, 990, 357, 1056, 429, 259, 1002, 971, 582, 1229, 1405, 254, 1408, 1247, 589, 1906, 223, 1238, 1886, 583, 1362, 1694, 1381, 725, 1860, 1018, 1991, 277, 963, 1267, 1033, 677, 628, 1757, 1876, 1337, 1881, 1892, 611, 124, 563, 1315, 476, 499, 449, 74, 1816, 1785, 487, 99, 453, 481, 1948, 218, 890, 1089, 1941, 1568, 1131, 1148, 1147, 395, 861, 461, 1555, 503, 928, 1507, 1113, 565, 204, 795, 797, 1463, 799, 1204, 553, 1472, 810, 1191, 1182, 891, 825, 448, 362, 365, 83, 1648, 1946, 1686, 16, 1726, 1717, 423, 901, 1669, 1064, 959, 1057, 230, 953, 7, 370, 12, 245, 1970, 1972, 317, 361, 1622, 1659, 13, 1774, 1697, 403, 1060, 1777, 186, 428, 1868, 1539, 1371, 1534, 784, 490, 1383, 1262, 631, 116, 506, 1819, 1508, 154, 1505, 1853, 1251, 765, 833, 158, 602, 86, 584, 1428, 101, 1843, 50, 1226, 1862, 572, 697, 1874, 134, 685, 1126, 63, 52, 142, 1342, 1121, 1560, 57, 862, 436, 1314, 431, 1301, 129, 69, 1702, 1542, 1643, 1287, 318, 1084, 1316, 761, 1159, 1035, 486, 1303, 1082, 669, 1328, 1140, 860, 1323, 1593, 718, 255, 149, 1583, 1803, 236, 735, 976, 212, 147, 1614, 1091, 195, 877, 1739, 1326, 1164, 459, 1141, 1264, 1093, 958, 463, 27, 1195, 79, 1477, 221, 356, 1849, 1223, 1065, 1412, 1922, 225, 1193, 1833, 699, 792, 1866, 549, 1662, 343, 803, 23, 172, 1464, 333, 1756, 524, 1443, 1232, 1783, 374, 339, 839, 1841, 369, 1820, 180, 1347, 654, 1499, 513, 980, 176, 1496, 515, 21, 1509, 1646, 1877, 838, 1832, 998, 1072, 828, 1644, 1488, 1012, 929, 1341, 534, 288, 1978, 552, 350, 1637, 1462, 798, 793, 95, 426, 97, 1980, 1220, 1839, 568, 700, 1048, 266, 137, 1937, 1794, 1, 1099, 1610, 1127, 1009, 910, 1961, 1436, 1601, 56, 1007, 209, 900, 203, 136, 400, 30, 1618, 68, 1887, 217, 466, 472, 1540, 1628, 1088, 695, 1154, 1753, 847, 220, 341, 1801, 1418, 298, 587, 949, 1420, 1277, 1711, 1243, 1271, 161, 1039, 1415, 757, 591, 599, 233, 1378, 1407, 1989, 1258, 1907, 1038, 767, 1706, 1767, 238, 128, 1904, 620, 127, 1263, 1845, 606, 1872, 336, 640, 944, 704, 1684, 732, 1268, 1722, 1373, 144, 422, 1602, 1366, 1863, 1356, 645, 367, 143, 269, 390, 1332, 383, 267, 1633, 1319, 1585, 1830, 1377, 557, 1446, 1541, 478, 1664, 170, 1317, 1525, 1682, 556, 464, 498, 1467, 174, 551, 536, 1483, 522, 1491, 570, 1549, 1714, 1486, 633, 1388, 627, 312, 618, 1707, 315, 1572, 596, 332, 316, 1566, 321, 456, 581, 1553, 576, 1551, 0, 1376, 1746, 1046, 1181, 821, 1188, 90, 796, 98, 1051, 1225, 1230, 933, 1911, 778, 946, 1240, 114, 760, 10, 123, 1069, 834, 8, 1137, 1959, 54, 1107, 1103, 1100, 1965, 34, 870, 64, 82, 920, 1940, 850, 1155, 71, 1083, 843, 72, 749, 1217, 690, 4, 717, 986, 1294, 6, 716, 788, 1452, 228, 1448, 169, 1840, 578, 1231, 1690, 781, 15, 569, 1212, 1915, 1454, 1484, 815, 88, 1192, 19, 811, 548, 1078, 1674, 1919, 1918, 1779, 1466, 171, 1207, 1460, 560, 1429, 1245, 773, 978, 150, 729, 643, 1354, 1894, 1761, 706, 656, 272, 1996, 243, 1873, 667, 1304, 670, 1888, 258, 638, 1897, 1846, 1721, 1424, 1241, 586, 1771, 1700, 1925, 1409, 1034, 610, 1393, 758, 753, 1856, 117, 1375, 1272, 1993, 937, 1049, 454, 409, 460, 1061, 445, 1074, 1942, 1612, 1584, 457, 1617, 930, 465, 1120, 1059, 1094, 424, 1561, 1620, 1569, 886, 359, 199, 41, 58, 1071, 1567, 869, 354, 1575, 1806, 190, 35, 47, 372, 200, 899, 1535, 1636, 1927, 440, 1786, 519, 831, 1175, 178, 1503, 1172, 923, 1671, 1931, 922, 1510, 1053, 348, 441, 497, 1519, 1521, 495, 1641, 491, 1067, 1626, 388, 444, 482, 1157, 1068, 1802, 1011, 1657, 1257, 1663, 1842, 1606, 1995, 1576, 1236, 1647, 1865, 1592, 1586, 1979, 1234, 1977, 1976, 1812, 1987, 1988, 1025, 1603, 1818, 1642, 1851, 1751, 1514, 1211, 1324, 1461, 1334, 1335, 1339, 1432, 1427, 1165, 1728, 1422, 1348, 1414, 1349, 1413, 1411, 1410, 1402, 1361, 1397, 1743, 1394, 1748, 1329, 1712, 1962, 1482, 1538, 1798, 1960, 1532, 1523, 1518, 1052, 1880, 1385, 1308, 1309, 1691, 1498, 1885, 1087, 1944, 1493, 1703, 1096, 1784, 1895, 1000, 1999, 484, 187, 479, 480, 508, 837, 509, 527, 818, 542, 546, 808, 806, 94, 800, 558, 559, 475, 65, 926, 189, 385, 397, 918, 410, 413, 210, 416, 418, 420, 437, 442, 60, 883, 878, 873, 573, 782, 575, 580, 637, 739, 723, 708, 707, 653, 658, 701, 659, 131, 672, 694, 673, 132, 689, 636, 748, 253, 613, 775, 110, 164, 594, 770, 604, 764, 151, 115, 621, 629, 634, 752, 153, 924, 682, 375, 985, 968, 297, 351, 299, 224, 229, 25, 340, 364, 287, 303, 366, 352, 9, 966, 347, 936, 276, 355, 252, 24, 250, 342, 247, 1878, 1198, 167, 138, 972, 1194, 1882, 1252, 974, 139, 1250, 1883, 1852, 999, 1020, 991, 1985, 1858, 783, 1210, 1233, 1869, 1235, 776, 146, 1982, 145, 162, 17, 994, 996, 1990, 771, 1844, 791, 1106, 130, 967, 1945, 1124, 81, 1929, 925, 882, 1130, 1924, 1079, 87, 89, 1952, 1135, 93, 1073, 1123, 1835, 919, 895, 1109, 906, 1116, 1105, 1104, 897, 912, 1122, 913, 78, 1943, 67, 1118, 66, 55, 1136, 1916, 1170, 845, 113, 840, 1966, 1169, 836, 1171, 1963, 32, 1967, 829, 120, 827, 1028, 1108, 952, 53, 1142, 1139, 1955, 866, 865, 864, 1956, 1913, 42, 945, 1151, 853, 1909, 1041, 851, 1621, 1302, 1256, 328, 1715, 1469, 550, 1475, 1476, 543, 308, 537, 310, 535, 1485, 531, 530, 1709, 523, 520, 1494, 517, 320, 322, 1506, 1458, 295, 294, 600, 251, 257, 616, 1738, 609, 263, 264, 1403, 1735, 595, 290, 1730, 759, 1421, 1426, 1724, 574, 1441, 1444, 1445, 326, 504, 1389, 1515, 1653, 1578, 1652, 1580, 1650, 438, 432, 1588, 1590, 427, 1638, 377, 417, 411, 408, 407, 402, 401, 391, 392, 1619, 1654, 1574, 451, 1672, 1004, 501, 1516, 331, 1522, 1526, 1527, 1528, 1536, 477, 1656, 1543, 473, 344, 470, 462, 1554, 1558, 1658, 1562, 1390, 273, 678, 671, 191, 1809, 1310, 1311, 1791, 1280, 687, 1789, 737, 1313, 1318, 681, 1320, 679, 1782, 222, 738, 692, 1808, 1282, 1291, 715, 1800, 720, 1797, 712, 198, 206, 1293, 1306, 197, 211, 1298, 196, 396, 214, 696, 185, 1286, 1330, 240, 1270, 651, 1821, 650, 237, 655, 1762, 641, 1367, 743, 1260, 1815, 1261, 1769, 244, 1834, 1382, 740, 1338, 1775, 1353, 1340, 756, 663, 1773, 502, 598, 601, 1404, 605, 1401, 607, 1400, 1399, 1398, 612, 614, 615, 617, 1396, 619, 1395, 1392, 623, 624, 625, 1391, 1387, 1406, 593, 1457, 592, 561, 562, 1455, 564, 1451, 566, 1449, 1447, 571, 1440, 1439, 1435, 577, 1433, 579, 1430, 1423, 585, 588, 1419, 1416, 630, 1386, 632, 1380, 1312, 686, 688, 1307, 1305, 698, 1299, 1296, 703, 1295, 705, 1290, 709, 710, 711, 1289, 714, 1288, 1285, 719, 721, 684, 1321, 676, 648, 1374, 1372, 1369, 1368, 1363, 644, 1355, 646, 647, 649, 1325, 1352, 657, 1346, 1345, 660, 661, 662, 666, 1327, 1456, 1459, 394, 435, 439, 1582, 1579, 443, 1577, 446, 447, 450, 452, 1573, 1570, 1565, 1559, 458, 1552, 1550, 1548, 1547, 1546, 467, 468, 1587, 434, 555, 433, 399, 1616, 1615, 404, 405, 406, 1613, 1611, 412, 1609, 414, 1608, 1605, 419, 421, 1599, 1598, 1596, 425, 1589, 430, 469, 471, 1544, 474, 521, 1492, 525, 526, 1490, 1489, 1487, 533, 1481, 538, 1480, 540, 541, 1479, 544, 545, 1478, 1474, 1473, 1471, 554, 518, 516, 1495, 493, 1537, 1533, 1530, 483, 1529, 485, 488, 489, 492, 494, 1497, 496, 1517, 500, 1513, 507, 1512, 1501, 511, 1500, 722, 1283, 724, 902, 1101, 1097, 914, 916, 917, 1095, 1092, 1086, 1085, 1081, 1080, 1077, 1076, 1075, 931, 932, 1070, 1066, 1063, 938, 939, 907, 1110, 726, 1112, 868, 1138, 871, 872, 874, 875, 876, 1134, 1132, 879, 880, 1129, 884, 1128, 1125, 887, 892, 893, 894, 896, 898, 1050, 941, 1047, 943, 1022, 977, 979, 1019, 981, 982, 983, 984, 1017, 1016, 987, 988, 989, 1014, 992, 993, 1013, 997, 1010, 1001, 1008, 975, 973, 1023, 956, 1045, 1044, 1042, 948, 950, 951, 1037, 954, 955, 957, 969, 1032, 1030, 960, 961, 962, 1029, 964, 1027, 1026, 863, 1146, 1150, 1209, 1253, 766, 1249, 768, 769, 1246, 1244, 1237, 774, 779, 1228, 1227, 1224, 1222, 1221, 787, 1218, 789, 790, 1215, 1213, 1254, 1255, 1259, 1278, 727, 728, 1281, 730, 731, 733, 734, 1279, 736, 1276, 755, 742, 744, 745, 1274, 747, 1273, 750, 1269, 1265, 794, 1208, 859, 1206, 826, 1179, 1177, 1176, 832, 1174, 1168, 1167, 841, 1160, 844, 846, 1158, 1156, 849, 1153, 1152, 855, 856, 857, 858, 1180, 824, 823, 1196, 1205, 1203, 1200, 1199, 804, 805, 807, 1197, 809, 1189, 822, 813, 814, 1187, 816, 817, 1185, 819, 1184, 1183, 398, 1003, 281, 1912, 1749, 1747, 1914, 1745, 1744, 1742, 1740, 96, 1737, 262, 1917, 265, 1736, 92, 1733, 249, 100, 108, 248, 234, 235, 1763, 107, 106, 1760, 241, 1759, 1758, 104, 103, 102, 1755, 246, 1910, 91, 1731, 270, 1920, 1720, 289, 291, 292, 293, 77, 1718, 76, 1716, 75, 1713, 300, 1934, 301, 73, 1723, 286, 1933, 1725, 1921, 271, 1729, 275, 1926, 1930, 1932, 80, 278, 279, 282, 283, 284, 285, 1765, 109, 304, 1850, 157, 193, 1807, 1805, 1854, 1855, 1857, 1804, 152, 1861, 1799, 1867, 205, 207, 208, 159, 1810, 1908, 1813, 1837, 173, 1838, 1829, 1828, 177, 1826, 1824, 165, 182, 1847, 163, 184, 1848, 1814, 1870, 1871, 1795, 1793, 1778, 1776, 119, 118, 1900, 1902, 1903, 1905, 226, 227, 1772, 1768, 112, 111, 1766, 121, 122, 1899, 135, 1875, 1792, 141, 213, 215, 216, 133, 1898, 1890, 1891, 219, 1893, 1896, 125, 1710, 1836, 1668, 1670, 18, 373, 44, 45, 1675, 1677, 1678, 338, 1680, 1958, 1957, 1681, 1685, 48, 49, 1983, 334, 1687, 1689, 14, 1640, 1975, 51, 1635, 330, 1986, 329, 1981, 371, 1954, 39, 363, 1971, 1651, 28, 360, 1968, 1655, 358, 31, 33, 1660, 1649, 22, 1964, 353, 36, 37, 368, 1665, 1666, 349, 20, 1667, 1645, 346, 38, 345, 1634, 1974, 1699, 1625, 1693, 62, 1947, 311, 1936, 1698, 386, 3, 1938, 1624, 1994, 389, 1701, 1623, 1704, 314, 1705, 1939, 1997, 70, 1629, 309, 61, 325, 379, 380, 2, 1953, 1992, 305, 1951, 327, 306, 59, 1950, 1692, 307, 1998, 1632, 1630, 393, 1631, 382]\n",
      "500\n",
      "500\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3509 - accuracy: 0.8871 - val_loss: 0.3673 - val_accuracy: 0.9020\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2886 - accuracy: 0.8993 - val_loss: 0.2422 - val_accuracy: 0.9040\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2426 - accuracy: 0.9016 - val_loss: 0.2263 - val_accuracy: 0.9060\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2200 - accuracy: 0.9044 - val_loss: 0.2538 - val_accuracy: 0.8980\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2124 - accuracy: 0.9100 - val_loss: 0.2367 - val_accuracy: 0.9100\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2062 - accuracy: 0.9109 - val_loss: 0.2119 - val_accuracy: 0.9100\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1917 - accuracy: 0.9202 - val_loss: 0.1925 - val_accuracy: 0.9180\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1861 - accuracy: 0.9173 - val_loss: 0.1977 - val_accuracy: 0.9140\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1649 - accuracy: 0.9320 - val_loss: 0.2289 - val_accuracy: 0.9160\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1563 - accuracy: 0.9313 - val_loss: 0.2031 - val_accuracy: 0.9200\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1344 - accuracy: 0.9456 - val_loss: 0.1918 - val_accuracy: 0.9160\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1224 - accuracy: 0.9509 - val_loss: 0.2166 - val_accuracy: 0.9160\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1033 - accuracy: 0.9600 - val_loss: 0.2385 - val_accuracy: 0.9280\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0854 - accuracy: 0.9629 - val_loss: 0.2119 - val_accuracy: 0.9180\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0700 - accuracy: 0.9720 - val_loss: 0.2912 - val_accuracy: 0.9240\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0516 - accuracy: 0.9824 - val_loss: 0.2380 - val_accuracy: 0.9300\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0338 - accuracy: 0.9873 - val_loss: 0.2338 - val_accuracy: 0.9220\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0335 - accuracy: 0.9884 - val_loss: 0.2652 - val_accuracy: 0.9300\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0255 - accuracy: 0.9911 - val_loss: 0.3307 - val_accuracy: 0.9140\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0292 - accuracy: 0.9900 - val_loss: 0.3047 - val_accuracy: 0.9220\n",
      "Test loss: 0.2820178270339966\n",
      "Test accuracy: 0.9190000295639038\n",
      "63/63 [==============================] - 0s 2ms/step\n",
      "0.617\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3461 - accuracy: 0.8947 - val_loss: 0.2778 - val_accuracy: 0.9020\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2512 - accuracy: 0.8993 - val_loss: 0.2359 - val_accuracy: 0.9120\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2412 - accuracy: 0.9029 - val_loss: 0.2370 - val_accuracy: 0.9020\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2202 - accuracy: 0.9071 - val_loss: 0.2222 - val_accuracy: 0.9060\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2279 - accuracy: 0.9029 - val_loss: 0.2281 - val_accuracy: 0.9020\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2049 - accuracy: 0.9113 - val_loss: 0.2242 - val_accuracy: 0.9020\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2067 - accuracy: 0.9104 - val_loss: 0.1973 - val_accuracy: 0.9080\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1809 - accuracy: 0.9224 - val_loss: 0.1962 - val_accuracy: 0.9180\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1792 - accuracy: 0.9236 - val_loss: 0.2236 - val_accuracy: 0.9060\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1498 - accuracy: 0.9376 - val_loss: 0.1860 - val_accuracy: 0.9300\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1320 - accuracy: 0.9476 - val_loss: 0.2143 - val_accuracy: 0.9140\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1112 - accuracy: 0.9558 - val_loss: 0.2728 - val_accuracy: 0.9240\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0990 - accuracy: 0.9582 - val_loss: 0.2011 - val_accuracy: 0.9320\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0646 - accuracy: 0.9747 - val_loss: 0.3912 - val_accuracy: 0.9200\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0684 - accuracy: 0.9713 - val_loss: 0.2679 - val_accuracy: 0.9320\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0465 - accuracy: 0.9831 - val_loss: 0.2933 - val_accuracy: 0.9220\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0578 - accuracy: 0.9760 - val_loss: 0.3254 - val_accuracy: 0.9340\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0294 - accuracy: 0.9887 - val_loss: 0.2423 - val_accuracy: 0.9300\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0193 - accuracy: 0.9938 - val_loss: 0.3843 - val_accuracy: 0.9180\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0456 - accuracy: 0.9822 - val_loss: 0.3236 - val_accuracy: 0.9240\n",
      "Test loss: 0.2746911942958832\n",
      "Test accuracy: 0.9369999766349792\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.267\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3532 - accuracy: 0.9000 - val_loss: 0.2634 - val_accuracy: 0.9020\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2662 - accuracy: 0.9000 - val_loss: 0.2445 - val_accuracy: 0.9060\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2437 - accuracy: 0.9002 - val_loss: 0.2282 - val_accuracy: 0.8980\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2215 - accuracy: 0.9060 - val_loss: 0.2713 - val_accuracy: 0.8980\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2199 - accuracy: 0.9033 - val_loss: 0.2217 - val_accuracy: 0.9060\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2189 - accuracy: 0.9080 - val_loss: 0.2303 - val_accuracy: 0.9020\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2027 - accuracy: 0.9153 - val_loss: 0.2007 - val_accuracy: 0.9200\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1980 - accuracy: 0.9182 - val_loss: 0.2464 - val_accuracy: 0.9100\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1767 - accuracy: 0.9264 - val_loss: 0.1959 - val_accuracy: 0.9140\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1601 - accuracy: 0.9367 - val_loss: 0.2337 - val_accuracy: 0.9080\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1486 - accuracy: 0.9376 - val_loss: 0.1948 - val_accuracy: 0.9200\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1280 - accuracy: 0.9522 - val_loss: 0.2133 - val_accuracy: 0.9160\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1049 - accuracy: 0.9576 - val_loss: 0.2681 - val_accuracy: 0.9240\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1038 - accuracy: 0.9609 - val_loss: 0.2644 - val_accuracy: 0.9280\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0700 - accuracy: 0.9744 - val_loss: 0.2951 - val_accuracy: 0.9220\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0690 - accuracy: 0.9733 - val_loss: 0.2906 - val_accuracy: 0.8880\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0622 - accuracy: 0.9771 - val_loss: 0.2921 - val_accuracy: 0.9080\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0417 - accuracy: 0.9827 - val_loss: 0.3296 - val_accuracy: 0.9060\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0296 - accuracy: 0.9902 - val_loss: 0.3402 - val_accuracy: 0.9140\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0168 - accuracy: 0.9942 - val_loss: 0.3809 - val_accuracy: 0.9140\n",
      "Test loss: 0.2923380136489868\n",
      "Test accuracy: 0.9259999990463257\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.6075\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3500 - accuracy: 0.8884 - val_loss: 0.2575 - val_accuracy: 0.9020\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2573 - accuracy: 0.9013 - val_loss: 0.2465 - val_accuracy: 0.9040\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2343 - accuracy: 0.9031 - val_loss: 0.2060 - val_accuracy: 0.9080\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2164 - accuracy: 0.9060 - val_loss: 0.2198 - val_accuracy: 0.9200\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.2436 - accuracy: 0.8996 - val_loss: 0.2145 - val_accuracy: 0.9120\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2124 - accuracy: 0.9049 - val_loss: 0.2465 - val_accuracy: 0.9100\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2033 - accuracy: 0.9093 - val_loss: 0.2145 - val_accuracy: 0.9140\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1879 - accuracy: 0.9200 - val_loss: 0.2066 - val_accuracy: 0.9140\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1756 - accuracy: 0.9242 - val_loss: 0.2049 - val_accuracy: 0.9300\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1679 - accuracy: 0.9311 - val_loss: 0.2043 - val_accuracy: 0.9160\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1620 - accuracy: 0.9322 - val_loss: 0.2140 - val_accuracy: 0.9280\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1312 - accuracy: 0.9480 - val_loss: 0.2050 - val_accuracy: 0.9280\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1053 - accuracy: 0.9567 - val_loss: 0.1919 - val_accuracy: 0.9340\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0842 - accuracy: 0.9658 - val_loss: 0.2055 - val_accuracy: 0.9300\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0797 - accuracy: 0.9693 - val_loss: 0.2216 - val_accuracy: 0.9420\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0777 - accuracy: 0.9691 - val_loss: 0.2050 - val_accuracy: 0.9320\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0564 - accuracy: 0.9798 - val_loss: 0.3324 - val_accuracy: 0.9320\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0394 - accuracy: 0.9851 - val_loss: 0.2725 - val_accuracy: 0.9380\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0241 - accuracy: 0.9922 - val_loss: 0.3040 - val_accuracy: 0.9300\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0259 - accuracy: 0.9904 - val_loss: 0.2834 - val_accuracy: 0.9340\n",
      "Test loss: 0.27361026406288147\n",
      "Test accuracy: 0.9369999766349792\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.693\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3604 - accuracy: 0.8782 - val_loss: 0.2731 - val_accuracy: 0.9020\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2743 - accuracy: 0.8987 - val_loss: 0.2543 - val_accuracy: 0.9020\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2383 - accuracy: 0.9031 - val_loss: 0.2281 - val_accuracy: 0.9080\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2280 - accuracy: 0.9058 - val_loss: 0.2373 - val_accuracy: 0.8980\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2257 - accuracy: 0.9051 - val_loss: 0.2151 - val_accuracy: 0.9060\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2086 - accuracy: 0.9098 - val_loss: 0.2074 - val_accuracy: 0.9140\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2034 - accuracy: 0.9153 - val_loss: 0.2773 - val_accuracy: 0.8880\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2080 - accuracy: 0.9124 - val_loss: 0.2003 - val_accuracy: 0.9120\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1666 - accuracy: 0.9324 - val_loss: 0.3780 - val_accuracy: 0.9020\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1749 - accuracy: 0.9284 - val_loss: 0.2079 - val_accuracy: 0.9200\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1452 - accuracy: 0.9402 - val_loss: 0.2431 - val_accuracy: 0.9080\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1230 - accuracy: 0.9511 - val_loss: 0.2809 - val_accuracy: 0.9160\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1070 - accuracy: 0.9569 - val_loss: 0.2412 - val_accuracy: 0.9240\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0868 - accuracy: 0.9636 - val_loss: 0.2550 - val_accuracy: 0.9220\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0785 - accuracy: 0.9713 - val_loss: 0.2095 - val_accuracy: 0.9160\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0697 - accuracy: 0.9736 - val_loss: 0.2799 - val_accuracy: 0.9160\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0432 - accuracy: 0.9842 - val_loss: 0.3214 - val_accuracy: 0.9040\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0255 - accuracy: 0.9918 - val_loss: 0.4825 - val_accuracy: 0.9120\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0244 - accuracy: 0.9920 - val_loss: 0.3666 - val_accuracy: 0.9160\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0171 - accuracy: 0.9938 - val_loss: 0.4296 - val_accuracy: 0.9180\n",
      "Test loss: 0.306751549243927\n",
      "Test accuracy: 0.9279999732971191\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.566\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3696 - accuracy: 0.8840 - val_loss: 0.2733 - val_accuracy: 0.9020\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2696 - accuracy: 0.9011 - val_loss: 0.2467 - val_accuracy: 0.9020\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2534 - accuracy: 0.9011 - val_loss: 0.2314 - val_accuracy: 0.9020\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2236 - accuracy: 0.9029 - val_loss: 0.2157 - val_accuracy: 0.9020\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2183 - accuracy: 0.9060 - val_loss: 0.2035 - val_accuracy: 0.9080\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2152 - accuracy: 0.9051 - val_loss: 0.2177 - val_accuracy: 0.9000\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1983 - accuracy: 0.9182 - val_loss: 0.2198 - val_accuracy: 0.8980\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1958 - accuracy: 0.9173 - val_loss: 0.2059 - val_accuracy: 0.9120\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1774 - accuracy: 0.9233 - val_loss: 0.2003 - val_accuracy: 0.9100\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1633 - accuracy: 0.9360 - val_loss: 0.2529 - val_accuracy: 0.9120\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1494 - accuracy: 0.9364 - val_loss: 0.2737 - val_accuracy: 0.9140\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1349 - accuracy: 0.9476 - val_loss: 0.1975 - val_accuracy: 0.9300\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1181 - accuracy: 0.9509 - val_loss: 0.2366 - val_accuracy: 0.9160\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0922 - accuracy: 0.9640 - val_loss: 0.2271 - val_accuracy: 0.9120\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0825 - accuracy: 0.9682 - val_loss: 0.2595 - val_accuracy: 0.9240\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0703 - accuracy: 0.9747 - val_loss: 0.2202 - val_accuracy: 0.9320\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0498 - accuracy: 0.9813 - val_loss: 0.3416 - val_accuracy: 0.9260\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0378 - accuracy: 0.9869 - val_loss: 0.3252 - val_accuracy: 0.9260\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0261 - accuracy: 0.9896 - val_loss: 0.3948 - val_accuracy: 0.9200\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0204 - accuracy: 0.9927 - val_loss: 0.3529 - val_accuracy: 0.9280\n",
      "Test loss: 0.28285130858421326\n",
      "Test accuracy: 0.9269999861717224\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.319\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3385 - accuracy: 0.8789 - val_loss: 0.2642 - val_accuracy: 0.9020\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2704 - accuracy: 0.8993 - val_loss: 0.2524 - val_accuracy: 0.9020\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2332 - accuracy: 0.8993 - val_loss: 0.2591 - val_accuracy: 0.9020\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2227 - accuracy: 0.9060 - val_loss: 0.2192 - val_accuracy: 0.9160\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2153 - accuracy: 0.9053 - val_loss: 0.2107 - val_accuracy: 0.9000\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2080 - accuracy: 0.9138 - val_loss: 0.2329 - val_accuracy: 0.8980\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1854 - accuracy: 0.9211 - val_loss: 0.3254 - val_accuracy: 0.9040\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1904 - accuracy: 0.9213 - val_loss: 0.2076 - val_accuracy: 0.9180\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1633 - accuracy: 0.9302 - val_loss: 0.2249 - val_accuracy: 0.9180\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1653 - accuracy: 0.9324 - val_loss: 0.1939 - val_accuracy: 0.9360\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1381 - accuracy: 0.9424 - val_loss: 0.1973 - val_accuracy: 0.9380\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1364 - accuracy: 0.9436 - val_loss: 0.2317 - val_accuracy: 0.9180\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0966 - accuracy: 0.9611 - val_loss: 0.2300 - val_accuracy: 0.9280\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0939 - accuracy: 0.9622 - val_loss: 0.2367 - val_accuracy: 0.9260\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0755 - accuracy: 0.9691 - val_loss: 0.2204 - val_accuracy: 0.9320\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0553 - accuracy: 0.9793 - val_loss: 0.2351 - val_accuracy: 0.9260\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0312 - accuracy: 0.9884 - val_loss: 0.3289 - val_accuracy: 0.9240\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0203 - accuracy: 0.9936 - val_loss: 0.3108 - val_accuracy: 0.9340\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0235 - accuracy: 0.9911 - val_loss: 0.3690 - val_accuracy: 0.9260\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0217 - accuracy: 0.9927 - val_loss: 0.3713 - val_accuracy: 0.9360\n",
      "Test loss: 0.3627156615257263\n",
      "Test accuracy: 0.9380000233650208\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.578\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3557 - accuracy: 0.8904 - val_loss: 0.2721 - val_accuracy: 0.9020\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2607 - accuracy: 0.9027 - val_loss: 0.2591 - val_accuracy: 0.9020\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2351 - accuracy: 0.9029 - val_loss: 0.2416 - val_accuracy: 0.9020\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2210 - accuracy: 0.9051 - val_loss: 0.2291 - val_accuracy: 0.9020\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2084 - accuracy: 0.9082 - val_loss: 0.2058 - val_accuracy: 0.9080\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1991 - accuracy: 0.9160 - val_loss: 0.2334 - val_accuracy: 0.9060\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1982 - accuracy: 0.9242 - val_loss: 0.2129 - val_accuracy: 0.9220\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1793 - accuracy: 0.9244 - val_loss: 0.1949 - val_accuracy: 0.9260\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1571 - accuracy: 0.9380 - val_loss: 0.2099 - val_accuracy: 0.9200\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1489 - accuracy: 0.9389 - val_loss: 0.3531 - val_accuracy: 0.9020\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1349 - accuracy: 0.9480 - val_loss: 0.1790 - val_accuracy: 0.9200\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1061 - accuracy: 0.9593 - val_loss: 0.1768 - val_accuracy: 0.9140\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0997 - accuracy: 0.9576 - val_loss: 0.1808 - val_accuracy: 0.9240\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0865 - accuracy: 0.9680 - val_loss: 0.1644 - val_accuracy: 0.9440\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0727 - accuracy: 0.9722 - val_loss: 0.2005 - val_accuracy: 0.9300\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0500 - accuracy: 0.9822 - val_loss: 0.2046 - val_accuracy: 0.9380\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0334 - accuracy: 0.9900 - val_loss: 0.2896 - val_accuracy: 0.9220\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0664 - accuracy: 0.9716 - val_loss: 0.2548 - val_accuracy: 0.9380\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0518 - accuracy: 0.9813 - val_loss: 0.2056 - val_accuracy: 0.9320\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0193 - accuracy: 0.9924 - val_loss: 0.2781 - val_accuracy: 0.9020\n",
      "Test loss: 0.28532901406288147\n",
      "Test accuracy: 0.9229999780654907\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.893\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3575 - accuracy: 0.8949 - val_loss: 0.2688 - val_accuracy: 0.9020\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2730 - accuracy: 0.9016 - val_loss: 0.2442 - val_accuracy: 0.8980\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2475 - accuracy: 0.9033 - val_loss: 0.2220 - val_accuracy: 0.9020\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2244 - accuracy: 0.9029 - val_loss: 0.2310 - val_accuracy: 0.9020\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2176 - accuracy: 0.9073 - val_loss: 0.2402 - val_accuracy: 0.9060\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2131 - accuracy: 0.9073 - val_loss: 0.2045 - val_accuracy: 0.9100\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2153 - accuracy: 0.9093 - val_loss: 0.2127 - val_accuracy: 0.9080\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1955 - accuracy: 0.9180 - val_loss: 0.2031 - val_accuracy: 0.9200\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2030 - accuracy: 0.9193 - val_loss: 0.2018 - val_accuracy: 0.9100\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1827 - accuracy: 0.9240 - val_loss: 0.2299 - val_accuracy: 0.9140\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1567 - accuracy: 0.9380 - val_loss: 0.2791 - val_accuracy: 0.9120\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1536 - accuracy: 0.9347 - val_loss: 0.1994 - val_accuracy: 0.9240\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1284 - accuracy: 0.9453 - val_loss: 0.2063 - val_accuracy: 0.9220\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0986 - accuracy: 0.9640 - val_loss: 0.2349 - val_accuracy: 0.9340\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0767 - accuracy: 0.9713 - val_loss: 0.2233 - val_accuracy: 0.9280\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0591 - accuracy: 0.9769 - val_loss: 0.2917 - val_accuracy: 0.9020\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0548 - accuracy: 0.9776 - val_loss: 0.3041 - val_accuracy: 0.9200\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0289 - accuracy: 0.9896 - val_loss: 0.2760 - val_accuracy: 0.9400\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0214 - accuracy: 0.9911 - val_loss: 0.3032 - val_accuracy: 0.9360\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0231 - accuracy: 0.9927 - val_loss: 0.4147 - val_accuracy: 0.9280\n",
      "Test loss: 0.37039944529533386\n",
      "Test accuracy: 0.925000011920929\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.524\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3615 - accuracy: 0.8944 - val_loss: 0.2747 - val_accuracy: 0.9020\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2676 - accuracy: 0.9007 - val_loss: 0.2469 - val_accuracy: 0.9080\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2574 - accuracy: 0.9000 - val_loss: 0.2373 - val_accuracy: 0.9040\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2273 - accuracy: 0.9038 - val_loss: 0.2267 - val_accuracy: 0.9000\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2168 - accuracy: 0.9109 - val_loss: 0.2250 - val_accuracy: 0.9000\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2016 - accuracy: 0.9127 - val_loss: 0.2928 - val_accuracy: 0.9120\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.2051 - accuracy: 0.9144 - val_loss: 0.1957 - val_accuracy: 0.9140\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1780 - accuracy: 0.9233 - val_loss: 0.1978 - val_accuracy: 0.9280\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1675 - accuracy: 0.9307 - val_loss: 0.1919 - val_accuracy: 0.9360\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1443 - accuracy: 0.9387 - val_loss: 0.2204 - val_accuracy: 0.9100\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1346 - accuracy: 0.9500 - val_loss: 0.2755 - val_accuracy: 0.9160\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.1369 - accuracy: 0.9458 - val_loss: 0.1892 - val_accuracy: 0.9340\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1119 - accuracy: 0.9549 - val_loss: 0.1767 - val_accuracy: 0.9440\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.1010 - accuracy: 0.9567 - val_loss: 0.2281 - val_accuracy: 0.9320\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0764 - accuracy: 0.9704 - val_loss: 0.2142 - val_accuracy: 0.9340\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0811 - accuracy: 0.9702 - val_loss: 0.2450 - val_accuracy: 0.9180\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0619 - accuracy: 0.9789 - val_loss: 0.2757 - val_accuracy: 0.9380\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0385 - accuracy: 0.9860 - val_loss: 0.3104 - val_accuracy: 0.9280\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0352 - accuracy: 0.9873 - val_loss: 0.2865 - val_accuracy: 0.9260\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0455 - accuracy: 0.9824 - val_loss: 0.3283 - val_accuracy: 0.9360\n",
      "Test loss: 0.2184830605983734\n",
      "Test accuracy: 0.9440000057220459\n",
      "63/63 [==============================] - 0s 1ms/step\n",
      "0.748\n",
      "      通し番号  カウント\n",
      "0        0     8\n",
      "1        1    10\n",
      "2        2     5\n",
      "3        3     0\n",
      "4        4     1\n",
      "...    ...   ...\n",
      "1995  1995     8\n",
      "1996  1996     9\n",
      "1997  1997     9\n",
      "1998  1998     5\n",
      "1999  1999     8\n",
      "\n",
      "[2000 rows x 2 columns]\n",
      "[0.617, 0.267, 0.6075, 0.693, 0.566, 0.319, 0.578, 0.893, 0.524, 0.748]\n",
      "11\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[1611, 1535, 1604, 449, 1361, 444, 1613, 1521, 1489, 236, 3, 777, 1624, 1220, 1627, 682, 1920, 1630, 1169, 784, 398, 481, 516, 1376, 1078, 1969, 1126, 1558, 472, 1121, 1368, 1129, 1511, 502, 251, 1915, 1113, 249, 468, 261, 1954, 1109, 709, 1102, 1587, 1517, 690, 36, 1344, 8, 459, 749, 1087, 714, 1226, 128, 439, 596, 160, 864, 1819, 600, 1823, 1719, 100, 316, 1830, 1460, 1831, 427, 176, 970, 971, 850, 846, 1700, 1443, 872, 873, 605, 897, 619, 1767, 1786, 1163, 1761, 141, 115, 884, 1799, 923, 110, 1803, 338, 1747, 1438, 150, 93, 1694, 1387, 1899, 1284, 1647, 1037, 1309, 1310, 362, 674, 1898, 1900, 1849, 1238, 1312, 1904, 219, 1388, 1040, 1911, 1912, 65, 1475, 1652, 1027, 1299, 651, 1688, 1857, 1858, 1405, 1684, 573, 831, 1404, 1302, 206, 826, 1470, 1660, 306, 69, 663, 384, 634, 863, 1286, 743, 402, 1333, 886, 335, 739, 885, 1328, 1794, 116, 1423, 403, 1805, 1987, 1810, 14, 723, 1352, 1992, 1994, 4, 875, 1337, 55, 29, 1296, 84, 1378, 394, 81, 1929, 1870, 775, 1871, 1927, 76, 73, 1398, 1382, 659, 1923, 818, 1882, 1307, 783, 1886, 814, 799, 1314, 1377, 1862, 652, 1326, 1297, 1825, 859, 1298, 1369, 1829, 636, 1372, 1907, 765, 851, 1856, 349, 1946, 1945, 1847, 350, 1852, 1942, 38, 688, 1937, 127, 1762, 383, 1248, 1097, 1672, 195, 1002, 993, 1585, 246, 991, 985, 1185, 565, 182, 1699, 496, 584, 179, 585, 1565, 1710, 313, 1011, 560, 314, 448, 537, 1636, 1639, 1224, 1641, 441, 1038, 1063, 445, 1477, 1081, 547, 433, 1031, 1605, 304, 1024, 554, 1601, 1471, 254, 1459, 132, 1541, 267, 1758, 1142, 332, 602, 937, 271, 1732, 603, 155, 1135, 135, 139, 1533, 263, 1173, 907, 259, 148, 1128, 950, 275, 415, 1722, 1448, 1279, 616, 279, 1131, 491, 1751, 994, 987, 352, 1693, 183, 89, 1350, 1464, 359, 666, 1645, 62, 1308, 1396, 1428, 70, 1657, 210, 1242, 1465, 1666, 1012, 204, 1468, 1866, 429, 1466, 830, 192, 843, 1164, 979, 890, 630, 877, 1289, 416, 612, 914, 1755, 331, 911, 925, 1788, 910, 1787, 119, 1784, 120, 893, 900, 152, 153, 844, 853, 94, 1840, 96, 97, 1249, 587, 1237, 1835, 957, 1290, 1718, 1294, 1725, 944, 318, 419, 866, 868, 793, 1884, 507, 1934, 290, 515, 37, 1943, 740, 490, 43, 1339, 11, 770, 733, 1494, 234, 1544, 233, 1554, 1555, 511, 1327, 1177, 1960, 1965, 1564, 1959, 1563, 1364, 371, 503, 759, 761, 287, 742, 1516, 1140, 1608, 695, 437, 1160, 727, 721, 719, 1623, 786, 679, 230, 1524, 724, 532, 1620, 434, 791, 1540, 1162, 1930, 1322, 447, 1909, 1651, 533, 485, 222, 535, 1042, 483, 218, 1646, 1035, 1957, 1958, 1629, 1955, 209, 1157, 556, 1016, 272, 691, 35, 487, 1119, 531, 1574, 1577, 245, 1104, 1982, 1981, 1091, 1592, 494, 15, 517, 1599, 6, 751, 1076, 257, 41, 753, 1966, 1616, 754, 1621, 530, 817, 982, 1691, 1783, 888, 117, 887, 880, 1894, 1804, 1811, 871, 104, 862, 860, 101, 1828, 810, 1839, 845, 643, 812, 1854, 1855, 1859, 656, 827, 66, 823, 821, 1780, 58, 896, 943, 980, 72, 1698, 967, 593, 958, 956, 955, 597, 1932, 1723, 1724, 779, 794, 161, 780, 936, 1922, 1741, 785, 611, 276, 54, 56, 142, 1759, 687, 717, 1190, 401, 1246, 1301, 1250, 1371, 346, 323, 1274, 1441, 1461, 1362, 470, 341, 1266, 1452, 1495, 1259, 1449, 1357, 1341, 1422, 458, 1430, 361, 1194, 407, 1500, 1410, 292, 1317, 1178, 1199, 1383, 1287, 1486, 1192, 1170, 80, 1385, 1584, 91, 1602, 1367, 1772, 1370, 241, 1743, 1771, 1355, 1379, 1750, 1746, 1390, 368, 1872, 240, 1606, 1597, 45, 1873, 1481, 312, 1456, 1897, 1518, 303, 1910, 302, 202, 285, 248, 1483, 1806, 289, 1931, 1685, 1496, 1493, 44, 1956, 1815, 1659, 1446, 1726, 1881, 20, 1416, 1424, 1425, 1559, 1553, 1649, 1545, 1349, 130, 174, 213, 268, 1792, 211, 1713, 1000, 566, 1267, 997, 575, 978, 594, 426, 599, 1260, 942, 601, 927, 1009, 924, 614, 1280, 906, 622, 894, 878, 637, 646, 569, 1010, 1304, 1085, 1137, 493, 1120, 1179, 1111, 1186, 509, 1095, 1086, 454, 1023, 1077, 522, 1071, 525, 1062, 1061, 1054, 1028, 432, 1303, 613, 477, 1343, 762, 685, 392, 684, 396, 755, 1329, 797, 745, 705, 1342, 388, 1325, 731, 385, 715, 661, 1334, 307, 580, 431, 689, 184, 381, 1940, 983, 1414, 1338, 725, 12, 1233, 1935, 1748, 21, 1399, 1229, 451, 1727, 778, 189, 1800, 1491, 1928, 1217, 1488, 1487, 440, 1223, 1933, 1998, 686, 2, 438, 1295, 1695, 728, 156, 963, 734, 698, 1421, 325, 1775, 748, 839, 1311, 1427, 1715, 708, 1395, 333, 898, 1269, 966, 1429, 908, 154, 1330, 608, 1252, 1254, 1407, 1306, 604, 395, 31, 1796, 366, 1397, 1705, 321, 172, 1068, 1925, 655, 264, 86, 87, 1539, 484, 1145, 1146, 808, 807, 553, 479, 529, 238, 270, 506, 1664, 1596, 214, 453, 832, 811, 1582, 1576, 1573, 71, 1569, 244, 1046, 1100, 543, 1566, 1562, 1125, 1638, 1099, 1832, 61, 217, 1526, 1019, 1675, 461, 1814, 1507, 466, 478, 632, 1618, 288, 1612, 231, 1008, 998, 1198, 295, 455, 1680, 1848, 524, 1203, 681, 95, 834, 1514, 278, 1168, 1522, 564, 474, 1905, 1903, 654, 518, 1543, 1547, 1381, 665, 1148, 1144, 918, 1149, 482, 806, 1155, 1156, 1158, 60, 1552, 1273, 372, 1127, 1853, 1073, 837, 1600, 1082, 239, 1089, 1094, 510, 1988, 1583, 375, 713, 822, 1332, 1570, 68, 1567, 729, 804, 373, 1122, 399, 670, 1936, 1478, 1951, 693, 1291, 1419, 760, 310, 406, 1257, 1258, 746, 1963, 1263, 699, 327, 411, 1442, 1268, 326, 752, 22, 435, 1230, 9, 340, 1440, 795, 283, 790, 1181, 787, 1508, 1916, 1917, 360, 356, 703, 1503, 1201, 1205, 452, 1408, 1211, 1851, 1485, 1482, 232, 915, 1347, 1020, 1703, 1818, 892, 551, 1707, 1029, 1709, 99, 858, 171, 1644, 1041, 951, 899, 949, 855, 598, 538, 165, 974, 975, 1049, 111, 1801, 1809, 990, 578, 198, 1007, 1686, 627, 199, 1669, 1668, 1665, 1689, 883, 562, 181, 1697, 1798, 867, 1838, 576, 621, 847, 645, 1753, 921, 1749, 1619, 1060, 912, 1843, 615, 227, 1842, 1729, 140, 223, 534, 849, 902, 1055, 212, 1052, 544, 1044, 528, 1637, 1064, 229, 1648, 1635, 1034, 377, 1655, 1021, 1720, 948, 945, 163, 941, 158, 1735, 1736, 935, 934, 1737, 931, 1739, 929, 609, 954, 595, 961, 577, 1662, 1006, 1677, 572, 1679, 1681, 989, 590, 981, 977, 582, 180, 968, 177, 1067, 252, 1614, 309, 322, 1262, 1450, 1256, 1458, 1462, 1247, 428, 521, 430, 1473, 301, 1232, 1225, 1221, 296, 1270, 1271, 328, 1285, 1351, 379, 718, 1340, 1359, 387, 1365, 1321, 365, 400, 1392, 1393, 1300, 345, 1292, 1212, 1208, 1206, 1136, 492, 1130, 258, 916, 1568, 1118, 498, 1571, 504, 1106, 1588, 1096, 242, 514, 1598, 1551, 1147, 462, 1537, 464, 1189, 467, 1509, 469, 1180, 1513, 471, 473, 1167, 277, 1527, 1161, 1159, 480, 917, 549, 813, 1948, 51, 1919, 1812, 46, 1807, 781, 879, 881, 764, 129, 1952, 33, 758, 756, 1964, 1789, 623, 28, 675, 798, 1901, 673, 835, 82, 642, 825, 824, 74, 657, 98, 1833, 1885, 64, 857, 1892, 1893, 861, 1821, 107, 122, 776, 1770, 1979, 1985, 744, 1978, 710, 1773, 1977, 7, 131, 147, 1769, 1990, 138, 730, 905, 1984, 891, 1777, 1752, 903, 1765, 1782, 1790, 1757, 1243, 856, 801, 792, 789, 1913, 788, 1926, 768, 1938, 1939, 1961, 747, 1967, 737, 736, 1986, 732, 1991, 1995, 796, 904, 1793, 1888, 1808, 1826, 1834, 1836, 838, 836, 1841, 1846, 829, 820, 1861, 1863, 816, 1867, 1868, 1877, 1880, 1742, 1653, 1740, 1412, 1134, 1418, 1420, 1426, 1123, 1117, 1435, 1439, 1444, 1107, 1457, 1463, 1093, 1088, 1084, 1484, 1492, 1502, 1504, 1506, 1069, 1415, 1143, 1059, 716, 1239, 1251, 1235, 1231, 1228, 1255, 1264, 1265, 1276, 1215, 1288, 1305, 1324, 1196, 1195, 1346, 1360, 1374, 1176, 1384, 1165, 1515, 1525, 920, 1640, 1003, 1650, 1001, 1245, 1656, 995, 992, 1661, 1667, 1670, 1674, 962, 952, 1696, 1702, 1708, 1712, 932, 1714, 1717, 1721, 1642, 1014, 1528, 1634, 1530, 1532, 1534, 1048, 1549, 1556, 1561, 1579, 1043, 1590, 1591, 1033, 1593, 1594, 1609, 1610, 1615, 1628, 1632, 1017, 1633, 0, 1999, 450, 436, 526, 190, 262, 298, 299, 579, 546, 34, 294, 308, 178, 118, 626, 586, 641, 671, 574, 486, 423, 678, 274, 280, 57, 476, 208, 282, 550, 633, 109, 570, 284, 108, 102, 548, 631, 49, 221, 424, 501, 374, 243, 92, 363, 512, 397, 370, 390, 519, 226, 527, 235, 88, 523, 5, 382, 149, 355, 103, 413, 420, 16, 344, 505, 247, 408, 173, 25, 700, 225, 417, 170, 712, 1240, 1174, 722, 701, 738, 1182, 1193, 767, 1202, 771, 692, 1210, 463, 702, 1207, 443, 773, 460, 757, 774, 1209, 697, 592, 475, 1013, 882, 541, 625, 1045, 620, 618, 913, 1026, 1022, 557, 928, 558, 559, 563, 607, 1171, 567, 568, 571, 933, 988, 938, 939, 984, 581, 976, 973, 940, 969, 588, 540, 539, 876, 1051, 1166, 1152, 1151, 1150, 802, 803, 805, 495, 500, 1112, 1110, 828, 1105, 653, 1103, 960, 513, 841, 1090, 1083, 644, 842, 848, 520, 640, 1070, 1065, 1058, 1053, 1098, 358, 1889, 187, 1501, 185, 186, 1766, 1878, 1512, 1876, 191, 1875, 77, 1869, 188, 1683, 266, 291, 1499, 1692, 1891, 1906, 1480, 1469, 1467, 1908, 1764, 311, 1453, 315, 1704, 320, 143, 53, 1542, 83, 50, 1781, 224, 1824, 1820, 105, 1813, 220, 112, 260, 113, 1643, 216, 215, 1795, 1791, 123, 1622, 1617, 1827, 125, 205, 1607, 1778, 203, 1671, 201, 1581, 1850, 197, 196, 255, 1678, 1436, 1437, 329, 1968, 1970, 1313, 1315, 1319, 1323, 393, 391, 1962, 26, 1335, 386, 1345, 168, 1353, 1972, 405, 1281, 162, 409, 412, 19, 1275, 1983, 1730, 159, 425, 1734, 1253, 1738, 1996, 1997, 1358, 1356, 1363, 1403, 1433, 1432, 1918, 1431, 48, 1921, 1924, 175, 144, 145, 348, 1411, 1941, 1406, 351, 1402, 1400, 30, 1754, 1375, 1949, 1389, 1391, 357, 1658, 1401, 1947, 1944, 720, 1536, 1519, 1520, 1523, 1057, 1529, 1056, 273, 1531, 269, 1538, 1066, 1050, 265, 536, 1546, 1548, 1047, 1550, 1557, 256, 281, 1510, 591, 1490, 1455, 1101, 1092, 1472, 305, 1474, 1476, 1479, 300, 297, 286, 1080, 1497, 1498, 293, 1079, 1075, 1074, 1072, 1505, 1560, 253, 542, 986, 1015, 1005, 1241, 1, 1654, 999, 996, 1663, 207, 583, 1572, 200, 1673, 972, 965, 1676, 194, 193, 589, 1682, 561, 1631, 1626, 228, 250, 1575, 1578, 1580, 545, 1586, 1589, 1039, 1036, 1032, 1030, 1595, 237, 1603, 552, 1025, 555, 1018, 1625, 1454, 508, 1451, 1331, 1293, 1204, 1316, 1318, 1320, 1200, 456, 457, 1197, 389, 1184, 1336, 1191, 1348, 465, 1354, 380, 1188, 378, 1187, 404, 1213, 1283, 1282, 1236, 1234, 1227, 1222, 1261, 422, 421, 1219, 442, 418, 1272, 1218, 414, 1277, 1216, 1278, 410, 446, 1214, 376, 1183, 317, 1116, 1417, 1133, 339, 1132, 337, 336, 1124, 334, 497, 330, 1366, 499, 1434, 1115, 1114, 324, 1445, 1108, 319, 1447, 342, 343, 489, 1413, 1373, 1175, 369, 1380, 367, 1386, 364, 1172, 1394, 1154, 1153, 354, 353, 1141, 1409, 1139, 1138, 347, 488, 964, 1004, 1244, 833, 694, 1816, 106, 1817, 763, 1822, 840, 647, 648, 649, 39, 40, 650, 766, 1837, 42, 1844, 1802, 1797, 852, 865, 126, 874, 124, 676, 696, 869, 121, 1785, 1950, 32, 635, 854, 1953, 638, 639, 114, 1845, 769, 750, 90, 1879, 1883, 67, 1887, 683, 672, 63, 1890, 1914, 800, 1895, 52, 782, 59, 1896, 680, 1902, 669, 668, 667, 1865, 1860, 658, 772, 819, 1864, 85, 47, 660, 75, 662, 815, 664, 79, 78, 809, 1874, 1779, 870, 610, 1733, 1976, 169, 13, 1975, 1974, 1973, 167, 166, 17, 18, 706, 704, 164, 1728, 926, 1731, 1971, 606, 1716, 930, 726, 959, 1687, 1690, 953, 947, 1701, 946, 1706, 1980, 1993, 711, 1989, 735, 707, 1711, 10, 922, 677, 895, 889, 27, 1763, 1760, 137, 741, 624, 157, 901, 136, 628, 134, 146, 1756, 133, 1768, 23, 919, 24, 1776, 1745, 629, 151, 1774, 1744, 617, 909]\n",
      "500\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPool2D\n",
    "from keras.layers.core import Dense,Activation,Dropout,Flatten\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import dlt\n",
    "import os\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "\n",
    "#データセットを読み込んでテンソルに変換\n",
    "\n",
    "#画像名リスト作成\n",
    "test_filename = os.listdir('./500test')           #ここで指定したディレクトリをまとめてnp配列に変換できる。\n",
    "true_filename = os.listdir('./10000harf')\n",
    "\n",
    "\n",
    "\n",
    "#random.shuffle(test_filename)\n",
    "#random.shuffle(true_filename)\n",
    "\n",
    "#dcgan_filename.sort()\n",
    "#print(dcgan_filename)\n",
    "\n",
    "if \".ipynb_checkpoints\" in test_filename:\n",
    "    test_filename.remove(\".ipynb_checkpoints\")     #いらないものを消す。\n",
    "\n",
    "if \".ipynb_checkpoints\" in true_filename:\n",
    "    true_filename.remove(\".ipynb_checkpoints\")\n",
    "    \n",
    "\n",
    "\n",
    "#print(len(true_filename))\n",
    "\n",
    "\n",
    "#クラスリスト作成\n",
    "#ex:classmodeはint型で入る。\n",
    "def makeusable(classmode,filename):\n",
    "    classname = [\"airplane\",\"automobile\",\"bird\",\"cat\",\"deer\",\"dog\",\"frog\",\"horse\",\"ship\",\"truck\"]\n",
    "    list1 = []\n",
    "    i=0\n",
    "    \n",
    "    if classmode == 0:\n",
    "        for name in filename:\n",
    "            if classname[0] in name:\n",
    "                list1.append([1])\n",
    "            else:\n",
    "                list1.append([0])\n",
    "                \n",
    "    elif classmode == 1: \n",
    "        for name in filename:\n",
    "            if classname[1] in name:\n",
    "                list1.append([1])\n",
    "            else:\n",
    "                list1.append([0])\n",
    "                \n",
    "    elif classmode == 2: \n",
    "        for name in filename:\n",
    "            if classname[2] in name:\n",
    "                list1.append([1])\n",
    "            else:\n",
    "                list1.append([0])\n",
    "                \n",
    "        \n",
    "    elif classmode == 3: \n",
    "        for name in filename:\n",
    "            if classname[3] in name:\n",
    "                list1.append([1])\n",
    "            else:\n",
    "                list1.append([0])\n",
    "                \n",
    "    elif classmode == 4: \n",
    "        for name in filename:\n",
    "            if classname[4] in name:\n",
    "                list1.append([1])\n",
    "            else:\n",
    "                list1.append([0])\n",
    "            \n",
    "    elif classmode == 5: \n",
    "        for name in filename:\n",
    "            if classname[5] in name:\n",
    "                list1.append([1])\n",
    "            else:\n",
    "                list1.append([0])\n",
    "                \n",
    "    elif classmode == 6: \n",
    "        for name in filename:\n",
    "            if classname[6] in name:\n",
    "                list1.append([1])\n",
    "            else:\n",
    "                list1.append([0])\n",
    "                \n",
    "    elif classmode == 7: \n",
    "        for name in filename:\n",
    "            if classname[7] in name:\n",
    "                list1.append([1])\n",
    "            else:\n",
    "                list1.append([0])\n",
    "                         \n",
    "    elif classmode == 8: \n",
    "        for name in filename:\n",
    "            if classname[8] in name:\n",
    "                list1.append([1])\n",
    "            else:\n",
    "                list1.append([0])\n",
    "                \n",
    "    else:\n",
    "        for name in filename:\n",
    "            if classname[9] in name:\n",
    "                list1.append([1])\n",
    "            else:\n",
    "                list1.append([0])\n",
    "                \n",
    "            #print(str(i)+\":\"+str(name))\n",
    "            i+=1\n",
    "                \n",
    "                \n",
    "    #list型をnp.arrayに変換\n",
    "    classlist = np.array(list1)\n",
    "    return classlist\n",
    "\n",
    "#\n",
    "#classmodeの設定！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！\n",
    "#ここで対象クラスを指定\n",
    "#\n",
    "\n",
    "classname = [\"airplane\",\"automobile\",\"bird\",\"cat\",\"deer\",\"dog\",\"frog\",\"horse\",\"ship\",\"truck\"]\n",
    "\n",
    "#統計用リスト\n",
    "kklist = []\n",
    "\n",
    "for classmode in range(len(classname)):\n",
    "\n",
    "    fname = './20000dcpic_c/{}'.format(classname[classmode])\n",
    "    dcgan_filename = os.listdir(fname)\n",
    "\n",
    "    if \".ipynb_checkpoints\" in dcgan_filename:\n",
    "        dcgan_filename.remove(\".ipynb_checkpoints\")  \n",
    "\n",
    "\n",
    "    #画像ファイルの相対パスを取得\n",
    "    test_filepass = []\n",
    "    for name in test_filename:\n",
    "        test_filepass.append(\"./500test/\"+name)\n",
    "\n",
    "    #print(filepass)\n",
    "\n",
    "    true_filepass = []\n",
    "    for name in true_filename:\n",
    "        true_filepass.append(\"./10000harf/\"+name)\n",
    "\n",
    "    dcgan_filepass = []\n",
    "    for name in dcgan_filename:\n",
    "        dcgan_filepass.append(fname+\"/\"+name)\n",
    "\n",
    "\n",
    "    test_label = makeusable(classmode,test_filename)\n",
    "    true_label = makeusable(classmode,true_filename)\n",
    "\n",
    "    dcgan_label = makeusable(classmode,dcgan_filename)\n",
    "\n",
    "\n",
    "\n",
    "    #test画像\n",
    "    #png画像をndarrayに変換。→一旦listに直して、imlistに追加\n",
    "    test_imlist = []\n",
    "    for im in test_filepass:\n",
    "        pic = np.array(Image.open(im))\n",
    "        piclist = pic.tolist()\n",
    "        test_imlist.append(piclist)\n",
    "\n",
    "    #imlist（list型）をimarray（ndarray型）に変換\n",
    "    test_imarray = np.array(test_imlist)\n",
    "\n",
    "\n",
    "    #true画像\n",
    "    #png画像をndarrayに変換。→一旦listに直して、imlistに追加\n",
    "    true_imlist = []\n",
    "    for im in true_filepass:\n",
    "        pic = np.array(Image.open(im))\n",
    "        piclist = pic.tolist()\n",
    "        true_imlist.append(piclist)\n",
    "\n",
    "    #imlist（list型）をimarray（ndarray型）に変換\n",
    "    true_imarray = np.array(true_imlist)\n",
    "\n",
    "    #print(true_filepass)\n",
    "    #print(len(true_filepass),len(true_label))\n",
    "    #print(len(x))\n",
    "\n",
    "    #dcgan画像\n",
    "    #png画像をndarrayに変換。→一旦listに直して、imlistに追加\n",
    "    dcgan_imlist = []\n",
    "    for im in dcgan_filepass:\n",
    "        pic = np.array(Image.open(im))\n",
    "        piclist = pic.tolist()\n",
    "        dcgan_imlist.append(piclist)\n",
    "\n",
    "    #imlist（list型）をimarray（ndarray型）に変換\n",
    "    dcgan_imarray = np.array(dcgan_imlist)\n",
    "\n",
    "\n",
    "    #ここで2つのパターンを用意する。\n",
    "    #パターン１：学習段階で、usableを５００枚（１クラス分）＋unusableを４５００枚（他の９クラス全部）\n",
    "    #パターン２：学習段階で、usableを５００枚（１クラス分）＋unusableを５００枚（他の９クラスからランダムに５００枚選出）←今これ\n",
    "    #\n",
    "    #これらでそれぞれ学習させ、精度の良い方を使用。\n",
    "\n",
    "\n",
    "    #cifar10のデータセットを設定。テスト画像も変えてね。\n",
    "    (x_train,y_train)=(true_imarray,true_label)\n",
    "    (x_test,y_test)=(test_imarray,test_label)\n",
    "\n",
    "\n",
    "    #画像を0-1の範囲で正規化\n",
    "    x_train=x_train.astype('float32')/255.0\n",
    "    x_test=x_test.astype('float32')/255.0\n",
    "\n",
    "    #正解ラベルをOne-Hot表現に変換\n",
    "    y_train=np_utils.to_categorical(y_train,2)\n",
    "    y_test=np_utils.to_categorical(y_test,2)\n",
    "\n",
    "    #統計用リスト\n",
    "    picnum = []\n",
    "    fcount = []\n",
    "    acclist = []\n",
    "    prelabellist = []\n",
    "\n",
    "    for n in range(2000):\n",
    "        picnum.append(n)\n",
    "        fcount.append(0)\n",
    "\n",
    "    #１０回学習\n",
    "    for num in range(10):\n",
    "        #モデルを構築\n",
    "        model=Sequential()\n",
    "\n",
    "        model.add(Conv2D(64,(3,3),padding='same',input_shape=(32,32,3)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Conv2D(64,(3,3),padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPool2D(pool_size=(2,2)))\n",
    "        #model.add(Dropout(0.25))\n",
    "\n",
    "        model.add(Conv2D(128,(3,3),padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Conv2D(128,(3,3),padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPool2D(pool_size=(2,2)))\n",
    "        #model.add(Dropout(0.25))\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1024))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(2,activation='softmax'))\n",
    "\n",
    "        model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "        history=model.fit(x_train,y_train,batch_size=128,epochs=20,verbose=1,validation_split=0.1)\n",
    "\n",
    "        #モデルと重みを保存\n",
    "        json_string=model.to_json()\n",
    "        open('cifar10_cnn.json',\"w\").write(json_string)\n",
    "        savefilename = '{}_cnn.h5'.format(classname[classmode])\n",
    "        model.save_weights(savefilename)\n",
    "\n",
    "        #モデルの表示/\n",
    "        #model.summary()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        #評価\n",
    "        score=model.evaluate(x_test,y_test,verbose=0)\n",
    "        print('Test loss:',score[0])\n",
    "        print('Test accuracy:',score[1])\n",
    "\n",
    "\n",
    "        #ファイル選別のためのアドレスを生成\n",
    "\n",
    "        acc_count = []\n",
    "        usable = []\n",
    "        unusable = []\n",
    "\n",
    "        x_usable = dcgan_imarray\n",
    "        y_usable = dcgan_label\n",
    "\n",
    "        y_predict = model.predict(x_usable, batch_size=32)\n",
    "        predict_classes = np.argmax(y_predict,1)\n",
    "        true_classes = np.argmax(y_usable,1)\n",
    "\n",
    "        for i in range(len(predict_classes)):\n",
    "            if predict_classes[i] == [1]:\n",
    "                acc_count.append(1)    \n",
    "                usable.append(i)\n",
    "\n",
    "\n",
    "            else:\n",
    "                acc_count.append(0)\n",
    "                unusable.append(i)\n",
    "\n",
    "\n",
    "        acc = np.average(acc_count)\n",
    "\n",
    "        #acc_count：usableなら１,unusableなら０となっている、予測されたラベルのリスト\n",
    "        prelabellist.append(acc_count)\n",
    "\n",
    "\n",
    "        for num in usable:\n",
    "            fcount[num] += 1\n",
    "\n",
    "\n",
    "\n",
    "        print(acc)\n",
    "        acclist.append(acc)\n",
    "        #print(usable)\n",
    "        #print(unusable)\n",
    "\n",
    "    data = {\n",
    "        \"通し番号\" : picnum,\n",
    "        \"カウント\" : fcount\n",
    "    }\n",
    "\n",
    "    df = pd.DataFrame(data, columns=[\"通し番号\", \"カウント\"])\n",
    "\n",
    "    predicts = {\n",
    "        \"通し番号\" : picnum,\n",
    "        \"１回目\" : prelabellist[0],\n",
    "        \"２回目\" : prelabellist[1],\n",
    "        \"３回目\" : prelabellist[2],\n",
    "        \"４回目\" : prelabellist[3],\n",
    "        \"５回目\" : prelabellist[4],\n",
    "        \"６回目\" : prelabellist[5],\n",
    "        \"７回目\" : prelabellist[6],\n",
    "        \"８回目\" : prelabellist[7],\n",
    "        \"９回目\" : prelabellist[8],\n",
    "        \"１０回目\" : prelabellist[9]\n",
    "    }\n",
    "\n",
    "    pds = pd.DataFrame(predicts, columns=[\"通し番号\",\"１回目\",\"２回目\",\"３回目\",\"４回目\",\"５回目\",\"６回目\",\"７回目\",\"８回目\",\"９回目\",\"１０回目\"])\n",
    "\n",
    "    print(df)\n",
    "    print(acclist)\n",
    "    df.to_csv(\"ave10.csv\")\n",
    "    pds.to_csv(\"plabellist.csv\")\n",
    "    \n",
    "    dfs = df.sort_values(\"カウント\",ascending=False)\n",
    "\n",
    "    dfname = \"ave10_c{}_sort.csv\".format(classmode)\n",
    "    dfs.to_csv(dfname)\n",
    "\n",
    "    #ファイルの選別\n",
    "    #画像をスコアごとリストにまとめる。後、一つのリストに結合。\n",
    "    slist = []\n",
    "    sortbyscore = []\n",
    "    for sc in range(11):\n",
    "        exec(\"cnt{} = []\".format(sc))\n",
    "        exec(\"slist.append(cnt{})\".format(sc))\n",
    "\n",
    "    for sc in range(11):\n",
    "        con = \"カウント == {}\".format(sc)\n",
    "        df0 = dfs.query(con)\n",
    "        slist[sc] = list(df0[\"通し番号\"])\n",
    "\n",
    "    print(len(slist))\n",
    "\n",
    "    for sc in range(len(slist)):\n",
    "        sortbyscore = sortbyscore + slist[sc]\n",
    "\n",
    "\n",
    "    print(\"\\n\\n\\n\\n\")\n",
    "    print(sortbyscore)\n",
    "    #本当に使える画像（Tusable）と本当に使えなさそうな画像（Tunusable）に分ける。\n",
    "\n",
    "    Tusable = sortbyscore[1500:2000]\n",
    "    Tunusable = sortbyscore[0:500]\n",
    "\n",
    "    print(len(Tusable))\n",
    "    print(len(Tunusable))\n",
    "\n",
    "    #ディレクトリに入れる\n",
    "    for i in range(len(Tusable)):\n",
    "        file = fname+\"/\"+str(dcgan_filename[Tusable[i]])\n",
    "        target = \"./usable/{}\".format(str(dcgan_filename[Tusable[i]]))\n",
    "        shutil.copyfile(file, target)\n",
    "\n",
    "\n",
    "    for i in range(len(Tunusable)):\n",
    "        file = fname+\"/\"+str(dcgan_filename[Tunusable[i]])\n",
    "        target = \"./unusable/{}\".format(str(dcgan_filename[Tunusable[i]]))\n",
    "        shutil.copyfile(file, target)\n",
    "        \n",
    "    klist = []\n",
    "    for i in range(11):\n",
    "        txt = \"カウント == {}\".format(i)\n",
    "        dfn = dfs.query(txt)\n",
    "        klist.append(len(dfn))\n",
    "        \n",
    "    kklist.append(klist)\n",
    "    \n",
    "#pd.Series(klist)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e429f9b4-8233-42ed-b65a-bfcbdaa84250",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c5b43ff-0200-46c9-81fc-9829d6ab0b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.58125\n",
      "0.0310497625\n"
     ]
    }
   ],
   "source": [
    "print(np.average(acclist))\n",
    "print(np.var(acclist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab47433-a02e-4689-8b59-0401013040d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd30836-6d00-4e14-8035-31a51b611f92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0694995-35dd-4cd3-b680-53c776444857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#ファイル選別のためのアドレスを生成\\n\\nacc_count = []\\nusable = []\\nunusable = []\\n\\nx_usable = dcgan_imarray\\ny_usable = dcgan_label\\n\\ny_predict = model.predict(x_usable, batch_size=32)\\npredict_classes = np.argmax(y_predict,1)\\ntrue_classes = np.argmax(y_usable,1)\\n\\nfor i in range(len(predict_classes)):\\n    if predict_classes[i] == [1]:\\n        acc_count.append(1)    \\n        usable.append(i)\\n        \\n        \\n    else:\\n        acc_count.append(0)\\n        unusable.append(i)\\n\\n\\nacc = np.average(acc_count)\\n\\n\\nfor num in usable:\\n    fcount[num] += 1\\n\\n\\n\\nprint(acc)\\n#print(usable)\\n#print(unusable)\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#ファイル選別のためのアドレスを生成\n",
    "\n",
    "acc_count = []\n",
    "usable = []\n",
    "unusable = []\n",
    "\n",
    "x_usable = dcgan_imarray\n",
    "y_usable = dcgan_label\n",
    "\n",
    "y_predict = model.predict(x_usable, batch_size=32)\n",
    "predict_classes = np.argmax(y_predict,1)\n",
    "true_classes = np.argmax(y_usable,1)\n",
    "\n",
    "for i in range(len(predict_classes)):\n",
    "    if predict_classes[i] == [1]:\n",
    "        acc_count.append(1)    \n",
    "        usable.append(i)\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        acc_count.append(0)\n",
    "        unusable.append(i)\n",
    "\n",
    "\n",
    "acc = np.average(acc_count)\n",
    "\n",
    "\n",
    "for num in usable:\n",
    "    fcount[num] += 1\n",
    "\n",
    "\n",
    "\n",
    "print(acc)\n",
    "#print(usable)\n",
    "#print(unusable)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cfd0be5-ded2-4cd9-b573-91ba22d6500b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor i in range(len(usable)):\\n    file = \"./test_model2/\"+str(dcgan_filename[usable[i]])\\n    target = \"test_model2_us/{}\".format(str(dcgan_filename[usable[i]]))\\n    shutil.copyfile(file, target)\\n\\n\\nfor j in range(len(unusable)):\\n    file = \"./test_model2/\"+str(dcgan_filename[unusable[j]])\\n    target = \"test_model2_un/{}\".format(str(dcgan_filename[unusable[j]]))\\n    shutil.copyfile(file, target)\\n\\n\\nprint(\"finish\")\\n\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ファイルの選別（usable/unusable）\n",
    "\n",
    "import shutil\n",
    "\"\"\"\n",
    "for i in range(len(usable)):\n",
    "    file = \"./test_model2/\"+str(dcgan_filename[usable[i]])\n",
    "    target = \"test_model2_us/{}\".format(str(dcgan_filename[usable[i]]))\n",
    "    shutil.copyfile(file, target)\n",
    "\n",
    "\n",
    "for j in range(len(unusable)):\n",
    "    file = \"./test_model2/\"+str(dcgan_filename[unusable[j]])\n",
    "    target = \"test_model2_un/{}\".format(str(dcgan_filename[unusable[j]]))\n",
    "    shutil.copyfile(file, target)\n",
    "\n",
    "\n",
    "print(\"finish\")\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "491450e0-6c22-4654-8c76-56ea58b13dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8293ab-9fbb-4f44-b2e2-cbc90e8037c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
